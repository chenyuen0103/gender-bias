{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, pipeline\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "input_dir = '../data/inputs'\n",
    "output_dir = '../data/outputs/s0'\n",
    "results_dir = '../data/results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:45:30.824026Z",
     "start_time": "2024-06-02T01:45:30.818138Z"
    }
   },
   "id": "f44b57b8ed707cad",
   "execution_count": 295
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:18.270313Z",
     "start_time": "2024-06-02T01:08:18.262643Z"
    }
   },
   "id": "18db9a6c65c4e55f",
   "execution_count": 280
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "female_ratios = pd.read_csv(os.path.join(input_dir, 'female_ratios.csv'))\n",
    "# for model in  llama3-8b llama3-8b-instruct mistral-7b mistral-7b-instruct llama2-7b llama2-7b-chat\n",
    "model_strs = ['llama3-8b', 'llama3-8b-instruct', 'mistral-7b', 'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-chat']\n",
    "model_strs = sorted(model_strs, key=len, reverse=True)\n",
    "\n",
    "prompt_ids = ['none','low-1','low-2','medium-3','medium-4','high-5','high-6']\n",
    "prompt_id_mapping = {pid: idx for idx, pid in enumerate(prompt_ids)}\n",
    "\n",
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if \"conv\" not in f and \"gender\" not in f:\n",
    "    # if 'conversation.csv' in f:\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "    # if 'conversation.csv' in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            # make sure the three columns add up to 1\n",
    "            # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "            # \n",
    "            # Optionally, drop the original detailed columns if only averages are needed\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'plain.csv'), index=False)\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:18.599738Z",
     "start_time": "2024-06-02T01:08:18.423397Z"
    }
   },
   "id": "9026f5b07325c14a",
   "execution_count": 281
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if 'conversation.csv' in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            # make sure the three columns add up to 1\n",
    "            # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "            # \n",
    "            # Optionally, drop the original detailed columns if only averages are needed\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'conversation.csv'), index=False)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:18.751468Z",
     "start_time": "2024-06-02T01:08:18.602599Z"
    }
   },
   "id": "e751480d2b8070f5",
   "execution_count": 282
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if 'genderquestion.csv' in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            # make sure the three columns add up to 1\n",
    "            # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "            # \n",
    "            # Optionally, drop the original detailed columns if only averages are needed\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'genderquestion.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:10:11.892351Z",
     "start_time": "2024-06-02T01:10:11.769087Z"
    }
   },
   "id": "6929333781b2efd3",
   "execution_count": 293
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if 'genderquestion_conv.csv' in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "         \n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            # make sure the three columns add up to 1\n",
    "            # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "            # \n",
    "            # Optionally, drop the original detailed columns if only averages are needed\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'genderquestion_conv.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:19.068910Z",
     "start_time": "2024-06-02T01:08:18.963156Z"
    }
   },
   "id": "97353b98d7dd6a5e",
   "execution_count": 284
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['llama2-7b', 'mistral-7b', 'llama3-8b-instruct', 'llama3-8b',\n       'mistral-7b-instruct', 'llama2-7b-chat'], dtype=object)"
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:10:25.547224Z",
     "start_time": "2024-06-02T01:10:25.539647Z"
    }
   },
   "id": "e8b094b1d58fc460",
   "execution_count": 294
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation      male    female  \\\n0              False            llama2-7b          True  0.266465  0.712365   \n1               True            llama2-7b          True  0.105650  0.873290   \n0              False           mistral-7b          True  0.625040  0.360585   \n1               True           mistral-7b          True  0.221395  0.738435   \n0              False           mistral-7b          True  0.796830  0.201195   \n..               ...                  ...           ...       ...       ...   \n1               True  mistral-7b-instruct          True  0.019800  0.038490   \n0              False           mistral-7b          True  0.708945  0.255865   \n1               True           mistral-7b          True  0.353300  0.593430   \n0              False   llama3-8b-instruct          True  0.010045  0.026320   \n1               True   llama3-8b-instruct          True  0.007415  0.021535   \n\n     diverse  female_ratio  prompt_id  alpaca-7b_male  alpaca-7b_female  \\\n0   0.021160         5.535        6.0             NaN               NaN   \n1   0.021050        89.265        6.0             NaN               NaN   \n0   0.014365         5.535        3.0             NaN               NaN   \n1   0.040150        89.265        3.0             NaN               NaN   \n0   0.001975         5.535        0.0             NaN               NaN   \n..       ...           ...        ...             ...               ...   \n1   0.941720        89.265        5.0             NaN               NaN   \n0   0.035170         5.535        1.0             NaN               NaN   \n1   0.053275        89.265        1.0             NaN               NaN   \n0   0.963625         5.535        1.0             NaN               NaN   \n1   0.971060        89.265        1.0             NaN               NaN   \n\n    alpaca-7b_diverse  \n0                 NaN  \n1                 NaN  \n0                 NaN  \n1                 NaN  \n0                 NaN  \n..                ...  \n1                 NaN  \n0                 NaN  \n1                 NaN  \n0                 NaN  \n1                 NaN  \n\n[84 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>male</th>\n      <th>female</th>\n      <th>diverse</th>\n      <th>female_ratio</th>\n      <th>prompt_id</th>\n      <th>alpaca-7b_male</th>\n      <th>alpaca-7b_female</th>\n      <th>alpaca-7b_diverse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>True</td>\n      <td>0.266465</td>\n      <td>0.712365</td>\n      <td>0.021160</td>\n      <td>5.535</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama2-7b</td>\n      <td>True</td>\n      <td>0.105650</td>\n      <td>0.873290</td>\n      <td>0.021050</td>\n      <td>89.265</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.625040</td>\n      <td>0.360585</td>\n      <td>0.014365</td>\n      <td>5.535</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.221395</td>\n      <td>0.738435</td>\n      <td>0.040150</td>\n      <td>89.265</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.796830</td>\n      <td>0.201195</td>\n      <td>0.001975</td>\n      <td>5.535</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>True</td>\n      <td>0.019800</td>\n      <td>0.038490</td>\n      <td>0.941720</td>\n      <td>89.265</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.708945</td>\n      <td>0.255865</td>\n      <td>0.035170</td>\n      <td>5.535</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.353300</td>\n      <td>0.593430</td>\n      <td>0.053275</td>\n      <td>89.265</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama3-8b-instruct</td>\n      <td>True</td>\n      <td>0.010045</td>\n      <td>0.026320</td>\n      <td>0.963625</td>\n      <td>5.535</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama3-8b-instruct</td>\n      <td>True</td>\n      <td>0.007415</td>\n      <td>0.021535</td>\n      <td>0.971060</td>\n      <td>89.265</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>84 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:19.149918Z",
     "start_time": "2024-06-02T01:08:19.142531Z"
    }
   },
   "id": "1b950e2327d38bf6",
   "execution_count": 285
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_plain = pd.read_csv(os.path.join(results_dir, 'plain.csv'))\n",
    "df_conv = pd.read_csv(os.path.join(results_dir, 'conversation.csv'))\n",
    "\n",
    "# if any column starts with a space, remove it\n",
    "df_plain.columns = df_plain.columns.str.strip()\n",
    "df_conv.columns = df_conv.columns.str.strip()\n",
    "\n",
    "df = pd.concat([df_plain, df_conv])\n",
    "for model, group_df in df.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'non_gq.csv'), index=False)\n",
    "\n",
    "    # Optional: Print a message to indicate the file has been saved\n",
    "    # print(f\"Saved {model} non_gq.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:19.327245Z",
     "start_time": "2024-06-02T01:08:19.314389Z"
    }
   },
   "id": "a649ed31f1e5571c",
   "execution_count": 286
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation  female_ratio  \\\n0              False   llama3-8b-instruct         False         5.535   \n1               True   llama3-8b-instruct         False        89.265   \n2              False           mistral-7b         False         5.535   \n3               True           mistral-7b         False        89.265   \n4              False            llama2-7b         False         5.535   \n..               ...                  ...           ...           ...   \n79              True  mistral-7b-instruct          True        89.265   \n80             False       llama2-7b-chat          True         5.535   \n81              True       llama2-7b-chat          True        89.265   \n82             False            llama3-8b          True         5.535   \n83              True            llama3-8b          True        89.265   \n\n    prompt_id      male    female   diverse  alpaca-7b_male_met-met  \\\n0         0.0  0.898010  0.049103  0.052882                     NaN   \n1         0.0  0.099750  0.857733  0.042522                     NaN   \n2         1.0  0.773295  0.193120  0.033583                     NaN   \n3         1.0  0.289362  0.670940  0.039702                     NaN   \n4         0.0  0.902528  0.083492  0.013972                     NaN   \n..        ...       ...       ...       ...                     ...   \n79        4.0  0.030102  0.417688  0.552205                     NaN   \n80        2.0  0.551020  0.015597  0.433387                     NaN   \n81        2.0  0.044227  0.587288  0.368485                     NaN   \n82        0.0  0.776022  0.125278  0.098695                     NaN   \n83        0.0  0.233245  0.651827  0.114928                     NaN   \n\n    alpaca-7b_male_friend  alpaca-7b_male_talk-met  alpaca-7b_female_met-met  \\\n0                     NaN                      NaN                       NaN   \n1                     NaN                      NaN                       NaN   \n2                     NaN                      NaN                       NaN   \n3                     NaN                      NaN                       NaN   \n4                     NaN                      NaN                       NaN   \n..                    ...                      ...                       ...   \n79                    NaN                      NaN                       NaN   \n80                    NaN                      NaN                       NaN   \n81                    NaN                      NaN                       NaN   \n82                    NaN                      NaN                       NaN   \n83                    NaN                      NaN                       NaN   \n\n    alpaca-7b_female_friend  alpaca-7b_female_talk-met  \\\n0                       NaN                        NaN   \n1                       NaN                        NaN   \n2                       NaN                        NaN   \n3                       NaN                        NaN   \n4                       NaN                        NaN   \n..                      ...                        ...   \n79                      NaN                        NaN   \n80                      NaN                        NaN   \n81                      NaN                        NaN   \n82                      NaN                        NaN   \n83                      NaN                        NaN   \n\n    alpaca-7b_diverse_met-met  alpaca-7b_diverse_friend  \\\n0                         NaN                       NaN   \n1                         NaN                       NaN   \n2                         NaN                       NaN   \n3                         NaN                       NaN   \n4                         NaN                       NaN   \n..                        ...                       ...   \n79                        NaN                       NaN   \n80                        NaN                       NaN   \n81                        NaN                       NaN   \n82                        NaN                       NaN   \n83                        NaN                       NaN   \n\n    alpaca-7b_diverse_talk-met  \n0                          NaN  \n1                          NaN  \n2                          NaN  \n3                          NaN  \n4                          NaN  \n..                         ...  \n79                         NaN  \n80                         NaN  \n81                         NaN  \n82                         NaN  \n83                         NaN  \n\n[168 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>female_ratio</th>\n      <th>prompt_id</th>\n      <th>male</th>\n      <th>female</th>\n      <th>diverse</th>\n      <th>alpaca-7b_male_met-met</th>\n      <th>alpaca-7b_male_friend</th>\n      <th>alpaca-7b_male_talk-met</th>\n      <th>alpaca-7b_female_met-met</th>\n      <th>alpaca-7b_female_friend</th>\n      <th>alpaca-7b_female_talk-met</th>\n      <th>alpaca-7b_diverse_met-met</th>\n      <th>alpaca-7b_diverse_friend</th>\n      <th>alpaca-7b_diverse_talk-met</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>5.535</td>\n      <td>0.0</td>\n      <td>0.898010</td>\n      <td>0.049103</td>\n      <td>0.052882</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>89.265</td>\n      <td>0.0</td>\n      <td>0.099750</td>\n      <td>0.857733</td>\n      <td>0.042522</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>5.535</td>\n      <td>1.0</td>\n      <td>0.773295</td>\n      <td>0.193120</td>\n      <td>0.033583</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>89.265</td>\n      <td>1.0</td>\n      <td>0.289362</td>\n      <td>0.670940</td>\n      <td>0.039702</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>5.535</td>\n      <td>0.0</td>\n      <td>0.902528</td>\n      <td>0.083492</td>\n      <td>0.013972</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>True</td>\n      <td>89.265</td>\n      <td>4.0</td>\n      <td>0.030102</td>\n      <td>0.417688</td>\n      <td>0.552205</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>False</td>\n      <td>llama2-7b-chat</td>\n      <td>True</td>\n      <td>5.535</td>\n      <td>2.0</td>\n      <td>0.551020</td>\n      <td>0.015597</td>\n      <td>0.433387</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>True</td>\n      <td>llama2-7b-chat</td>\n      <td>True</td>\n      <td>89.265</td>\n      <td>2.0</td>\n      <td>0.044227</td>\n      <td>0.587288</td>\n      <td>0.368485</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>False</td>\n      <td>llama3-8b</td>\n      <td>True</td>\n      <td>5.535</td>\n      <td>0.0</td>\n      <td>0.776022</td>\n      <td>0.125278</td>\n      <td>0.098695</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>True</td>\n      <td>llama3-8b</td>\n      <td>True</td>\n      <td>89.265</td>\n      <td>0.0</td>\n      <td>0.233245</td>\n      <td>0.651827</td>\n      <td>0.114928</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>168 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:19.804495Z",
     "start_time": "2024-06-02T01:08:19.801275Z"
    }
   },
   "id": "d34d378bb736b6b5",
   "execution_count": 287
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_gq_plain = pd.read_csv(os.path.join(results_dir, 'genderquestion.csv'))\n",
    "df_gq_conv = pd.read_csv(os.path.join(results_dir, 'genderquestion_conv.csv'))\n",
    "\n",
    "# if any column starts with a space, remove it\n",
    "df_gq_plain.columns = df_gq_plain.columns.str.strip()\n",
    "df_gq_conv.columns = df_gq_conv.columns.str.strip()\n",
    "\n",
    "df_gq = pd.concat([df_gq_plain, df_gq_conv])\n",
    "for model, group_df in df_gq.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'genderquestion.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:20.295132Z",
     "start_time": "2024-06-02T01:08:20.286708Z"
    }
   },
   "id": "90915c22ac13a2ac",
   "execution_count": 288
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation      male    female  \\\n0              False            llama2-7b         False  0.448720  0.498865   \n1               True            llama2-7b         False  0.266260  0.688840   \n2              False           mistral-7b         False  0.621235  0.269070   \n3               True           mistral-7b         False  0.297795  0.634930   \n4              False            llama2-7b         False  0.633945  0.358185   \n..               ...                  ...           ...       ...       ...   \n79              True  mistral-7b-instruct          True  0.019800  0.038490   \n80             False           mistral-7b          True  0.708945  0.255865   \n81              True           mistral-7b          True  0.353300  0.593430   \n82             False   llama3-8b-instruct          True  0.010045  0.026320   \n83              True   llama3-8b-instruct          True  0.007415  0.021535   \n\n     diverse  female_ratio  prompt_id  alpaca-7b_male  alpaca-7b_female  \\\n0   0.052400         5.535        5.0             NaN               NaN   \n1   0.044890        89.265        5.0             NaN               NaN   \n2   0.109715         5.535        4.0             NaN               NaN   \n3   0.067265        89.265        4.0             NaN               NaN   \n4   0.007860         5.535        2.0             NaN               NaN   \n..       ...           ...        ...             ...               ...   \n79  0.941720        89.265        5.0             NaN               NaN   \n80  0.035170         5.535        1.0             NaN               NaN   \n81  0.053275        89.265        1.0             NaN               NaN   \n82  0.963625         5.535        1.0             NaN               NaN   \n83  0.971060        89.265        1.0             NaN               NaN   \n\n    alpaca-7b_diverse  \n0                 NaN  \n1                 NaN  \n2                 NaN  \n3                 NaN  \n4                 NaN  \n..                ...  \n79                NaN  \n80                NaN  \n81                NaN  \n82                NaN  \n83                NaN  \n\n[168 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>male</th>\n      <th>female</th>\n      <th>diverse</th>\n      <th>female_ratio</th>\n      <th>prompt_id</th>\n      <th>alpaca-7b_male</th>\n      <th>alpaca-7b_female</th>\n      <th>alpaca-7b_diverse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.448720</td>\n      <td>0.498865</td>\n      <td>0.052400</td>\n      <td>5.535</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.266260</td>\n      <td>0.688840</td>\n      <td>0.044890</td>\n      <td>89.265</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.621235</td>\n      <td>0.269070</td>\n      <td>0.109715</td>\n      <td>5.535</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.297795</td>\n      <td>0.634930</td>\n      <td>0.067265</td>\n      <td>89.265</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.633945</td>\n      <td>0.358185</td>\n      <td>0.007860</td>\n      <td>5.535</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>True</td>\n      <td>0.019800</td>\n      <td>0.038490</td>\n      <td>0.941720</td>\n      <td>89.265</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.708945</td>\n      <td>0.255865</td>\n      <td>0.035170</td>\n      <td>5.535</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>True</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.353300</td>\n      <td>0.593430</td>\n      <td>0.053275</td>\n      <td>89.265</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>False</td>\n      <td>llama3-8b-instruct</td>\n      <td>True</td>\n      <td>0.010045</td>\n      <td>0.026320</td>\n      <td>0.963625</td>\n      <td>5.535</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>True</td>\n      <td>llama3-8b-instruct</td>\n      <td>True</td>\n      <td>0.007415</td>\n      <td>0.021535</td>\n      <td>0.971060</td>\n      <td>89.265</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>168 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:21.449947Z",
     "start_time": "2024-06-02T01:08:21.444799Z"
    }
   },
   "id": "a9ed47d5a5a8cb7c",
   "execution_count": 289
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the mapping dictionaries\n",
    "model_str_map = {\n",
    "    'llama3-8b': 'Llama3 8B',\n",
    "    'llama3-8b-instruct': 'Llama3 8B (Instruct)',\n",
    "    'mistral-7b': 'Mistral 7B',\n",
    "    'mistral-7b-instruct': 'Mistral 7B (Instruct)',\n",
    "    'llama2-7b': 'Llama2 7B',\n",
    "    'llama2-7b-chat': 'Llama2 7B (Chat)',\n",
    "    # 'alpaca-7b': 'Alpaca 7B',\n",
    "}\n",
    "\n",
    "prompt_id_map = {\n",
    "    0: 'None',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6'\n",
    "}\n",
    "\n",
    "abstraction_levels = {\n",
    "    0: '',\n",
    "    1: 'High',\n",
    "    2: 'High',\n",
    "    3: 'Med.',\n",
    "    4: 'Med.',\n",
    "    5: 'Low',\n",
    "    6: 'Low'\n",
    "}\n",
    "\n",
    "abs_order = ['', 'High', 'Med.', 'Low']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:45:41.897097Z",
     "start_time": "2024-06-02T01:45:41.887230Z"
    }
   },
   "id": "7f353fee7e286d0c",
   "execution_count": 296
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/aggregated_results.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/2488884905.py:60: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n"
     ]
    }
   ],
   "source": [
    " # Update this to your results directory\n",
    "models = list(model_str_map.keys())\n",
    "\n",
    "output_tex_file = os.path.join(results_dir, 'aggregated_results.tex')\n",
    "\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(r'\\onecolumn')\n",
    "    for model in models:\n",
    "        model_name = model.replace('-', '')\n",
    "        model_description = model_str_map[model]\n",
    "\n",
    "        f_out.write(r'\\subsection{' + model_description + '}\\n')\n",
    "\n",
    "        for csv_file, (caption, label_suffix) in [('genderquestion.csv', ('Probability of gender expressions for task prompt number one. ``ID\\'\\' refers to the id of the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'genderquestion')),\n",
    "                                                  ('non_gq.csv', ('Aggregated results for task prompts two to four. ``ID\\'\\' refers to the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'nongq'))]:\n",
    "            \n",
    "            \n",
    "            # Load the CSV file into a DataFrame\n",
    "            df_path = os.path.join(results_dir, model, csv_file)\n",
    "            df = pd.read_csv(df_path)\n",
    "\n",
    "            # Add the abstraction level column to the DataFrame\n",
    "            df['Abs.'] = df['prompt_id'].map(abstraction_levels)\n",
    "\n",
    "            # Calculate means for each combination of prompt_id, conversation, and female_dominated\n",
    "            grouped_df = df.groupby(['Abs.', 'model', 'prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "            model = grouped_df['model'].unique()[0]\n",
    "\n",
    "            # Drop the 'model' column\n",
    "            model_df = grouped_df.drop(columns=['model'])\n",
    "                        # Sort by Abs. and prompt_id to ensure correct order\n",
    "            model_df['prompt_id'] = model_df['prompt_id'].astype(int)\n",
    "            model_df['Abs.'] = pd.Categorical(model_df['Abs.'], categories=abs_order, ordered=True)\n",
    "            model_df = model_df.sort_values(by=['Abs.', 'prompt_id'])\n",
    "\n",
    "            latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){3-8} \\cmidrule(lr){9-14}\n",
    "    & & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-11} \\cmidrule(lr){12-14}\n",
    "        Abs. & ID & M & F & D & M & F & D & M & F & D & M & F & D\\\\\n",
    "        \\midrule\n",
    "'''\n",
    "\n",
    "            # Sort by prompt_id to ensure order from None to 6\n",
    "            model_df['prompt_id'] = model_df['prompt_id'].astype(int)\n",
    "            model_df = model_df.sort_values(by=['Abs.','prompt_id'])\n",
    "\n",
    "            previous_abs_level = None\n",
    "\n",
    "            for abs_level, abs_group in model_df.groupby('Abs.'):\n",
    "                if previous_abs_level is not None:\n",
    "                    latex_table += \"        \\\\midrule\\n\"\n",
    "                for prompt_id, prompt_group in abs_group.groupby('prompt_id'):\n",
    "                    id_label = 'None' if prompt_id == 0 else str(prompt_id)\n",
    "                    row_prefix = f\"        {abs_level if prompt_id in [0,2,4,6] else ''} & {id_label} & \"\n",
    "\n",
    "                    no_dialogue_fd = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == True)]\n",
    "                    no_dialogue_md = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == False)]\n",
    "                    dialogue_fd = prompt_group[(prompt_group['conversation'] == True) & (prompt_group['female_dominated'] == True)]\n",
    "                    dialogue_md = prompt_group[(prompt_group['conversation'] == True) & (prompt_group['female_dominated'] == False)]\n",
    "\n",
    "                    row = row_prefix\n",
    "\n",
    "                    if not no_dialogue_fd.empty:\n",
    "                        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not no_dialogue_md.empty:\n",
    "                        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not dialogue_fd.empty:\n",
    "                        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not dialogue_md.empty:\n",
    "                        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "                    else:\n",
    "                        row += \" & & \"\n",
    "\n",
    "                    row += r\"\\\\\"\n",
    "                    latex_table += row + \"\\n\"\n",
    "\n",
    "                if abs_level != '':  # Add averages for all except \"None\"\n",
    "                    avg_row_prefix = f\"         & \\\\textbf{{Avg}} & \"\n",
    "\n",
    "                    avg_no_dialogue_fd = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_no_dialogue_md = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_dialogue_fd = abs_group[(abs_group['conversation'] == True) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_dialogue_md = abs_group[(abs_group['conversation'] == True) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "\n",
    "                    avg_row = avg_row_prefix\n",
    "\n",
    "                    if not avg_no_dialogue_fd.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & & \"\n",
    "\n",
    "                    if not avg_no_dialogue_md.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & & \"\n",
    "\n",
    "                    if not avg_dialogue_fd.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & & \"\n",
    "\n",
    "                    if not avg_dialogue_md.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_md['diverse']*100:.1f}\\\\%}} \"\n",
    "                    else:\n",
    "                        avg_row += \" & & \"\n",
    "\n",
    "                    avg_row += r\"\\\\\"\n",
    "                    latex_table += avg_row + \"\\n\"\n",
    "\n",
    "                previous_abs_level = abs_level\n",
    "\n",
    "            latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{''' + caption + r'''}\n",
    "\\label{tab:''' + label_suffix + r'''_''' + model_name + r'''}\n",
    "\\end{table*}\n",
    "\n",
    "'''\n",
    "\n",
    "            f_out.write(latex_table)\n",
    "        f_out.write('\\\\clearpage\\n\\n')\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T15:42:30.930017Z",
     "start_time": "2024-06-02T15:42:30.781987Z"
    }
   },
   "id": "262f5966f8e50558",
   "execution_count": 302
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/aggregated_results_no_diag.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_48870/1537791341.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n"
     ]
    }
   ],
   "source": [
    " # Update this to your results directory\n",
    "models = list(model_str_map.keys())\n",
    "\n",
    "output_tex_file = os.path.join(results_dir, 'aggregated_results_no_diag.tex')\n",
    "\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(r'\\onecolumn')\n",
    "    for model in models:\n",
    "        model_name = model.replace('-', '')\n",
    "        model_description = model_str_map[model]\n",
    "\n",
    "        f_out.write(r'\\subsection{' + model_description + '}\\n')\n",
    "\n",
    "        for csv_file, (caption, label_suffix) in [('genderquestion.csv', ('Result for explicit bias (task prompt 1). ``ID\\'\\' refers to the id of the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'genderquestion')),\n",
    "                                                  ('non_gq.csv', ('Result for explicit bias (average over task prompt 2-4). ``ID\\'\\' refers to the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'nongq'))]:\n",
    "            \n",
    "            \n",
    "            # Load the CSV file into a DataFrame\n",
    "            df_path = os.path.join(results_dir, model, csv_file)\n",
    "            df = pd.read_csv(df_path)\n",
    "\n",
    "            # Add the abstraction level column to the DataFrame\n",
    "            df['Abs.'] = df['prompt_id'].map(abstraction_levels)\n",
    "\n",
    "            # Calculate means for each combination of prompt_id, conversation, and female_dominated\n",
    "            grouped_df = df.groupby(['Abs.', 'model', 'prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "            model = grouped_df['model'].unique()[0]\n",
    "\n",
    "            # Drop the 'model' column\n",
    "            model_df = grouped_df.drop(columns=['model'])\n",
    "                        # Sort by Abs. and prompt_id to ensure correct order\n",
    "            model_df['prompt_id'] = model_df['prompt_id'].astype(int)\n",
    "            model_df['Abs.'] = pd.Categorical(model_df['Abs.'], categories=abs_order, ordered=True)\n",
    "            model_df = model_df.sort_values(by=['Abs.', 'prompt_id'])\n",
    "\n",
    "            latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c}\n",
    "    \\toprule\n",
    "    & &\\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){3-5} \\cmidrule(lr){6-8}\n",
    "        Abs. & ID & M & F & D & M & F & D \\\\\n",
    "        \\midrule\n",
    "'''\n",
    "\n",
    "            # Sort by prompt_id to ensure order from None to 6\n",
    "            model_df['prompt_id'] = model_df['prompt_id'].astype(int)\n",
    "            model_df = model_df.sort_values(by=['Abs.','prompt_id'])\n",
    "\n",
    "            previous_abs_level = None\n",
    "\n",
    "            for abs_level, abs_group in model_df.groupby('Abs.'):\n",
    "                if previous_abs_level is not None:\n",
    "                    latex_table += \"        \\\\midrule\\n\"\n",
    "                for prompt_id, prompt_group in abs_group.groupby('prompt_id'):\n",
    "                    id_label = 'None' if prompt_id == 0 else str(prompt_id)\n",
    "                    row_prefix = f\"        {abs_level if prompt_id in [0,2,4,6] else ''} & {id_label} & \"\n",
    "\n",
    "                    no_dialogue_fd = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == True)]\n",
    "                    no_dialogue_md = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == False)]\n",
    "\n",
    "\n",
    "                    row = row_prefix\n",
    "\n",
    "                    if not no_dialogue_fd.empty:\n",
    "                        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not no_dialogue_md.empty:\n",
    "                        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "                    else:\n",
    "                        row += \" & & \"\n",
    "\n",
    "\n",
    "                    row += r\"\\\\\"\n",
    "                    latex_table += row + \"\\n\"\n",
    "\n",
    "                if abs_level != '':  # Add averages for all except \"None\"\n",
    "                    avg_row_prefix = f\"         & \\\\textbf{{Avg}} & \"\n",
    "\n",
    "                    avg_no_dialogue_fd = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_no_dialogue_md = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "\n",
    "                    avg_row = avg_row_prefix\n",
    "\n",
    "                    if not avg_no_dialogue_fd.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & &\"\n",
    "\n",
    "                    if not avg_no_dialogue_md.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['diverse']*100:.1f}\\\\%}}\"\n",
    "                    else:\n",
    "                        avg_row += \" & & \"\n",
    "\n",
    "\n",
    "\n",
    "                    avg_row += r\"\\\\\"\n",
    "                    latex_table += avg_row + \"\\n\"\n",
    "\n",
    "                previous_abs_level = abs_level\n",
    "\n",
    "            latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{''' + caption + r'''}\n",
    "\\label{tab:''' + label_suffix + r'''_''' + model_name + r'''}\n",
    "\\end{table*}\n",
    "\n",
    "'''\n",
    "\n",
    "            f_out.write(latex_table)\n",
    "        f_out.write('\\\\clearpage\\n\\n')\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T15:52:02.536890Z",
     "start_time": "2024-06-02T15:52:02.434420Z"
    }
   },
   "id": "4d9ca328379ec1c3",
   "execution_count": 308
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/results/alpaca-7b/genderquestion.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[292], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model, file_name \u001B[38;5;129;01min\u001B[39;00m product(models, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenderquestion.csv\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# Load the CSV file into a DataFrame\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     df_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(results_dir, model, file_name)\n\u001B[0;32m----> 7\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     df_0\u001B[38;5;241m.\u001B[39mappend(df[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprompt_id\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     10\u001B[0m df_0 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(df_0)\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/results/alpaca-7b/genderquestion.csv'"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:23.227011Z",
     "start_time": "2024-06-02T01:08:23.183488Z"
    }
   },
   "id": "1e1bbdb4c5b87be3",
   "execution_count": 292
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/explicit_default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == True)]\n",
    "    dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_fd.empty:\n",
    "        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_md.empty:\n",
    "        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on explicit bias (Task prompt 1).}\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'explicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:11.676678Z",
     "start_time": "2024-06-02T01:08:11.661429Z"
    }
   },
   "id": "d39208ea5f1d3a9c",
   "execution_count": 277
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/implicit_default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == True)]\n",
    "    dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_fd.empty:\n",
    "        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_md.empty:\n",
    "        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (Average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:11.924585Z",
     "start_time": "2024-06-02T01:08:11.908215Z"
    }
   },
   "id": "2b84e9f84c53cc5a",
   "execution_count": 278
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/results/alpaca-7b/genderquestion.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[279], line 28\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model, file_name \u001B[38;5;129;01min\u001B[39;00m product(models, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenderquestion.csv\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;66;03m# Load the CSV file into a DataFrame\u001B[39;00m\n\u001B[1;32m     27\u001B[0m     df_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(results_dir, model, file_name)\n\u001B[0;32m---> 28\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m     df_0\u001B[38;5;241m.\u001B[39mappend(df[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprompt_id\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     31\u001B[0m df_0 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(df_0)\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/results/alpaca-7b/genderquestion.csv'"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "models = [\n",
    "    'llama3-8b', 'llama3-8b-instruct', 'mistral-7b', \n",
    "    'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-chat',\n",
    "    'alpaca-7b'\n",
    "    \n",
    "]\n",
    "\n",
    "model_str_map = {\n",
    "    'llama3-8b': 'Llama3 8B',\n",
    "    'llama3-8b-instruct': 'Llama3 8B (Instruct)',\n",
    "    'mistral-7b': 'Mistral 7B',\n",
    "    'mistral-7b-instruct': 'Mistral 7B (Instruct)',\n",
    "    'llama2-7b': 'Llama2 7B',\n",
    "    'llama2-7b-chat': 'Llama2 7B (Chat)',\n",
    "    'alpaca-7b': 'Alpaca 7B'\n",
    "}\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on explicit bias (task prompt 1).}\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'explicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T01:08:12.712704Z",
     "start_time": "2024-06-02T01:08:12.608254Z"
    }
   },
   "id": "cfb988ea0fb8997a",
   "execution_count": 279
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/implicit_default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "models = [\n",
    "    'llama3-8b', 'llama3-8b-instruct', 'mistral-7b', \n",
    "    'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-chat'\n",
    "]\n",
    "\n",
    "model_str_map = {\n",
    "    'llama3-8b': 'Llama3 8B',\n",
    "    'llama3-8b-instruct': 'Llama3 8B (Instruct)',\n",
    "    'mistral-7b': 'Mistral 7B',\n",
    "    'mistral-7b-instruct': 'Mistral 7B (Instruct)',\n",
    "    'llama2-7b': 'Llama2 7B',\n",
    "    'llama2-7b-chat': 'Llama2 7B (Chat)'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T00:54:36.761021Z",
     "start_time": "2024-06-02T00:54:36.746825Z"
    }
   },
   "id": "2cb37de0ed62e51a",
   "execution_count": 274
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "173a7a330f58bf2e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
