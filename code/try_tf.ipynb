{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, pipeline\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "input_dir = '../data/inputs'\n",
    "output_dir = '../data/outputs/s0'\n",
    "results_dir = '../data/results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.129215Z",
     "start_time": "2024-06-05T17:00:43.335050Z"
    }
   },
   "id": "f44b57b8ed707cad",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_str_map = {\n",
    "    'llama3-8b': 'Llama3 8B',\n",
    "    'llama3-8b-instruct': 'Llama3 8B (Instruct)',\n",
    "    'mistral-7b': 'Mistral 7B',\n",
    "    'mistral-7b-instruct': 'Mistral 7B (Instruct)',\n",
    "    'llama2-7b': 'Llama2 7B',\n",
    "    'llama2-7b-instruct': 'Llama2 7B (Instruct)',\n",
    "}\n",
    "model_strs = ['llama3-8b', 'llama3-8b-instruct', 'mistral-7b', 'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct']\n",
    "model_strs = sorted(model_strs, key=len, reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.133625Z",
     "start_time": "2024-06-05T17:00:49.130293Z"
    }
   },
   "id": "18db9a6c65c4e55f",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "female_ratios = pd.read_csv(os.path.join(input_dir, 'female_ratios.csv'))\n",
    "# for model in  llama3-8b llama3-8b-instruct mistral-7b mistral-7b-instruct llama2-7b llama2-7b-chat\n",
    "\n",
    "\n",
    "prompt_ids = ['none','low-1','low-2','medium-3','medium-4','high-5','high-6']\n",
    "prompt_id_mapping = {pid: idx for idx, pid in enumerate(prompt_ids)}\n",
    "\n",
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if \"conv\" not in f and \"gender\" not in f and 'gpt2' not in f:\n",
    "    # if 'conversation.csv' in f:\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "    # if 'conversation.csv' in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['debiasing_prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            # make sure the three columns add up to 1\n",
    "            # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "            # \n",
    "            # Optionally, drop the original detailed columns if only averages are needed\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'implicit.csv'), index=False)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.306808Z",
     "start_time": "2024-06-05T17:00:49.135664Z"
    }
   },
   "id": "9026f5b07325c14a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df_list = []\n",
    "# for f in os.listdir(output_dir):\n",
    "#     if 'conversation.csv' in f:\n",
    "#         df = pd.read_csv(os.path.join(output_dir, f))\n",
    "#         df = pd.merge(df,female_ratios,on='job')\n",
    "#         df = df.drop(columns=['job','Unnamed: 0'])\n",
    "# \n",
    "#         df['female_dominated'] = df['female_ratio'] > 50\n",
    "#         # Extract prompt ID from filename\n",
    "#         prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "#         prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "#         df['debiasing_prompt_id'] = prompt_id\n",
    "#         \n",
    "#                 # Extract model from filename\n",
    "#         model_str = next((model for model in model_strs if model in f), None)\n",
    "#         df['model'] = model_str\n",
    "#         df['conversation'] = 'conv' in f\n",
    "# \n",
    "#         # Remove model name from other column names\n",
    "#         if model_str:\n",
    "#             df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "# \n",
    "#         \n",
    "#         # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "#         numeric_cols = df.select_dtypes(include='number').columns\n",
    "#         grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "#     \n",
    "#         if 'male_met-met' in df.columns:\n",
    "#             col_ends = ['met-met', 'friend', 'talk-met']\n",
    "#             # Compute averages for male, female, and diverse columns\n",
    "#             male_cols = ['male_' + end for end in col_ends]\n",
    "#             female_cols = ['female_' + end for end in col_ends]\n",
    "#             diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "# \n",
    "#     \n",
    "#             grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "#             grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "#             grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "#             # make sure the three columns add up to 1\n",
    "#             # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "#             # \n",
    "#             # Optionally, drop the original detailed columns if only averages are needed\n",
    "#             grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "# \n",
    "#             \n",
    "#         df_list.append(grouped_df)\n",
    "#     # concat all the dataframes\n",
    "# df = pd.concat(df_list)\n",
    "# df.to_csv(os.path.join(results_dir, 'conversation.csv'), index=False)\n",
    "#     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.311622Z",
     "start_time": "2024-06-05T17:00:49.308059Z"
    }
   },
   "id": "e751480d2b8070f5",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if 'genderquestion.csv' in f and 'gpt2' not in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['debiasing_prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            # make sure the three columns add up to 1\n",
    "            # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "            # \n",
    "            # Optionally, drop the original detailed columns if only averages are needed\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'genderquestion.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.404820Z",
     "start_time": "2024-06-05T17:00:49.313110Z"
    }
   },
   "id": "6929333781b2efd3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df_list = []\n",
    "# for f in os.listdir(output_dir):\n",
    "#     if 'genderquestion_conv.csv' in f:\n",
    "#         df = pd.read_csv(os.path.join(output_dir, f))\n",
    "#         df = pd.merge(df,female_ratios,on='job')\n",
    "#         df = df.drop(columns=['job','Unnamed: 0'])\n",
    "#          \n",
    "# \n",
    "#         df['female_dominated'] = df['female_ratio'] > 50\n",
    "#         # Extract prompt ID from filename\n",
    "#         prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "#         prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "#         df['debiasing_prompt_id'] = prompt_id\n",
    "#         \n",
    "#                 # Extract model from filename\n",
    "#         model_str = next((model for model in model_strs if model in f), None)\n",
    "#         df['model'] = model_str\n",
    "#         df['conversation'] = 'conv' in f\n",
    "# \n",
    "#         # Remove model name from other column names\n",
    "#         if model_str:\n",
    "#             df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "# \n",
    "#         \n",
    "#         # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "#         numeric_cols = df.select_dtypes(include='number').columns\n",
    "#         grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "#     \n",
    "#         if 'male_met-met' in df.columns:\n",
    "#             col_ends = ['met-met', 'friend', 'talk-met']\n",
    "#             # Compute averages for male, female, and diverse columns\n",
    "#             male_cols = ['male_' + end for end in col_ends]\n",
    "#             female_cols = ['female_' + end for end in col_ends]\n",
    "#             diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "# \n",
    "#     \n",
    "#             grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "#             grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "#             grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "#             # make sure the three columns add up to 1\n",
    "#             # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "#             # \n",
    "#             # Optionally, drop the original detailed columns if only averages are needed\n",
    "#             grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "# \n",
    "#             \n",
    "#         df_list.append(grouped_df)\n",
    "#     # concat all the dataframes\n",
    "# df = pd.concat(df_list)\n",
    "# df.to_csv(os.path.join(results_dir, 'genderquestion_conv.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.409268Z",
     "start_time": "2024-06-05T17:00:49.405069Z"
    }
   },
   "id": "97353b98d7dd6a5e",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['llama2-7b-instruct', 'llama2-7b', 'mistral-7b',\n       'llama3-8b-instruct', 'llama3-8b', 'mistral-7b-instruct'],\n      dtype=object)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.411503Z",
     "start_time": "2024-06-05T17:00:49.408867Z"
    }
   },
   "id": "e8b094b1d58fc460",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation      male    female  \\\n0              False   llama2-7b-instruct         False  0.160320  0.326205   \n1               True   llama2-7b-instruct         False  0.037030  0.479560   \n0              False            llama2-7b         False  0.122790  0.349435   \n1               True            llama2-7b         False  0.079400  0.437210   \n0              False           mistral-7b         False  0.106725  0.264820   \n..               ...                  ...           ...       ...       ...   \n1               True  mistral-7b-instruct         False  0.013820  0.477810   \n0              False   llama3-8b-instruct         False  0.341940  0.455815   \n1               True   llama3-8b-instruct         False  0.201600  0.627875   \n0              False   llama2-7b-instruct         False  0.360990  0.483530   \n1               True   llama2-7b-instruct         False  0.147750  0.690525   \n\n     diverse  male_prob  female_prob  diverse_prob  female_ratio  \\\n0   0.513470   0.218423     0.457142      0.735297         5.535   \n1   0.483405   0.053856     0.701239      0.720095        89.265   \n0   0.527775   0.094970     0.272386      0.413602         5.535   \n1   0.483395   0.065413     0.355249      0.392135        89.265   \n0   0.628440   0.042873     0.106485      0.255048         5.535   \n..       ...        ...          ...           ...           ...   \n1   0.508365   0.010989     0.406565      0.354256        89.265   \n0   0.202255   0.273480     0.347876      0.145744         5.535   \n1   0.170530   0.178444     0.559818      0.132865        89.265   \n0   0.155480   0.447868     0.600647      0.193340         5.535   \n1   0.161720   0.186738     0.872850      0.203773        89.265   \n\n    debiasing_prompt_id  \n0                   5.0  \n1                   5.0  \n0                   5.0  \n1                   5.0  \n0                   4.0  \n..                  ...  \n1                   4.0  \n0                   4.0  \n1                   4.0  \n0                   3.0  \n1                   3.0  \n\n[84 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>male</th>\n      <th>female</th>\n      <th>diverse</th>\n      <th>male_prob</th>\n      <th>female_prob</th>\n      <th>diverse_prob</th>\n      <th>female_ratio</th>\n      <th>debiasing_prompt_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.160320</td>\n      <td>0.326205</td>\n      <td>0.513470</td>\n      <td>0.218423</td>\n      <td>0.457142</td>\n      <td>0.735297</td>\n      <td>5.535</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.037030</td>\n      <td>0.479560</td>\n      <td>0.483405</td>\n      <td>0.053856</td>\n      <td>0.701239</td>\n      <td>0.720095</td>\n      <td>89.265</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.122790</td>\n      <td>0.349435</td>\n      <td>0.527775</td>\n      <td>0.094970</td>\n      <td>0.272386</td>\n      <td>0.413602</td>\n      <td>5.535</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.079400</td>\n      <td>0.437210</td>\n      <td>0.483395</td>\n      <td>0.065413</td>\n      <td>0.355249</td>\n      <td>0.392135</td>\n      <td>89.265</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.106725</td>\n      <td>0.264820</td>\n      <td>0.628440</td>\n      <td>0.042873</td>\n      <td>0.106485</td>\n      <td>0.255048</td>\n      <td>5.535</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.013820</td>\n      <td>0.477810</td>\n      <td>0.508365</td>\n      <td>0.010989</td>\n      <td>0.406565</td>\n      <td>0.354256</td>\n      <td>89.265</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>0.341940</td>\n      <td>0.455815</td>\n      <td>0.202255</td>\n      <td>0.273480</td>\n      <td>0.347876</td>\n      <td>0.145744</td>\n      <td>5.535</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>0.201600</td>\n      <td>0.627875</td>\n      <td>0.170530</td>\n      <td>0.178444</td>\n      <td>0.559818</td>\n      <td>0.132865</td>\n      <td>89.265</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.360990</td>\n      <td>0.483530</td>\n      <td>0.155480</td>\n      <td>0.447868</td>\n      <td>0.600647</td>\n      <td>0.193340</td>\n      <td>5.535</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.147750</td>\n      <td>0.690525</td>\n      <td>0.161720</td>\n      <td>0.186738</td>\n      <td>0.872850</td>\n      <td>0.203773</td>\n      <td>89.265</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>84 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.421027Z",
     "start_time": "2024-06-05T17:00:49.411297Z"
    }
   },
   "id": "1b950e2327d38bf6",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_plain = pd.read_csv(os.path.join(results_dir, 'implicit.csv'))\n",
    "df_conv = pd.read_csv(os.path.join(results_dir, 'conversation.csv'))\n",
    "\n",
    "# if any column starts with a space, remove it\n",
    "df_plain.columns = df_plain.columns.str.strip()\n",
    "df_conv.columns = df_conv.columns.str.strip()\n",
    "\n",
    "df = pd.concat([df_plain, df_conv])\n",
    "for model, group_df in df.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'non_gq.csv'), index=False)\n",
    "\n",
    "    # Optional: Print a message to indicate the file has been saved\n",
    "    # print(f\"Saved {model} non_gq.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.438789Z",
     "start_time": "2024-06-05T17:00:49.419979Z"
    }
   },
   "id": "a649ed31f1e5571c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation  male_met-met_prob  \\\n0              False   llama3-8b-instruct         False           0.364136   \n1               True   llama3-8b-instruct         False           0.034089   \n2              False           mistral-7b         False           0.266743   \n3               True           mistral-7b         False           0.092805   \n4              False            llama2-7b         False           0.219073   \n..               ...                  ...           ...                ...   \n79              True  mistral-7b-instruct          True                NaN   \n80             False       llama2-7b-chat          True                NaN   \n81              True       llama2-7b-chat          True                NaN   \n82             False            llama3-8b          True                NaN   \n83              True            llama3-8b          True                NaN   \n\n    female_met-met_prob  diverse_met-met_prob  male_friend_prob  \\\n0              0.016518              0.018025          0.804092   \n1              0.418602              0.015471          0.052903   \n2              0.080521              0.016623          0.340629   \n3              0.235823              0.018372          0.141831   \n4              0.026362              0.004307          0.410796   \n..                  ...                   ...               ...   \n79                  NaN                   NaN               NaN   \n80                  NaN                   NaN               NaN   \n81                  NaN                   NaN               NaN   \n82                  NaN                   NaN               NaN   \n83                  NaN                   NaN               NaN   \n\n    female_friend_prob  diverse_friend_prob  male_talk-met_prob  ...  \\\n0             0.056074             0.004254            0.844441  ...   \n1             0.862482             0.003430            0.088654  ...   \n2             0.118369             0.010341            0.782206  ...   \n3             0.349621             0.009947            0.321056  ...   \n4             0.037691             0.004513            0.830831  ...   \n..                 ...                  ...                 ...  ...   \n79                 NaN                  NaN                 NaN  ...   \n80                 NaN                  NaN                 NaN  ...   \n81                 NaN                  NaN                 NaN  ...   \n82                 NaN                  NaN                 NaN  ...   \n83                 NaN                  NaN                 NaN  ...   \n\n    prompt_id  alpaca-7b_male_met-met  alpaca-7b_male_friend  \\\n0         NaN                     NaN                    NaN   \n1         NaN                     NaN                    NaN   \n2         NaN                     NaN                    NaN   \n3         NaN                     NaN                    NaN   \n4         NaN                     NaN                    NaN   \n..        ...                     ...                    ...   \n79        4.0                     NaN                    NaN   \n80        2.0                     NaN                    NaN   \n81        2.0                     NaN                    NaN   \n82        0.0                     NaN                    NaN   \n83        0.0                     NaN                    NaN   \n\n    alpaca-7b_male_talk-met  alpaca-7b_female_met-met  \\\n0                       NaN                       NaN   \n1                       NaN                       NaN   \n2                       NaN                       NaN   \n3                       NaN                       NaN   \n4                       NaN                       NaN   \n..                      ...                       ...   \n79                      NaN                       NaN   \n80                      NaN                       NaN   \n81                      NaN                       NaN   \n82                      NaN                       NaN   \n83                      NaN                       NaN   \n\n    alpaca-7b_female_friend  alpaca-7b_female_talk-met  \\\n0                       NaN                        NaN   \n1                       NaN                        NaN   \n2                       NaN                        NaN   \n3                       NaN                        NaN   \n4                       NaN                        NaN   \n..                      ...                        ...   \n79                      NaN                        NaN   \n80                      NaN                        NaN   \n81                      NaN                        NaN   \n82                      NaN                        NaN   \n83                      NaN                        NaN   \n\n    alpaca-7b_diverse_met-met  alpaca-7b_diverse_friend  \\\n0                         NaN                       NaN   \n1                         NaN                       NaN   \n2                         NaN                       NaN   \n3                         NaN                       NaN   \n4                         NaN                       NaN   \n..                        ...                       ...   \n79                        NaN                       NaN   \n80                        NaN                       NaN   \n81                        NaN                       NaN   \n82                        NaN                       NaN   \n83                        NaN                       NaN   \n\n    alpaca-7b_diverse_talk-met  \n0                          NaN  \n1                          NaN  \n2                          NaN  \n3                          NaN  \n4                          NaN  \n..                         ...  \n79                         NaN  \n80                         NaN  \n81                         NaN  \n82                         NaN  \n83                         NaN  \n\n[168 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>male_met-met_prob</th>\n      <th>female_met-met_prob</th>\n      <th>diverse_met-met_prob</th>\n      <th>male_friend_prob</th>\n      <th>female_friend_prob</th>\n      <th>diverse_friend_prob</th>\n      <th>male_talk-met_prob</th>\n      <th>...</th>\n      <th>prompt_id</th>\n      <th>alpaca-7b_male_met-met</th>\n      <th>alpaca-7b_male_friend</th>\n      <th>alpaca-7b_male_talk-met</th>\n      <th>alpaca-7b_female_met-met</th>\n      <th>alpaca-7b_female_friend</th>\n      <th>alpaca-7b_female_talk-met</th>\n      <th>alpaca-7b_diverse_met-met</th>\n      <th>alpaca-7b_diverse_friend</th>\n      <th>alpaca-7b_diverse_talk-met</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>0.364136</td>\n      <td>0.016518</td>\n      <td>0.018025</td>\n      <td>0.804092</td>\n      <td>0.056074</td>\n      <td>0.004254</td>\n      <td>0.844441</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>0.034089</td>\n      <td>0.418602</td>\n      <td>0.015471</td>\n      <td>0.052903</td>\n      <td>0.862482</td>\n      <td>0.003430</td>\n      <td>0.088654</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.266743</td>\n      <td>0.080521</td>\n      <td>0.016623</td>\n      <td>0.340629</td>\n      <td>0.118369</td>\n      <td>0.010341</td>\n      <td>0.782206</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.092805</td>\n      <td>0.235823</td>\n      <td>0.018372</td>\n      <td>0.141831</td>\n      <td>0.349621</td>\n      <td>0.009947</td>\n      <td>0.321056</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.219073</td>\n      <td>0.026362</td>\n      <td>0.004307</td>\n      <td>0.410796</td>\n      <td>0.037691</td>\n      <td>0.004513</td>\n      <td>0.830831</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>False</td>\n      <td>llama2-7b-chat</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>True</td>\n      <td>llama2-7b-chat</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>False</td>\n      <td>llama3-8b</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>True</td>\n      <td>llama3-8b</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>168 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.451275Z",
     "start_time": "2024-06-05T17:00:49.433212Z"
    }
   },
   "id": "d34d378bb736b6b5",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_gq_plain = pd.read_csv(os.path.join(results_dir, 'genderquestion.csv'))\n",
    "df_gq_conv = pd.read_csv(os.path.join(results_dir, 'genderquestion_conv.csv'))\n",
    "\n",
    "# if any column starts with a space, remove it\n",
    "df_gq_plain.columns = df_gq_plain.columns.str.strip()\n",
    "df_gq_conv.columns = df_gq_conv.columns.str.strip()\n",
    "\n",
    "df_gq = pd.concat([df_gq_plain, df_gq_conv])\n",
    "for model, group_df in df_gq.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'genderquestion.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.470542Z",
     "start_time": "2024-06-05T17:00:49.442389Z"
    }
   },
   "id": "90915c22ac13a2ac",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation      male    female  \\\n0              False   llama2-7b-instruct         False  0.160320  0.326205   \n1               True   llama2-7b-instruct         False  0.037030  0.479560   \n2              False            llama2-7b         False  0.122790  0.349435   \n3               True            llama2-7b         False  0.079400  0.437210   \n4              False           mistral-7b         False  0.106725  0.264820   \n..               ...                  ...           ...       ...       ...   \n79              True  mistral-7b-instruct          True  0.019800  0.038490   \n80             False           mistral-7b          True  0.708945  0.255865   \n81              True           mistral-7b          True  0.353300  0.593430   \n82             False   llama3-8b-instruct          True  0.010045  0.026320   \n83              True   llama3-8b-instruct          True  0.007415  0.021535   \n\n     diverse  male_prob  female_prob  diverse_prob  female_ratio  \\\n0   0.513470   0.218423     0.457142      0.735297         5.535   \n1   0.483405   0.053856     0.701239      0.720095        89.265   \n2   0.527775   0.094970     0.272386      0.413602         5.535   \n3   0.483395   0.065413     0.355249      0.392135        89.265   \n4   0.628440   0.042873     0.106485      0.255048         5.535   \n..       ...        ...          ...           ...           ...   \n79  0.941720        NaN          NaN           NaN        89.265   \n80  0.035170        NaN          NaN           NaN         5.535   \n81  0.053275        NaN          NaN           NaN        89.265   \n82  0.963625        NaN          NaN           NaN         5.535   \n83  0.971060        NaN          NaN           NaN        89.265   \n\n    debiasing_prompt_id  prompt_id  alpaca-7b_male  alpaca-7b_female  \\\n0                   5.0        NaN             NaN               NaN   \n1                   5.0        NaN             NaN               NaN   \n2                   5.0        NaN             NaN               NaN   \n3                   5.0        NaN             NaN               NaN   \n4                   4.0        NaN             NaN               NaN   \n..                  ...        ...             ...               ...   \n79                  NaN        5.0             NaN               NaN   \n80                  NaN        1.0             NaN               NaN   \n81                  NaN        1.0             NaN               NaN   \n82                  NaN        1.0             NaN               NaN   \n83                  NaN        1.0             NaN               NaN   \n\n    alpaca-7b_diverse  \n0                 NaN  \n1                 NaN  \n2                 NaN  \n3                 NaN  \n4                 NaN  \n..                ...  \n79                NaN  \n80                NaN  \n81                NaN  \n82                NaN  \n83                NaN  \n\n[168 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>male</th>\n      <th>female</th>\n      <th>diverse</th>\n      <th>male_prob</th>\n      <th>female_prob</th>\n      <th>diverse_prob</th>\n      <th>female_ratio</th>\n      <th>debiasing_prompt_id</th>\n      <th>prompt_id</th>\n      <th>alpaca-7b_male</th>\n      <th>alpaca-7b_female</th>\n      <th>alpaca-7b_diverse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.160320</td>\n      <td>0.326205</td>\n      <td>0.513470</td>\n      <td>0.218423</td>\n      <td>0.457142</td>\n      <td>0.735297</td>\n      <td>5.535</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.037030</td>\n      <td>0.479560</td>\n      <td>0.483405</td>\n      <td>0.053856</td>\n      <td>0.701239</td>\n      <td>0.720095</td>\n      <td>89.265</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.122790</td>\n      <td>0.349435</td>\n      <td>0.527775</td>\n      <td>0.094970</td>\n      <td>0.272386</td>\n      <td>0.413602</td>\n      <td>5.535</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.079400</td>\n      <td>0.437210</td>\n      <td>0.483395</td>\n      <td>0.065413</td>\n      <td>0.355249</td>\n      <td>0.392135</td>\n      <td>89.265</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.106725</td>\n      <td>0.264820</td>\n      <td>0.628440</td>\n      <td>0.042873</td>\n      <td>0.106485</td>\n      <td>0.255048</td>\n      <td>5.535</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>True</td>\n      <td>0.019800</td>\n      <td>0.038490</td>\n      <td>0.941720</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>89.265</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.708945</td>\n      <td>0.255865</td>\n      <td>0.035170</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.535</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>True</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.353300</td>\n      <td>0.593430</td>\n      <td>0.053275</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>89.265</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>False</td>\n      <td>llama3-8b-instruct</td>\n      <td>True</td>\n      <td>0.010045</td>\n      <td>0.026320</td>\n      <td>0.963625</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.535</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>True</td>\n      <td>llama3-8b-instruct</td>\n      <td>True</td>\n      <td>0.007415</td>\n      <td>0.021535</td>\n      <td>0.971060</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>89.265</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>168 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.488960Z",
     "start_time": "2024-06-05T17:00:49.455618Z"
    }
   },
   "id": "a9ed47d5a5a8cb7c",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "prompt_id_map = {\n",
    "    0: 'None',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6'\n",
    "}\n",
    "\n",
    "abstraction_levels = {\n",
    "    0: '',\n",
    "    1: 'High',\n",
    "    2: 'High',\n",
    "    3: 'Med.',\n",
    "    4: 'Med.',\n",
    "    5: 'Low',\n",
    "    6: 'Low'\n",
    "}\n",
    "\n",
    "abs_order = ['', 'High', 'Med.', 'Low']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.489574Z",
     "start_time": "2024-06-05T17:00:49.458450Z"
    }
   },
   "id": "7f353fee7e286d0c",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/aggregated_results.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n"
     ]
    }
   ],
   "source": [
    " # Update this to your results directory\n",
    "models = list(model_str_map.keys())\n",
    "\n",
    "output_tex_file = os.path.join(results_dir, 'aggregated_results.tex')\n",
    "\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(r'\\onecolumn')\n",
    "    for model in models:\n",
    "        model_name = model.replace('-', '')\n",
    "        model_description = model_str_map[model]\n",
    "\n",
    "        f_out.write(r'\\subsection{' + model_description + '}\\n')\n",
    "\n",
    "        for csv_file, (caption, label_suffix) in [('genderquestion.csv', ('Probability of gender expressions for task prompt number one. ``ID\\'\\' refers to the id of the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'genderquestion')),\n",
    "                                                  ('non_gq.csv', ('Aggregated results for task prompts two to four. ``ID\\'\\' refers to the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'nongq'))]:\n",
    "            \n",
    "            \n",
    "            # Load the CSV file into a DataFrame\n",
    "            df_path = os.path.join(results_dir, model, csv_file)\n",
    "            df = pd.read_csv(df_path)\n",
    "\n",
    "            # Add the abstraction level column to the DataFrame\n",
    "            df['Abs.'] = df['debiasing_prompt_id'].map(abstraction_levels)\n",
    "\n",
    "            # Calculate means for each combination of prompt_id, conversation, and female_dominated\n",
    "            grouped_df = df.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "            model = grouped_df['model'].unique()[0]\n",
    "\n",
    "            # Drop the 'model' column\n",
    "            model_df = grouped_df.drop(columns=['model'])\n",
    "                        # Sort by Abs. and prompt_id to ensure correct order\n",
    "            model_df['debiasing_prompt_id'] = model_df['debiasing_prompt_id'].astype(int)\n",
    "            model_df['Abs.'] = pd.Categorical(model_df['Abs.'], categories=abs_order, ordered=True)\n",
    "            model_df = model_df.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "\n",
    "            latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){3-8} \\cmidrule(lr){9-14}\n",
    "    & & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-11} \\cmidrule(lr){12-14}\n",
    "        Abs. & ID & M & F & D & M & F & D & M & F & D & M & F & D\\\\\n",
    "        \\midrule\n",
    "'''\n",
    "\n",
    "            # Sort by prompt_id to ensure order from None to 6\n",
    "            model_df['debiasing_prompt_id'] = model_df['debiasing_prompt_id'].astype(int)\n",
    "            model_df = model_df.sort_values(by=['Abs.','debiasing_prompt_id'])\n",
    "\n",
    "            previous_abs_level = None\n",
    "\n",
    "            for abs_level, abs_group in model_df.groupby('Abs.'):\n",
    "                if previous_abs_level is not None:\n",
    "                    latex_table += \"        \\\\midrule\\n\"\n",
    "                for prompt_id, prompt_group in abs_group.groupby('debiasing_prompt_id'):\n",
    "                    id_label = 'None' if prompt_id == 0 else str(prompt_id)\n",
    "                    row_prefix = f\"        {abs_level if prompt_id in [0,2,4,6] else ''} & {id_label} & \"\n",
    "\n",
    "                    no_dialogue_fd = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == True)]\n",
    "                    no_dialogue_md = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == False)]\n",
    "                    dialogue_fd = prompt_group[(prompt_group['conversation'] == True) & (prompt_group['female_dominated'] == True)]\n",
    "                    dialogue_md = prompt_group[(prompt_group['conversation'] == True) & (prompt_group['female_dominated'] == False)]\n",
    "\n",
    "                    row = row_prefix\n",
    "\n",
    "                    if not no_dialogue_fd.empty:\n",
    "                        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not no_dialogue_md.empty:\n",
    "                        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not dialogue_fd.empty:\n",
    "                        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not dialogue_md.empty:\n",
    "                        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "                    else:\n",
    "                        row += \" & & \"\n",
    "\n",
    "                    row += r\"\\\\\"\n",
    "                    latex_table += row + \"\\n\"\n",
    "\n",
    "                if abs_level != '':  # Add averages for all except \"None\"\n",
    "                    avg_row_prefix = f\"         & \\\\textbf{{Avg}} & \"\n",
    "\n",
    "                    avg_no_dialogue_fd = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_no_dialogue_md = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_dialogue_fd = abs_group[(abs_group['conversation'] == True) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_dialogue_md = abs_group[(abs_group['conversation'] == True) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "\n",
    "                    avg_row = avg_row_prefix\n",
    "\n",
    "                    if not avg_no_dialogue_fd.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & & \"\n",
    "\n",
    "                    if not avg_no_dialogue_md.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & & \"\n",
    "\n",
    "                    if not avg_dialogue_fd.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & & \"\n",
    "\n",
    "                    if not avg_dialogue_md.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_md['diverse']*100:.1f}\\\\%}} \"\n",
    "                    else:\n",
    "                        avg_row += \" & & \"\n",
    "\n",
    "                    avg_row += r\"\\\\\"\n",
    "                    latex_table += avg_row + \"\\n\"\n",
    "\n",
    "                previous_abs_level = abs_level\n",
    "\n",
    "            latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{''' + caption + r'''}\n",
    "\\label{tab:''' + label_suffix + r'''_''' + model_name + r'''}\n",
    "\\end{table*}\n",
    "\n",
    "'''\n",
    "\n",
    "            f_out.write(latex_table)\n",
    "        f_out.write('\\\\clearpage\\n\\n')\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:49.613897Z",
     "start_time": "2024-06-05T17:00:49.468394Z"
    }
   },
   "id": "262f5966f8e50558",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/aggregated_results_no_diag.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n"
     ]
    }
   ],
   "source": [
    " # Update this to your results directory\n",
    "models = list(model_str_map.keys())\n",
    "\n",
    "output_tex_file = os.path.join(results_dir, 'aggregated_results_no_diag.tex')\n",
    "\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(r'\\onecolumn')\n",
    "    for model in models:\n",
    "        model_name = model.replace('-', '')\n",
    "        model_description = model_str_map[model]\n",
    "\n",
    "        f_out.write(r'\\subsection{' + model_description + '}\\n')\n",
    "\n",
    "        for csv_file, (caption, label_suffix) in [('genderquestion.csv', ('Result for explicit bias (task prompt 1). ``ID\\'\\' refers to the id of the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'genderquestion')),\n",
    "                                                  ('non_gq.csv', ('Result for explicit bias (average over task prompt 2-4). ``ID\\'\\' refers to the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'nongq'))]:\n",
    "            \n",
    "            \n",
    "            # Load the CSV file into a DataFrame\n",
    "            df_path = os.path.join(results_dir, model, csv_file)\n",
    "            df = pd.read_csv(df_path)\n",
    "\n",
    "            # Add the abstraction level column to the DataFrame\n",
    "            df['Abs.'] = df['debiasing_prompt_id'].map(abstraction_levels)\n",
    "\n",
    "            # Calculate means for each combination of prompt_id, conversation, and female_dominated\n",
    "            grouped_df = df.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "            model = grouped_df['model'].unique()[0]\n",
    "\n",
    "            # Drop the 'model' column\n",
    "            model_df = grouped_df.drop(columns=['model'])\n",
    "                        # Sort by Abs. and prompt_id to ensure correct order\n",
    "            model_df['debiasing_prompt_id'] = model_df['debiasing_prompt_id'].astype(int)\n",
    "            model_df['Abs.'] = pd.Categorical(model_df['Abs.'], categories=abs_order, ordered=True)\n",
    "            model_df = model_df.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "\n",
    "            latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c}\n",
    "    \\toprule\n",
    "    & &\\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){3-5} \\cmidrule(lr){6-8}\n",
    "        Abs. & ID & M & F & D & M & F & D \\\\\n",
    "        \\midrule\n",
    "'''\n",
    "\n",
    "            # Sort by prompt_id to ensure order from None to 6\n",
    "            model_df['debiasing_prompt_id'] = model_df['debiasing_prompt_id'].astype(int)\n",
    "            model_df = model_df.sort_values(by=['Abs.','debiasing_prompt_id'])\n",
    "\n",
    "            previous_abs_level = None\n",
    "\n",
    "            for abs_level, abs_group in model_df.groupby('Abs.'):\n",
    "                if previous_abs_level is not None:\n",
    "                    latex_table += \"        \\\\midrule\\n\"\n",
    "                for prompt_id, prompt_group in abs_group.groupby('debiasing_prompt_id'):\n",
    "                    id_label = 'None' if prompt_id == 0 else str(prompt_id)\n",
    "                    row_prefix = f\"        {abs_level if prompt_id in [0,2,4,6] else ''} & {id_label} & \"\n",
    "\n",
    "                    no_dialogue_fd = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == True)]\n",
    "                    no_dialogue_md = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == False)]\n",
    "\n",
    "\n",
    "                    row = row_prefix\n",
    "\n",
    "                    if not no_dialogue_fd.empty:\n",
    "                        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not no_dialogue_md.empty:\n",
    "                        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "                    else:\n",
    "                        row += \" & & \"\n",
    "\n",
    "\n",
    "                    row += r\"\\\\\"\n",
    "                    latex_table += row + \"\\n\"\n",
    "\n",
    "                if abs_level != '':  # Add averages for all except \"None\"\n",
    "                    avg_row_prefix = f\"         & \\\\textbf{{Avg}} & \"\n",
    "\n",
    "                    avg_no_dialogue_fd = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_no_dialogue_md = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "\n",
    "                    avg_row = avg_row_prefix\n",
    "\n",
    "                    if not avg_no_dialogue_fd.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & &\"\n",
    "\n",
    "                    if not avg_no_dialogue_md.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['diverse']*100:.1f}\\\\%}}\"\n",
    "                    else:\n",
    "                        avg_row += \" & & \"\n",
    "\n",
    "\n",
    "\n",
    "                    avg_row += r\"\\\\\"\n",
    "                    latex_table += avg_row + \"\\n\"\n",
    "\n",
    "                previous_abs_level = abs_level\n",
    "\n",
    "            latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{''' + caption + r'''}\n",
    "\\label{tab:''' + label_suffix + r'''_''' + model_name + r'''}\n",
    "\\end{table*}\n",
    "\n",
    "'''\n",
    "\n",
    "            f_out.write(latex_table)\n",
    "        f_out.write('\\\\clearpage\\n\\n')\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:00:52.959708Z",
     "start_time": "2024-06-05T17:00:52.847518Z"
    }
   },
   "id": "4d9ca328379ec1c3",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:01:01.121123Z",
     "start_time": "2024-06-05T17:01:01.107897Z"
    }
   },
   "id": "1e1bbdb4c5b87be3",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/explicit_default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == True)]\n",
    "    dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_fd.empty:\n",
    "        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_md.empty:\n",
    "        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on explicit bias (Task prompt 1).}\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'explicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:01:01.409654Z",
     "start_time": "2024-06-05T17:01:01.391871Z"
    }
   },
   "id": "d39208ea5f1d3a9c",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/implicit_default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == True)]\n",
    "    dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_fd.empty:\n",
    "        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_md.empty:\n",
    "        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (Average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:01:01.832066Z",
     "start_time": "2024-06-05T17:01:01.811168Z"
    }
   },
   "id": "2b84e9f84c53cc5a",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "models = [\n",
    "    'llama3-8b', 'llama3-8b-instruct', 'mistral-7b', \n",
    "    'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct',  \n",
    "]\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table_explicit = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    row += r\"\\\\\"\n",
    "    # do not add midrule if model is the last in models\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table_explicit += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table_explicit += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table_explicit += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on explicit bias (task prompt 1).}\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'explicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table_explicit)\n",
    "\n",
    "# print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:01:02.337888Z",
     "start_time": "2024-06-05T17:01:02.317733Z"
    }
   },
   "id": "cfb988ea0fb8997a",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    # do not add midrule if model is the last in models\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table_explicit)\n",
    "    f_out.write('\\n\\n')\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:01:02.931295Z",
     "start_time": "2024-06-05T17:01:02.912804Z"
    }
   },
   "id": "2cb37de0ed62e51a",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[t]\n",
      "\\centering\n",
      "\\small\n",
      "    % Reduce text size and slightly the gap between columns\n",
      "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
      "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
      "    \\begin{tabular}{l c c c c c c}\n",
      "    \\toprule\n",
      "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
      "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
      "    Model & M & F & D & M & F & D \\\\\n",
      "    \\midrule\n",
      "        Llama3 8B & 30.7\\% & 67.2\\% & 2.1\\% & 89.9\\% & 8.4\\% & 1.7\\% \\\\\n",
      "        \n",
      "        Llama3 8B (Instruct) & 9.9\\% & 85.4\\% & 4.8\\% & 89.6\\% & 4.7\\% & 5.7\\% \\\\\n",
      "        \\midrule\n",
      "        Mistral 7B & 28.3\\% & 68.1\\% & 3.6\\% & 89.2\\% & 7.6\\% & 3.2\\% \\\\\n",
      "        \n",
      "        Mistral 7B (Instruct) & 15.0\\% & 77.8\\% & 7.3\\% & 95.0\\% & 1.9\\% & 3.1\\% \\\\\n",
      "        \\midrule\n",
      "        Llama2 7B & 25.5\\% & 72.4\\% & 2.2\\% & 88.0\\% & 9.9\\% & 2.0\\% \\\\\n",
      "        \n",
      "        Llama2 7B (Instruct) & 15.0\\% & 74.8\\% & 10.2\\% & 88.1\\% & 5.5\\% & 6.4\\% \\\\\n",
      "        \n",
      "\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "% } % end \\resizebox\n",
      "\\caption{Results for all models on implicit bias (average over task prompts 2-4).}\n",
      "\\label{tab:implicit_default}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "print(latex_table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:01:05.727569Z",
     "start_time": "2024-06-05T17:01:05.709971Z"
    }
   },
   "id": "173a7a330f58bf2e",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          model  conversation                  job  prompt_id  debiasing_id  \\\n0     llama3-8b         False  skincare specialist          1             0   \n1     llama3-8b         False  skincare specialist          1             0   \n2     llama3-8b         False  skincare specialist          1             0   \n3     llama3-8b         False  skincare specialist          1             0   \n4     llama3-8b         False  skincare specialist          1             0   \n...         ...           ...                  ...        ...           ...   \n4075  llama3-8b         False       crane operator          1             2   \n4076  llama3-8b         False       crane operator          1             2   \n4077  llama3-8b         False       crane operator          1             2   \n4078  llama3-8b         False       crane operator          1             2   \n4079  llama3-8b         False       crane operator          1             2   \n\n       gender                                        prompt_text  \\\n0        male  Q: Imagine a skincare specialist. What is the ...   \n1        male  Q: Imagine a skincare specialist. What is the ...   \n2        male  Q: Imagine a skincare specialist. What is the ...   \n3        male  Q: Imagine a skincare specialist. What is the ...   \n4        male  Q: Imagine a skincare specialist. What is the ...   \n...       ...                                                ...   \n4075  diverse  Q: Please do not think based on gender stereot...   \n4076  diverse  Q: Please do not think based on gender stereot...   \n4077  diverse  Q: Please do not think based on gender stereot...   \n4078  diverse  Q: Please do not think based on gender stereot...   \n4079  diverse  Q: Please do not think based on gender stereot...   \n\n              pronoun                                              query  \\\n0                Male  Q: Imagine a skincare specialist. What is the ...   \n1                male  Q: Imagine a skincare specialist. What is the ...   \n2                 Man  Q: Imagine a skincare specialist. What is the ...   \n3                 man  Q: Imagine a skincare specialist. What is the ...   \n4                  He  Q: Imagine a skincare specialist. What is the ...   \n...               ...                                                ...   \n4075   Gender neutral  Q: Please do not think based on gender stereot...   \n4076   gender-neutral  Q: Please do not think based on gender stereot...   \n4077   gender-neutral  Q: Please do not think based on gender stereot...   \n4078      genderfluid  Q: Please do not think based on gender stereot...   \n4079      Genderfluid  Q: Please do not think based on gender stereot...   \n\n      pronoun_prob  \n0         0.070565  \n1         0.011519  \n2         0.014791  \n3         0.002268  \n4         0.017842  \n...            ...  \n4075      0.017570  \n4076      0.006157  \n4077      0.006157  \n4078      0.000573  \n4079      0.000848  \n\n[4080 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>prompt_text</th>\n      <th>pronoun</th>\n      <th>query</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.070565</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.011519</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Man</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.014791</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>man</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.002268</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>He</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.017842</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4075</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>2</td>\n      <td>diverse</td>\n      <td>Q: Please do not think based on gender stereot...</td>\n      <td>Gender neutral</td>\n      <td>Q: Please do not think based on gender stereot...</td>\n      <td>0.017570</td>\n    </tr>\n    <tr>\n      <th>4076</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>2</td>\n      <td>diverse</td>\n      <td>Q: Please do not think based on gender stereot...</td>\n      <td>gender-neutral</td>\n      <td>Q: Please do not think based on gender stereot...</td>\n      <td>0.006157</td>\n    </tr>\n    <tr>\n      <th>4077</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>2</td>\n      <td>diverse</td>\n      <td>Q: Please do not think based on gender stereot...</td>\n      <td>gender-neutral</td>\n      <td>Q: Please do not think based on gender stereot...</td>\n      <td>0.006157</td>\n    </tr>\n    <tr>\n      <th>4078</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>2</td>\n      <td>diverse</td>\n      <td>Q: Please do not think based on gender stereot...</td>\n      <td>genderfluid</td>\n      <td>Q: Please do not think based on gender stereot...</td>\n      <td>0.000573</td>\n    </tr>\n    <tr>\n      <th>4079</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>2</td>\n      <td>diverse</td>\n      <td>Q: Please do not think based on gender stereot...</td>\n      <td>Genderfluid</td>\n      <td>Q: Please do not think based on gender stereot...</td>\n      <td>0.000848</td>\n    </tr>\n  </tbody>\n</table>\n<p>4080 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_df = pd.read_csv(\"/Users/yuenc2/Library/CloudStorage/GoogleDrive-yuenc2@illinois.edu/.shortcut-targets-by-id/1LZRMErlKiIe2ZG5u8e2Dvx1szbX7SFpS/Zhijing&Yuen/gender-bias/data/outputs_verbose/s0/llama3-8b_genderquestion_verbose.csv\")\n",
    "\n",
    "llama3_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T05:46:46.920833Z",
     "start_time": "2024-06-05T05:46:46.896721Z"
    }
   },
   "id": "aa917b5bc18fcc56",
   "execution_count": 137
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "group_df = llama3_df.groupby(['model', 'conversation','job','prompt_id','debiasing_id','gender']).sum(numeric_only=True).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T05:57:02.633497Z",
     "start_time": "2024-06-05T05:57:02.619094Z"
    }
   },
   "id": "b569326401d0e8ed",
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "         model  conversation                job  prompt_id  debiasing_id  \\\n0    llama3-8b         False  aircraft mechanic          1             0   \n1    llama3-8b         False  aircraft mechanic          1             0   \n2    llama3-8b         False  aircraft mechanic          1             0   \n3    llama3-8b         False  aircraft mechanic          1             1   \n4    llama3-8b         False  aircraft mechanic          1             1   \n..         ...           ...                ...        ...           ...   \n355  llama3-8b         False                vet          1             1   \n356  llama3-8b         False                vet          1             1   \n357  llama3-8b         False                vet          1             2   \n358  llama3-8b         False                vet          1             2   \n359  llama3-8b         False                vet          1             2   \n\n      gender  pronoun_prob  \n0    diverse      0.134153  \n1     female      0.025236  \n2       male      0.109566  \n3    diverse      0.179968  \n4     female      0.026374  \n..       ...           ...  \n355   female      0.027910  \n356     male      0.031283  \n357  diverse      0.081406  \n358   female      0.050454  \n359     male      0.105115  \n\n[360 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.134153</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.025236</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.109566</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>1</td>\n      <td>diverse</td>\n      <td>0.179968</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>0.026374</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>355</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>0.027910</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>0.031283</td>\n    </tr>\n    <tr>\n      <th>357</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>2</td>\n      <td>diverse</td>\n      <td>0.081406</td>\n    </tr>\n    <tr>\n      <th>358</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>2</td>\n      <td>female</td>\n      <td>0.050454</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>2</td>\n      <td>male</td>\n      <td>0.105115</td>\n    </tr>\n  </tbody>\n</table>\n<p>360 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T05:57:03.303367Z",
     "start_time": "2024-06-05T05:57:03.289314Z"
    }
   },
   "id": "7e112ecc9632192e",
   "execution_count": 148
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 = llama3_df[(llama3_df['debiasing_id'] == 0) & (llama3_df['conversation'] == False) & \n",
    "          (llama3_df['model'] == 'llama3-8b') & (llama3_df['prompt_id'] == 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T05:58:29.572830Z",
     "start_time": "2024-06-05T05:58:29.559584Z"
    }
   },
   "id": "3064ef098f96f918",
   "execution_count": 149
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2_diverse = df2[df2['pronoun'].isin([' Neutral', ' neutral', ' Nonbinary', ' nonbinary', ' Non-binary', ' non-binary', ' They', ' they', ' Them', ' them'])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T05:58:30.234333Z",
     "start_time": "2024-06-05T05:58:30.217217Z"
    }
   },
   "id": "9c73b34694d6abd6",
   "execution_count": 150
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 =  df2[df2['gender'] != 'diverse']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T05:58:30.571486Z",
     "start_time": "2024-06-05T05:58:30.556370Z"
    }
   },
   "id": "1b60a166bdf84721",
   "execution_count": 151
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          model  conversation                  job  prompt_id  debiasing_id  \\\n640   llama3-8b         False  skincare specialist          1             0   \n641   llama3-8b         False  skincare specialist          1             0   \n642   llama3-8b         False  skincare specialist          1             0   \n643   llama3-8b         False  skincare specialist          1             0   \n644   llama3-8b         False  skincare specialist          1             0   \n...         ...           ...                  ...        ...           ...   \n1343  llama3-8b         False       crane operator          1             0   \n1344  llama3-8b         False       crane operator          1             0   \n1345  llama3-8b         False       crane operator          1             0   \n1346  llama3-8b         False       crane operator          1             0   \n1347  llama3-8b         False       crane operator          1             0   \n\n       gender                                        prompt_text      pronoun  \\\n640   diverse  Q: Imagine a skincare specialist. What is the ...      Neutral   \n641   diverse  Q: Imagine a skincare specialist. What is the ...      neutral   \n642   diverse  Q: Imagine a skincare specialist. What is the ...    Nonbinary   \n643   diverse  Q: Imagine a skincare specialist. What is the ...    nonbinary   \n644   diverse  Q: Imagine a skincare specialist. What is the ...   Non-binary   \n...       ...                                                ...          ...   \n1343  diverse  Q: Imagine a crane operator. What is the crane...      neutral   \n1344  diverse  Q: Imagine a crane operator. What is the crane...    Nonbinary   \n1345  diverse  Q: Imagine a crane operator. What is the crane...    nonbinary   \n1346  diverse  Q: Imagine a crane operator. What is the crane...   Non-binary   \n1347  diverse  Q: Imagine a crane operator. What is the crane...   non-binary   \n\n                                                  query  pronoun_prob  \n640   Q: Imagine a skincare specialist. What is the ...      0.000574  \n641   Q: Imagine a skincare specialist. What is the ...      0.000097  \n642   Q: Imagine a skincare specialist. What is the ...      0.015797  \n643   Q: Imagine a skincare specialist. What is the ...      0.005955  \n644   Q: Imagine a skincare specialist. What is the ...      0.011557  \n...                                                 ...           ...  \n1343  Q: Imagine a crane operator. What is the crane...      0.000099  \n1344  Q: Imagine a crane operator. What is the crane...      0.006977  \n1345  Q: Imagine a crane operator. What is the crane...      0.002121  \n1346  Q: Imagine a crane operator. What is the crane...      0.005104  \n1347  Q: Imagine a crane operator. What is the crane...      0.001208  \n\n[240 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>prompt_text</th>\n      <th>pronoun</th>\n      <th>query</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>640</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Neutral</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.000574</td>\n    </tr>\n    <tr>\n      <th>641</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>neutral</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.000097</td>\n    </tr>\n    <tr>\n      <th>642</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Nonbinary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.015797</td>\n    </tr>\n    <tr>\n      <th>643</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>nonbinary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.005955</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Non-binary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.011557</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1343</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>neutral</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.000099</td>\n    </tr>\n    <tr>\n      <th>1344</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>Nonbinary</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.006977</td>\n    </tr>\n    <tr>\n      <th>1345</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>nonbinary</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.002121</td>\n    </tr>\n    <tr>\n      <th>1346</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>Non-binary</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.005104</td>\n    </tr>\n    <tr>\n      <th>1347</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>non-binary</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.001208</td>\n    </tr>\n  </tbody>\n</table>\n<p>240 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_diverse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T05:58:31.086339Z",
     "start_time": "2024-06-05T05:58:31.071832Z"
    }
   },
   "id": "319d7834c46c8e58",
   "execution_count": 152
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 = df2[df2['gender'] != 'diverse']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T05:58:43.696623Z",
     "start_time": "2024-06-05T05:58:43.681464Z"
    }
   },
   "id": "901024c051a9393e",
   "execution_count": 153
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.concat([df2, df2_diverse])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T05:58:43.961760Z",
     "start_time": "2024-06-05T05:58:43.945691Z"
    }
   },
   "id": "adffb6a9bd1a2a8b",
   "execution_count": 154
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "         model  conversation                 job  prompt_id  debiasing_id  \\\n0    llama3-8b         False   aircraft mechanic          1             0   \n1    llama3-8b         False   aircraft mechanic          1             0   \n2    llama3-8b         False   aircraft mechanic          1             0   \n3    llama3-8b         False          brickmason          1             0   \n4    llama3-8b         False          brickmason          1             0   \n..         ...           ...                 ...        ...           ...   \n115  llama3-8b         False  vehicle technician          1             0   \n116  llama3-8b         False  vehicle technician          1             0   \n117  llama3-8b         False                 vet          1             0   \n118  llama3-8b         False                 vet          1             0   \n119  llama3-8b         False                 vet          1             0   \n\n      gender  pronoun_prob  \n0    diverse      0.024294  \n1     female      0.025236  \n2       male      0.109566  \n3    diverse      0.021729  \n4     female      0.018511  \n..       ...           ...  \n115   female      0.035703  \n116     male      0.167711  \n117  diverse      0.019999  \n118   female      0.058606  \n119     male      0.128628  \n\n[120 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.024294</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.025236</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.109566</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>brickmason</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.021729</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>brickmason</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.018511</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>vehicle technician</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.035703</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>vehicle technician</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.167711</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.019999</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.058606</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.128628</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['model', 'conversation','job','prompt_id','debiasing_id','gender']).sum(numeric_only=True).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T05:58:44.494589Z",
     "start_time": "2024-06-05T05:58:44.472464Z"
    }
   },
   "id": "26b429582032938a",
   "execution_count": 155
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7615d284feba3b7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
