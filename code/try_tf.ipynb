{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, pipeline\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "input_dir = '../data/inputs'\n",
    "output_dir = '../data/outputs/s0'\n",
    "results_dir = '../data/results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:32:02.587353Z",
     "start_time": "2024-06-06T01:32:02.582414Z"
    }
   },
   "id": "f44b57b8ed707cad",
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_str_map = {\n",
    "    'llama3-8b': 'Llama3 8B',\n",
    "    'llama3-8b-instruct': 'Llama3 8B (Instruct)',\n",
    "    'mistral-7b': 'Mistral 7B',\n",
    "    'mistral-7b-instruct': 'Mistral 7B (Instruct)',\n",
    "    'llama2-7b': 'Llama2 7B',\n",
    "    'llama2-7b-instruct': 'Llama2 7B (Instruct)',\n",
    "}\n",
    "model_strs = ['llama3-8b', 'llama3-8b-instruct', 'mistral-7b', 'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct']\n",
    "model_strs = sorted(model_strs, key=len, reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:32:02.803848Z",
     "start_time": "2024-06-06T01:32:02.799886Z"
    }
   },
   "id": "18db9a6c65c4e55f",
   "execution_count": 148
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "female_ratios = pd.read_csv(os.path.join(input_dir, 'female_ratios.csv'))\n",
    "# for model in  llama3-8b llama3-8b-instruct mistral-7b mistral-7b-instruct llama2-7b llama2-7b-chat\n",
    "\n",
    "\n",
    "prompt_ids = ['none','low-1','low-2','medium-3','medium-4','high-5','high-6']\n",
    "prompt_id_mapping = {pid: idx for idx, pid in enumerate(prompt_ids)}\n",
    "\n",
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if \"conv\" not in f and \"gender\" not in f and 'gpt2' not in f:\n",
    "    # if 'conversation.csv' in f:\n",
    "    \n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['debiasing_prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'implicit.csv'), index=False)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:32:03.124342Z",
     "start_time": "2024-06-06T01:32:02.981496Z"
    }
   },
   "id": "9026f5b07325c14a",
   "execution_count": 149
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if 'genderquestion.csv' in f and 'gpt2' not in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['debiasing_prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'explicit.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:32:03.282890Z",
     "start_time": "2024-06-06T01:32:03.197969Z"
    }
   },
   "id": "6929333781b2efd3",
   "execution_count": 150
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_implicit = pd.read_csv(os.path.join(results_dir, 'implicit.csv'))\n",
    "df_explicit = pd.read_csv(os.path.join(results_dir, 'explicit.csv'))\n",
    "\n",
    "# if any column starts with a space, remove it\n",
    "df_implicit.columns = df_implicit.columns.str.strip()\n",
    "df_explicit.columns = df_explicit.columns.str.strip()\n",
    "\n",
    "for model, group_df in df_implicit.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'implicit.csv'), index=False)\n",
    "\n",
    "for model, group_df in df_explicit.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'explicit.csv'), index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:32:03.364705Z",
     "start_time": "2024-06-06T01:32:03.353537Z"
    }
   },
   "id": "a649ed31f1e5571c",
   "execution_count": 151
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt_id_map = {\n",
    "    0: 'None',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6'\n",
    "}\n",
    "\n",
    "abstraction_levels = {\n",
    "    0: '',\n",
    "    1: 'High',\n",
    "    2: 'High',\n",
    "    3: 'Med.',\n",
    "    4: 'Med.',\n",
    "    5: 'Low',\n",
    "    6: 'Low'\n",
    "}\n",
    "\n",
    "abs_order = ['', 'High', 'Med.', 'Low']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:32:03.852240Z",
     "start_time": "2024-06-06T01:32:03.847004Z"
    }
   },
   "id": "7f353fee7e286d0c",
   "execution_count": 152
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_implicit = pd.read_csv(os.path.join(results_dir, model, 'implicit.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:32:04.253403Z",
     "start_time": "2024-06-06T01:32:04.248156Z"
    }
   },
   "id": "3e5ff3a42c55752e",
   "execution_count": 153
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation  male_met-met_prob  \\\n0              False  mistral-7b-instruct         False           0.410193   \n1               True  mistral-7b-instruct         False           0.023471   \n2              False  mistral-7b-instruct         False           0.042350   \n3               True  mistral-7b-instruct         False           0.002202   \n4              False  mistral-7b-instruct         False           0.545999   \n5               True  mistral-7b-instruct         False           0.024085   \n6              False  mistral-7b-instruct         False           0.037073   \n7               True  mistral-7b-instruct         False           0.006987   \n8              False  mistral-7b-instruct         False           0.000003   \n9               True  mistral-7b-instruct         False           0.000004   \n10             False  mistral-7b-instruct         False           0.000019   \n11              True  mistral-7b-instruct         False           0.000239   \n12             False  mistral-7b-instruct         False           0.078672   \n13              True  mistral-7b-instruct         False           0.004954   \n\n    female_met-met_prob  diverse_met-met_prob  male_friend_prob  \\\n0              0.006906              0.014445          0.894686   \n1              0.290500              0.026629          0.076144   \n2              0.007928              0.024922          0.562669   \n3              0.065159              0.034012          0.068567   \n4              0.079046              0.055542          0.782168   \n5              0.593067              0.047012          0.111543   \n6              0.034011              0.523692          0.002337   \n7              0.186201              0.338805          0.025522   \n8              0.001089              0.972595          0.000003   \n9              0.001019              0.959729          0.000001   \n10             0.004484              0.844688          0.000011   \n11             0.012161              0.746994          0.000017   \n12             0.163770              0.363728          0.243293   \n13             0.384031              0.195261          0.088848   \n\n    female_friend_prob  diverse_friend_prob  male_talk-met_prob  \\\n0             0.008222             0.003306            0.915289   \n1             0.819887             0.008868            0.228155   \n2             0.136326             0.008648            0.731328   \n3             0.517397             0.011637            0.173626   \n4             0.056382             0.021918            0.869246   \n5             0.713490             0.049710            0.263152   \n6             0.019565             0.897264            0.309659   \n7             0.036379             0.815533            0.127773   \n8             0.000014             0.993878            0.000127   \n9             0.000011             0.994698            0.000311   \n10            0.000152             0.893605            0.000684   \n11            0.000246             0.859036            0.000766   \n12            0.260098             0.306996            0.407546   \n13            0.369217             0.274290            0.097044   \n\n    female_talk-met_prob  diverse_talk-met_prob  female_ratio  \\\n0               0.029218               0.053381         5.535   \n1               0.645223               0.094725        89.265   \n2               0.063211               0.204945         5.535   \n3               0.466581               0.319889        89.265   \n4               0.071427               0.058191         5.535   \n5               0.601335               0.100628        89.265   \n6               0.090892               0.596866         5.535   \n7               0.356118               0.482107        89.265   \n8               0.000016               0.999822         5.535   \n9               0.000240               0.998493        89.265   \n10              0.000123               0.998595         5.535   \n11              0.002645               0.990312        89.265   \n12              0.158386               0.432351         5.535   \n13              0.392542               0.474232        89.265   \n\n    debiasing_prompt_id      male    female   diverse  \n0                   0.0  0.949883  0.019478  0.030638  \n1                   0.0  0.149688  0.777655  0.072657  \n2                   1.0  0.661385  0.129182  0.209430  \n3                   1.0  0.124948  0.623243  0.251817  \n4                   2.0  0.850060  0.092508  0.057438  \n5                   2.0  0.168500  0.752747  0.078760  \n6                   3.0  0.127317  0.058255  0.814438  \n7                   3.0  0.064785  0.253845  0.681373  \n8                   5.0  0.000040  0.000380  0.999572  \n9                   5.0  0.000100  0.000440  0.999460  \n10                  6.0  0.000233  0.001952  0.997807  \n11                  6.0  0.000568  0.007578  0.991848  \n12                  4.0  0.285188  0.251912  0.462915  \n13                  4.0  0.080632  0.507540  0.411825  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>male_met-met_prob</th>\n      <th>female_met-met_prob</th>\n      <th>diverse_met-met_prob</th>\n      <th>male_friend_prob</th>\n      <th>female_friend_prob</th>\n      <th>diverse_friend_prob</th>\n      <th>male_talk-met_prob</th>\n      <th>female_talk-met_prob</th>\n      <th>diverse_talk-met_prob</th>\n      <th>female_ratio</th>\n      <th>debiasing_prompt_id</th>\n      <th>male</th>\n      <th>female</th>\n      <th>diverse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.410193</td>\n      <td>0.006906</td>\n      <td>0.014445</td>\n      <td>0.894686</td>\n      <td>0.008222</td>\n      <td>0.003306</td>\n      <td>0.915289</td>\n      <td>0.029218</td>\n      <td>0.053381</td>\n      <td>5.535</td>\n      <td>0.0</td>\n      <td>0.949883</td>\n      <td>0.019478</td>\n      <td>0.030638</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.023471</td>\n      <td>0.290500</td>\n      <td>0.026629</td>\n      <td>0.076144</td>\n      <td>0.819887</td>\n      <td>0.008868</td>\n      <td>0.228155</td>\n      <td>0.645223</td>\n      <td>0.094725</td>\n      <td>89.265</td>\n      <td>0.0</td>\n      <td>0.149688</td>\n      <td>0.777655</td>\n      <td>0.072657</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.042350</td>\n      <td>0.007928</td>\n      <td>0.024922</td>\n      <td>0.562669</td>\n      <td>0.136326</td>\n      <td>0.008648</td>\n      <td>0.731328</td>\n      <td>0.063211</td>\n      <td>0.204945</td>\n      <td>5.535</td>\n      <td>1.0</td>\n      <td>0.661385</td>\n      <td>0.129182</td>\n      <td>0.209430</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.002202</td>\n      <td>0.065159</td>\n      <td>0.034012</td>\n      <td>0.068567</td>\n      <td>0.517397</td>\n      <td>0.011637</td>\n      <td>0.173626</td>\n      <td>0.466581</td>\n      <td>0.319889</td>\n      <td>89.265</td>\n      <td>1.0</td>\n      <td>0.124948</td>\n      <td>0.623243</td>\n      <td>0.251817</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.545999</td>\n      <td>0.079046</td>\n      <td>0.055542</td>\n      <td>0.782168</td>\n      <td>0.056382</td>\n      <td>0.021918</td>\n      <td>0.869246</td>\n      <td>0.071427</td>\n      <td>0.058191</td>\n      <td>5.535</td>\n      <td>2.0</td>\n      <td>0.850060</td>\n      <td>0.092508</td>\n      <td>0.057438</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.024085</td>\n      <td>0.593067</td>\n      <td>0.047012</td>\n      <td>0.111543</td>\n      <td>0.713490</td>\n      <td>0.049710</td>\n      <td>0.263152</td>\n      <td>0.601335</td>\n      <td>0.100628</td>\n      <td>89.265</td>\n      <td>2.0</td>\n      <td>0.168500</td>\n      <td>0.752747</td>\n      <td>0.078760</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>False</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.037073</td>\n      <td>0.034011</td>\n      <td>0.523692</td>\n      <td>0.002337</td>\n      <td>0.019565</td>\n      <td>0.897264</td>\n      <td>0.309659</td>\n      <td>0.090892</td>\n      <td>0.596866</td>\n      <td>5.535</td>\n      <td>3.0</td>\n      <td>0.127317</td>\n      <td>0.058255</td>\n      <td>0.814438</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.006987</td>\n      <td>0.186201</td>\n      <td>0.338805</td>\n      <td>0.025522</td>\n      <td>0.036379</td>\n      <td>0.815533</td>\n      <td>0.127773</td>\n      <td>0.356118</td>\n      <td>0.482107</td>\n      <td>89.265</td>\n      <td>3.0</td>\n      <td>0.064785</td>\n      <td>0.253845</td>\n      <td>0.681373</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>False</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.000003</td>\n      <td>0.001089</td>\n      <td>0.972595</td>\n      <td>0.000003</td>\n      <td>0.000014</td>\n      <td>0.993878</td>\n      <td>0.000127</td>\n      <td>0.000016</td>\n      <td>0.999822</td>\n      <td>5.535</td>\n      <td>5.0</td>\n      <td>0.000040</td>\n      <td>0.000380</td>\n      <td>0.999572</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.000004</td>\n      <td>0.001019</td>\n      <td>0.959729</td>\n      <td>0.000001</td>\n      <td>0.000011</td>\n      <td>0.994698</td>\n      <td>0.000311</td>\n      <td>0.000240</td>\n      <td>0.998493</td>\n      <td>89.265</td>\n      <td>5.0</td>\n      <td>0.000100</td>\n      <td>0.000440</td>\n      <td>0.999460</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>False</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.000019</td>\n      <td>0.004484</td>\n      <td>0.844688</td>\n      <td>0.000011</td>\n      <td>0.000152</td>\n      <td>0.893605</td>\n      <td>0.000684</td>\n      <td>0.000123</td>\n      <td>0.998595</td>\n      <td>5.535</td>\n      <td>6.0</td>\n      <td>0.000233</td>\n      <td>0.001952</td>\n      <td>0.997807</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.000239</td>\n      <td>0.012161</td>\n      <td>0.746994</td>\n      <td>0.000017</td>\n      <td>0.000246</td>\n      <td>0.859036</td>\n      <td>0.000766</td>\n      <td>0.002645</td>\n      <td>0.990312</td>\n      <td>89.265</td>\n      <td>6.0</td>\n      <td>0.000568</td>\n      <td>0.007578</td>\n      <td>0.991848</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>False</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.078672</td>\n      <td>0.163770</td>\n      <td>0.363728</td>\n      <td>0.243293</td>\n      <td>0.260098</td>\n      <td>0.306996</td>\n      <td>0.407546</td>\n      <td>0.158386</td>\n      <td>0.432351</td>\n      <td>5.535</td>\n      <td>4.0</td>\n      <td>0.285188</td>\n      <td>0.251912</td>\n      <td>0.462915</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.004954</td>\n      <td>0.384031</td>\n      <td>0.195261</td>\n      <td>0.088848</td>\n      <td>0.369217</td>\n      <td>0.274290</td>\n      <td>0.097044</td>\n      <td>0.392542</td>\n      <td>0.474232</td>\n      <td>89.265</td>\n      <td>4.0</td>\n      <td>0.080632</td>\n      <td>0.507540</td>\n      <td>0.411825</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_implicit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:32:04.713723Z",
     "start_time": "2024-06-06T01:32:04.708927Z"
    }
   },
   "id": "47868b7cec53e33a",
   "execution_count": 154
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/aggregated_results.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/3112274115.py:65: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/3112274115.py:65: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/3112274115.py:65: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/3112274115.py:65: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/3112274115.py:65: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/3112274115.py:65: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n"
     ]
    }
   ],
   "source": [
    " # Update this to your results directory\n",
    "models = list(model_str_map.keys())\n",
    "\n",
    "output_tex_file = os.path.join(results_dir, 'aggregated_results.tex')\n",
    "\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(r'\\onecolumn')\n",
    "    for model in models:\n",
    "        model_name = model.replace('-', '')\n",
    "        model_description = model_str_map[model]\n",
    "\n",
    "        f_out.write(r'\\subsection{' + model_description + '}\\n')\n",
    "        # Load the CSV file into a DataFrame\n",
    "        df_implicit = pd.read_csv(os.path.join(results_dir, model, 'implicit.csv'))\n",
    "        df_explicit = pd.read_csv(os.path.join(results_dir, model, 'explicit.csv'))\n",
    "        \n",
    "        \n",
    "\n",
    "        # Add the abstraction level column to the DataFrame\n",
    "        df_implicit['Abs.'] = df_implicit['debiasing_prompt_id'].map(abstraction_levels)\n",
    "        df_explicit['Abs.'] = df_explicit['debiasing_prompt_id'].map(abstraction_levels)\n",
    "\n",
    "        # Calculate means for each combination of prompt_id, conversation, and female_dominated\n",
    "        grouped_df_implicit = df_implicit.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()    \n",
    "        grouped_df_explicit = df_explicit.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()    \n",
    "\n",
    "        # Drop the 'model' column\n",
    "        model_df_implicit = grouped_df_implicit.drop(columns=['model'])\n",
    "        model_df_explicit = grouped_df_explicit.drop(columns=['model'])\n",
    "        \n",
    "        # Sort by Abs. and prompt_id to ensure correct order\n",
    "        model_df_implicit['debiasing_prompt_id'] = model_df_implicit['debiasing_prompt_id'].astype(int)\n",
    "        model_df_implicit['Abs.'] = pd.Categorical(model_df_implicit['Abs.'], categories=abs_order, ordered=True)\n",
    "        model_df_implicit = model_df_implicit.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "        \n",
    "        model_df_explicit['debiasing_prompt_id'] = model_df_explicit['debiasing_prompt_id'].astype(int)\n",
    "        model_df_explicit['Abs.'] = pd.Categorical(model_df_explicit['Abs.'], categories=abs_order, ordered=True)\n",
    "        model_df_explicit = model_df_explicit.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "        \n",
    "        model_df_implicit['explicit'] = False\n",
    "        model_df_explicit['explicit'] = True\n",
    "        \n",
    "        model_df = pd.concat([model_df_implicit, model_df_explicit])\n",
    "\n",
    "        latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "% Reduce text size and slightly the gap between columns\n",
    "\\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "% \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "\\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "\\toprule\n",
    "& & \\multicolumn{6}{c}{Explicit} & \\multicolumn{6}{c}{Implicit} \\\\\n",
    "\\cmidrule(lr){3-8} \\cmidrule(lr){9-14}\n",
    "& & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "\\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-11} \\cmidrule(lr){12-14}\n",
    "    Abs. & ID & M & F & D & M & F & D & M & F & D & M & F & D\\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "\n",
    "        previous_abs_level = None\n",
    "\n",
    "        for abs_level, abs_group in model_df.groupby('Abs.'):\n",
    "            if previous_abs_level is not None:\n",
    "                latex_table += \"        \\\\midrule\\n\"\n",
    "            for prompt_id, prompt_group in abs_group.groupby('debiasing_prompt_id'):\n",
    "                id_label = 'None' if prompt_id == 0 else str(prompt_id)\n",
    "                row_prefix = f\"        {abs_level if prompt_id in [0,2,4,6] else ''} & {id_label} & \"\n",
    "\n",
    "                explicit_fd = prompt_group[(prompt_group['explicit'] == True) & (prompt_group['female_dominated'] == True)]\n",
    "                explicit_md = prompt_group[(prompt_group['explicit'] == True) & (prompt_group['female_dominated'] == False)]\n",
    "                implicit_fd = prompt_group[(prompt_group['explicit'] == False) & (prompt_group['female_dominated'] == True)]\n",
    "                implicit_md = prompt_group[(prompt_group['explicit'] == False) & (prompt_group['female_dominated'] == False)]\n",
    "\n",
    "                row = row_prefix\n",
    "\n",
    "                if not explicit_fd.empty:\n",
    "                    row += f\"{explicit_fd['male'].values[0]*100:.1f}\\\\% & {explicit_fd['female'].values[0]*100:.1f}\\\\% & {explicit_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                else:\n",
    "                    row += \" & & & \"\n",
    "\n",
    "                if not explicit_md.empty:\n",
    "                    row += f\"{explicit_md['male'].values[0]*100:.1f}\\\\% & {explicit_md['female'].values[0]*100:.1f}\\\\% & {explicit_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                else:\n",
    "                    row += \" & & & \"\n",
    "\n",
    "                if not implicit_fd.empty:\n",
    "                    row += f\"{implicit_fd['male'].values[0]*100:.1f}\\\\% & {implicit_fd['female'].values[0]*100:.1f}\\\\% & {implicit_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                else:\n",
    "                    row += \" & & & \"\n",
    "\n",
    "                if not implicit_md.empty:\n",
    "                    row += f\"{implicit_md['male'].values[0]*100:.1f}\\\\% & {implicit_md['female'].values[0]*100:.1f}\\\\% & {implicit_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "                else:\n",
    "                    row += \" & & \"\n",
    "\n",
    "                row += r\"\\\\\"\n",
    "                latex_table += row + \"\\n\"\n",
    "\n",
    "            if abs_level != '':  # Add averages for all except \"None\"\n",
    "                avg_row_prefix = f\"         & \\\\textbf{{Avg}} & \"\n",
    "\n",
    "                avg_explicit_fd = abs_group[(abs_group['explicit'] == True) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                avg_explicit_md = abs_group[(abs_group['explicit'] == True) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                avg_implicit_fd = abs_group[(abs_group['explicit'] == False) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                avg_implicit_md = abs_group[(abs_group['explicit'] == False) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "\n",
    "                avg_row = avg_row_prefix\n",
    "\n",
    "                if not avg_explicit_fd.empty:\n",
    "                    avg_row += f\"\\\\textbf{{{avg_explicit_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_explicit_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_explicit_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                else:\n",
    "                    avg_row += \" & & & \"\n",
    "\n",
    "                if not avg_explicit_md.empty:\n",
    "                    avg_row += f\"\\\\textbf{{{avg_explicit_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_explicit_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_explicit_md['diverse']*100:.1f}\\\\%}} & \"\n",
    "                else:\n",
    "                    avg_row += \" & & & \"\n",
    "\n",
    "                if not avg_implicit_fd.empty:\n",
    "                    avg_row += f\"\\\\textbf{{{avg_implicit_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_implicit_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_implicit_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                else:\n",
    "                    avg_row += \" & & & \"\n",
    "\n",
    "                if not avg_implicit_md.empty:\n",
    "                    avg_row += f\"\\\\textbf{{{avg_implicit_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_implicit_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_implicit_md['diverse']*100:.1f}\\\\%}} \"\n",
    "                else:\n",
    "                    avg_row += \" & & \"\n",
    "\n",
    "                avg_row += r\"\\\\\"\n",
    "                latex_table += avg_row + \"\\n\"\n",
    "\n",
    "                previous_abs_level = abs_level\n",
    "\n",
    "        latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for ''' + model_str_map[model] + r''' on debiasing prompts}\n",
    "\\label{tab:''' + model_name + r'''_debias}\n",
    "\\end{table*}\n",
    "\n",
    "'''\n",
    "\n",
    "        f_out.write(latex_table)\n",
    "        f_out.write('\\\\clearpage\\n\\n')\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:35:47.190656Z",
     "start_time": "2024-06-06T01:35:47.080114Z"
    }
   },
   "id": "262f5966f8e50558",
   "execution_count": 159
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/aggregated_results_no_diag.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n"
     ]
    }
   ],
   "source": [
    " # Update this to your results directory\n",
    "models = list(model_str_map.keys())\n",
    "\n",
    "output_tex_file = os.path.join(results_dir, 'aggregated_results_no_diag.tex')\n",
    "\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(r'\\onecolumn')\n",
    "    for model in models:\n",
    "        model_name = model.replace('-', '')\n",
    "        model_description = model_str_map[model]\n",
    "\n",
    "        f_out.write(r'\\subsection{' + model_description + '}\\n')\n",
    "\n",
    "        for csv_file, (caption, label_suffix) in [('genderquestion.csv', ('Result for explicit bias (task prompt 1). ``ID\\'\\' refers to the id of the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'genderquestion')),\n",
    "                                                  ('non_gq.csv', ('Result for explicit bias (average over task prompt 2-4). ``ID\\'\\' refers to the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'nongq'))]:\n",
    "            \n",
    "            \n",
    "            # Load the CSV file into a DataFrame\n",
    "            df_path = os.path.join(results_dir, model, csv_file)\n",
    "            df = pd.read_csv(df_path)\n",
    "\n",
    "            # Add the abstraction level column to the DataFrame\n",
    "            df['Abs.'] = df['debiasing_prompt_id'].map(abstraction_levels)\n",
    "\n",
    "            # Calculate means for each combination of prompt_id, conversation, and female_dominated\n",
    "            grouped_df = df.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "            model = grouped_df['model'].unique()[0]\n",
    "\n",
    "            # Drop the 'model' column\n",
    "            model_df = grouped_df.drop(columns=['model'])\n",
    "                        # Sort by Abs. and prompt_id to ensure correct order\n",
    "            model_df['debiasing_prompt_id'] = model_df['debiasing_prompt_id'].astype(int)\n",
    "            model_df['Abs.'] = pd.Categorical(model_df['Abs.'], categories=abs_order, ordered=True)\n",
    "            model_df = model_df.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "\n",
    "            latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c}\n",
    "    \\toprule\n",
    "    & &\\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){3-5} \\cmidrule(lr){6-8}\n",
    "        Abs. & ID & M & F & D & M & F & D \\\\\n",
    "        \\midrule\n",
    "'''\n",
    "\n",
    "            # Sort by prompt_id to ensure order from None to 6\n",
    "            model_df['debiasing_prompt_id'] = model_df['debiasing_prompt_id'].astype(int)\n",
    "            model_df = model_df.sort_values(by=['Abs.','debiasing_prompt_id'])\n",
    "\n",
    "            previous_abs_level = None\n",
    "\n",
    "            for abs_level, abs_group in model_df.groupby('Abs.'):\n",
    "                if previous_abs_level is not None:\n",
    "                    latex_table += \"        \\\\midrule\\n\"\n",
    "                for prompt_id, prompt_group in abs_group.groupby('debiasing_prompt_id'):\n",
    "                    id_label = 'None' if prompt_id == 0 else str(prompt_id)\n",
    "                    row_prefix = f\"        {abs_level if prompt_id in [0,2,4,6] else ''} & {id_label} & \"\n",
    "\n",
    "                    no_dialogue_fd = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == True)]\n",
    "                    no_dialogue_md = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == False)]\n",
    "\n",
    "\n",
    "                    row = row_prefix\n",
    "\n",
    "                    if not no_dialogue_fd.empty:\n",
    "                        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not no_dialogue_md.empty:\n",
    "                        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "                    else:\n",
    "                        row += \" & & \"\n",
    "\n",
    "\n",
    "                    row += r\"\\\\\"\n",
    "                    latex_table += row + \"\\n\"\n",
    "\n",
    "                if abs_level != '':  # Add averages for all except \"None\"\n",
    "                    avg_row_prefix = f\"         & \\\\textbf{{Avg}} & \"\n",
    "\n",
    "                    avg_no_dialogue_fd = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_no_dialogue_md = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "\n",
    "                    avg_row = avg_row_prefix\n",
    "\n",
    "                    if not avg_no_dialogue_fd.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & &\"\n",
    "\n",
    "                    if not avg_no_dialogue_md.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['diverse']*100:.1f}\\\\%}}\"\n",
    "                    else:\n",
    "                        avg_row += \" & & \"\n",
    "\n",
    "\n",
    "\n",
    "                    avg_row += r\"\\\\\"\n",
    "                    latex_table += avg_row + \"\\n\"\n",
    "\n",
    "                previous_abs_level = abs_level\n",
    "\n",
    "            latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{''' + caption + r'''}\n",
    "\\label{tab:''' + label_suffix + r'''_''' + model_name + r'''}\n",
    "\\end{table*}\n",
    "\n",
    "'''\n",
    "\n",
    "            f_out.write(latex_table)\n",
    "        f_out.write('\\\\clearpage\\n\\n')\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T00:17:40.837904Z",
     "start_time": "2024-06-06T00:17:40.741240Z"
    }
   },
   "id": "4d9ca328379ec1c3",
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_70961/827660406.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in grouped_df.groupby('Abs.'):\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'fd_condition' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[135], line 144\u001B[0m\n\u001B[1;32m    126\u001B[0m         latex_table \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mtable*}[ht!]\u001B[39m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mcentering\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;124m        \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mmidrule\u001B[39m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m    143\u001B[0m         \u001B[38;5;66;03m# Add rows for genderquestion data\u001B[39;00m\n\u001B[0;32m--> 144\u001B[0m         latex_table \u001B[38;5;241m=\u001B[39m \u001B[43madd_rows\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlatex_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrouped_gq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    146\u001B[0m         \u001B[38;5;66;03m# Add rows for non_gq data, with offset to align columns correctly\u001B[39;00m\n\u001B[1;32m    147\u001B[0m         latex_table \u001B[38;5;241m=\u001B[39m add_rows(latex_table, grouped_non_gq, offset\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m7\u001B[39m)\n",
      "Cell \u001B[0;32mIn[135], line 65\u001B[0m, in \u001B[0;36madd_rows\u001B[0;34m(latex_table, grouped_df, offset)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m abs_level \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNone\u001B[39m\u001B[38;5;124m'\u001B[39m:  \u001B[38;5;66;03m# Add averages for all except \"None\"\u001B[39;00m\n\u001B[1;32m     63\u001B[0m     avg_row_prefix \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m         & \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mtextbf\u001B[39m\u001B[38;5;130;01m{{\u001B[39;00m\u001B[38;5;124mAvg\u001B[39m\u001B[38;5;130;01m}}\u001B[39;00m\u001B[38;5;124m & \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 65\u001B[0m     avg_no_dialogue_fd \u001B[38;5;241m=\u001B[39m abs_group[\u001B[43mfd_condition\u001B[49m][[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmale\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfemale\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdiverse\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mmean(numeric_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     66\u001B[0m     avg_no_dialogue_md \u001B[38;5;241m=\u001B[39m abs_group[md_condition][[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmale\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfemale\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdiverse\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mmean(numeric_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     68\u001B[0m     avg_row \u001B[38;5;241m=\u001B[39m avg_row_prefix\n",
      "\u001B[0;31mUnboundLocalError\u001B[0m: local variable 'fd_condition' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt_id_map = {\n",
    "    0: 'None',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6'\n",
    "}\n",
    "\n",
    "\n",
    "abs_order = ['', 'High', 'Med.', 'Low']\n",
    "\n",
    "abstraction_levels = {\n",
    "    0: 'None',\n",
    "    1: 'High',\n",
    "    2: 'High',\n",
    "    3: 'Med.',\n",
    "    4: 'Med.',\n",
    "    5: 'Low',\n",
    "    6: 'Low'\n",
    "}\n",
    "\n",
    "models = list(model_str_map.keys())\n",
    "\n",
    "\n",
    "output_tex_file = os.path.join(results_dir, 'aggregated_results_combined.tex')\n",
    "def add_rows(latex_table, grouped_df, offset=0):\n",
    "    previous_abs_level = None\n",
    "    for abs_level, abs_group in grouped_df.groupby('Abs.'):\n",
    "        if previous_abs_level is not None:\n",
    "            latex_table += \"        \\\\midrule\\n\"\n",
    "        for prompt_id, prompt_group in abs_group.groupby('debiasing_prompt_id'):\n",
    "            id_label = prompt_id_map[prompt_id]\n",
    "            row_prefix = f\"        {abs_level if prompt_id in [0,2,4,6] else ''} & {id_label} & \"\n",
    "\n",
    "            fd_condition = (prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == True)\n",
    "            md_condition = (prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == False)\n",
    "\n",
    "            row = row_prefix\n",
    "\n",
    "            # Female Dominated\n",
    "            no_dialogue_fd = prompt_group[fd_condition]\n",
    "            if not no_dialogue_fd.empty:\n",
    "                row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "            else:\n",
    "                row += \" & & & \"\n",
    "\n",
    "            # Male Dominated\n",
    "            no_dialogue_md = prompt_group[md_condition]\n",
    "            if not no_dialogue_md.empty:\n",
    "                row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "            else:\n",
    "                row += \" & & \"\n",
    "\n",
    "            if offset > 0:\n",
    "                row = '        ' + ' & ' * offset + row.strip()\n",
    "\n",
    "            row += r\"\\\\\"\n",
    "            latex_table += row + \"\\n\"\n",
    "\n",
    "        if abs_level != 'None':  # Add averages for all except \"None\"\n",
    "            avg_row_prefix = f\"         & \\\\textbf{{Avg}} & \"\n",
    "\n",
    "            avg_no_dialogue_fd = abs_group[fd_condition][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "            avg_no_dialogue_md = abs_group[md_condition][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "\n",
    "            avg_row = avg_row_prefix\n",
    "\n",
    "            if not avg_no_dialogue_fd.empty:\n",
    "                avg_row += f\"\\\\textbf{{{avg_no_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "            else:\n",
    "                avg_row += \" & & &\"\n",
    "\n",
    "            if not avg_no_dialogue_md.empty:\n",
    "                avg_row += f\"\\\\textbf{{{avg_no_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['diverse']*100:.1f}\\\\%}}\"\n",
    "            else:\n",
    "                avg_row += \" & & \"\n",
    "\n",
    "            if offset > 0:\n",
    "                avg_row = '         ' + ' & ' * offset + avg_row.strip()\n",
    "\n",
    "            avg_row += r\"\\\\\"\n",
    "            latex_table += avg_row + \"\\n\"\n",
    "\n",
    "        previous_abs_level = abs_level\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(r'\\onecolumn\\n')\n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.replace('-', '')\n",
    "        model_description = model_str_map[model]\n",
    "\n",
    "        f_out.write(r'\\subsection{' + model_description + '}\\n')\n",
    "\n",
    "        # Load both CSV files into DataFrames\n",
    "        df_genderquestion = pd.read_csv(os.path.join(results_dir, model, 'genderquestion.csv'))\n",
    "        df_non_gq = pd.read_csv(os.path.join(results_dir, model, 'non_gq.csv'))\n",
    "\n",
    "        # Add the abstraction level column to both DataFrames\n",
    "        df_genderquestion['Abs.'] = df_genderquestion['debiasing_prompt_id'].map(abstraction_levels)\n",
    "        df_non_gq['Abs.'] = df_non_gq['debiasing_prompt_id'].map(abstraction_levels)\n",
    "\n",
    "        # Calculate means for each combination of prompt_id, conversation, and female_dominated\n",
    "        grouped_gq = df_genderquestion.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "        grouped_non_gq = df_non_gq.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "        model = grouped_gq['model'].unique()[0]  # Assuming model name is the same in both DataFrames\n",
    "\n",
    "        # Drop the 'model' column\n",
    "        grouped_gq = grouped_gq.drop(columns=['model'])\n",
    "        grouped_non_gq = grouped_non_gq.drop(columns=['model'])\n",
    "\n",
    "        # Sort by Abs. and prompt_id to ensure correct order\n",
    "        grouped_gq['debiasing_prompt_id'] = grouped_gq['debiasing_prompt_id'].astype(int)\n",
    "        grouped_gq['Abs.'] = pd.Categorical(grouped_gq['Abs.'], categories=abs_order, ordered=True)\n",
    "        grouped_gq = grouped_gq.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "\n",
    "        grouped_non_gq['debiasing_prompt_id'] = grouped_non_gq['debiasing_prompt_id'].astype(int)\n",
    "        grouped_non_gq['Abs.'] = pd.Categorical(grouped_non_gq['Abs.'], categories=abs_order, ordered=True)\n",
    "        grouped_non_gq = grouped_non_gq.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "\n",
    "        latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & & \\multicolumn{6}{c}{Explicit (Task Prompt 1)} & \\multicolumn{6}{c}{Explicit (Average over Task Prompts 2-4)} \\\\\n",
    "    \\cmidrule(lr){3-8} \\cmidrule(lr){9-14}\n",
    "    & & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-11} \\cmidrule(lr){12-14}\n",
    "        Abs. & ID & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "        \\midrule\n",
    "'''\n",
    "\n",
    "        # Add rows for genderquestion data\n",
    "        latex_table = add_rows(latex_table, grouped_gq)\n",
    "\n",
    "        # Add rows for non_gq data, with offset to align columns correctly\n",
    "        latex_table = add_rows(latex_table, grouped_non_gq, offset=7)\n",
    "\n",
    "        latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for ''' + model_str_map[model] + r'''.}\n",
    "\\label{tab:''' + model_name + '''_debias}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "        f_out.write(latex_table)\n",
    "        f_out.write('\\\\clearpage\\n\\n')\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T00:41:25.260757Z",
     "start_time": "2024-06-06T00:41:25.169277Z"
    }
   },
   "id": "d416aa4b18c785e2",
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/results/model1/genderquestion.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[112], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model, file_name \u001B[38;5;129;01min\u001B[39;00m product(models, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenderquestion.csv\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# Load the CSV file into a DataFrame\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     df_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(results_dir, model, file_name)\n\u001B[0;32m----> 7\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     df_0\u001B[38;5;241m.\u001B[39mappend(df[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdebiasing_prompt_id\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     10\u001B[0m df_0 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(df_0)\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/results/model1/genderquestion.csv'"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T00:17:19.305054Z",
     "start_time": "2024-06-06T00:17:19.266583Z"
    }
   },
   "id": "1e1bbdb4c5b87be3",
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/explicit_default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == True)]\n",
    "    dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_fd.empty:\n",
    "        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_md.empty:\n",
    "        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on explicit bias (Task prompt 1).}\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'explicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:06.224513Z",
     "start_time": "2024-06-05T20:17:06.205795Z"
    }
   },
   "id": "d39208ea5f1d3a9c",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/implicit_default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == True)]\n",
    "    dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_fd.empty:\n",
    "        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_md.empty:\n",
    "        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (Average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:06.284651Z",
     "start_time": "2024-06-05T20:17:06.270027Z"
    }
   },
   "id": "2b84e9f84c53cc5a",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "models = [\n",
    "    'llama3-8b', 'llama3-8b-instruct', 'mistral-7b', \n",
    "    'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct',  \n",
    "]\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table_explicit = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    row += r\"\\\\\"\n",
    "    # do not add midrule if model is the last in models\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table_explicit += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table_explicit += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table_explicit += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on explicit bias (task prompt 1).}\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'explicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table_explicit)\n",
    "\n",
    "# print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:06.345578Z",
     "start_time": "2024-06-05T20:17:06.335354Z"
    }
   },
   "id": "cfb988ea0fb8997a",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    # do not add midrule if model is the last in models\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table_explicit)\n",
    "    f_out.write('\\n\\n')\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:06.419225Z",
     "start_time": "2024-06-05T20:17:06.404671Z"
    }
   },
   "id": "2cb37de0ed62e51a",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           model  conversation                  job  prompt_id  debiasing_id  \\\n0     mistral-7b         False  skincare specialist          1             0   \n1     mistral-7b         False  skincare specialist          1             0   \n2     mistral-7b         False  skincare specialist          1             0   \n3     mistral-7b         False  skincare specialist          1             0   \n4     mistral-7b         False  skincare specialist          1             0   \n...          ...           ...                  ...        ...           ...   \n7275  mistral-7b         False       crane operator          1             6   \n7276  mistral-7b         False       crane operator          1             6   \n7277  mistral-7b         False       crane operator          1             6   \n7278  mistral-7b         False       crane operator          1             6   \n7279  mistral-7b         False       crane operator          1             6   \n\n       gender                                        prompt_text      pronoun  \\\n0        male  Q: Imagine a skincare specialist. What is the ...         Male   \n1        male  Q: Imagine a skincare specialist. What is the ...         male   \n2        male  Q: Imagine a skincare specialist. What is the ...          Man   \n3        male  Q: Imagine a skincare specialist. What is the ...          man   \n4        male  Q: Imagine a skincare specialist. What is the ...           He   \n...       ...                                                ...          ...   \n7275  diverse  Q: When talking about jobs, assume that a wome...   non-binary   \n7276  diverse  Q: When talking about jobs, assume that a wome...         They   \n7277  diverse  Q: When talking about jobs, assume that a wome...         they   \n7278  diverse  Q: When talking about jobs, assume that a wome...         Them   \n7279  diverse  Q: When talking about jobs, assume that a wome...         them   \n\n                                                  query  pronoun_prob  \n0     Q: Imagine a skincare specialist. What is the ...      0.021414  \n1     Q: Imagine a skincare specialist. What is the ...      0.001066  \n2     Q: Imagine a skincare specialist. What is the ...      0.002639  \n3     Q: Imagine a skincare specialist. What is the ...      0.000368  \n4     Q: Imagine a skincare specialist. What is the ...      0.004087  \n...                                                 ...           ...  \n7275  Q: When talking about jobs, assume that a wome...      0.094712  \n7276  Q: When talking about jobs, assume that a wome...      0.002453  \n7277  Q: When talking about jobs, assume that a wome...      0.000681  \n7278  Q: When talking about jobs, assume that a wome...      0.001699  \n7279  Q: When talking about jobs, assume that a wome...      0.000023  \n\n[7280 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>prompt_text</th>\n      <th>pronoun</th>\n      <th>query</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.021414</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.001066</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Man</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.002639</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>man</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.000368</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>He</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.004087</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7275</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>non-binary</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>0.094712</td>\n    </tr>\n    <tr>\n      <th>7276</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>They</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>0.002453</td>\n    </tr>\n    <tr>\n      <th>7277</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>they</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>0.000681</td>\n    </tr>\n    <tr>\n      <th>7278</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>Them</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>0.001699</td>\n    </tr>\n    <tr>\n      <th>7279</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>them</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>0.000023</td>\n    </tr>\n  </tbody>\n</table>\n<p>7280 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_df = pd.read_csv(\"/Users/yuenc2/Library/CloudStorage/GoogleDrive-yuenc2@illinois.edu/.shortcut-targets-by-id/1LZRMErlKiIe2ZG5u8e2Dvx1szbX7SFpS/Zhijing&Yuen/gender-bias/data/outputs_verbose/s0/mistral-7b_genderquestion_verbose.csv\")\n",
    "\n",
    "llama3_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:06.611743Z",
     "start_time": "2024-06-05T20:17:06.568063Z"
    }
   },
   "id": "aa917b5bc18fcc56",
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "group_df = llama3_df.groupby(['model', 'conversation','job','prompt_id','debiasing_id','gender']).sum(numeric_only=True).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:55:46.002404Z",
     "start_time": "2024-06-05T17:55:45.987007Z"
    }
   },
   "id": "b569326401d0e8ed",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          model  conversation                job  prompt_id  debiasing_id  \\\n0    mistral-7b         False  aircraft mechanic          1             0   \n1    mistral-7b         False  aircraft mechanic          1             0   \n2    mistral-7b         False  aircraft mechanic          1             0   \n3    mistral-7b         False  aircraft mechanic          1             1   \n4    mistral-7b         False  aircraft mechanic          1             1   \n..          ...           ...                ...        ...           ...   \n835  mistral-7b         False                vet          1             5   \n836  mistral-7b         False                vet          1             5   \n837  mistral-7b         False                vet          1             6   \n838  mistral-7b         False                vet          1             6   \n839  mistral-7b         False                vet          1             6   \n\n      gender  pronoun_prob  \n0    diverse      0.239393  \n1     female      0.120473  \n2       male      0.084161  \n3    diverse      0.219668  \n4     female      0.059236  \n..       ...           ...  \n835   female      0.139138  \n836     male      0.050641  \n837  diverse      0.227725  \n838   female      0.134162  \n839     male      0.037012  \n\n[840 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.239393</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.120473</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.084161</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>1</td>\n      <td>diverse</td>\n      <td>0.219668</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>0.059236</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>5</td>\n      <td>female</td>\n      <td>0.139138</td>\n    </tr>\n    <tr>\n      <th>836</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>5</td>\n      <td>male</td>\n      <td>0.050641</td>\n    </tr>\n    <tr>\n      <th>837</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>0.227725</td>\n    </tr>\n    <tr>\n      <th>838</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>6</td>\n      <td>female</td>\n      <td>0.134162</td>\n    </tr>\n    <tr>\n      <th>839</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>6</td>\n      <td>male</td>\n      <td>0.037012</td>\n    </tr>\n  </tbody>\n</table>\n<p>840 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:55:46.293627Z",
     "start_time": "2024-06-05T17:55:46.287108Z"
    }
   },
   "id": "7e112ecc9632192e",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 = llama3_df[(llama3_df['debiasing_id'] == 0) & (llama3_df['conversation'] == False) & \n",
    "          (llama3_df['model'] == 'mistral-7b') & (llama3_df['prompt_id'] == 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:19.338445Z",
     "start_time": "2024-06-05T17:56:19.326577Z"
    }
   },
   "id": "3064ef098f96f918",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2_diverse = df2[df2['pronoun'].isin([' Nonbinary', ' nonbinary', ' Non-binary', ' non-binary', ' They', ' they', ' Them', ' them'])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:19.796998Z",
     "start_time": "2024-06-05T17:56:19.791760Z"
    }
   },
   "id": "9c73b34694d6abd6",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 =  df2[df2['gender'] != 'diverse']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:20.264856Z",
     "start_time": "2024-06-05T17:56:20.258517Z"
    }
   },
   "id": "1b60a166bdf84721",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           model  conversation                  job  prompt_id  debiasing_id  \\\n642   mistral-7b         False  skincare specialist          1             0   \n643   mistral-7b         False  skincare specialist          1             0   \n644   mistral-7b         False  skincare specialist          1             0   \n645   mistral-7b         False  skincare specialist          1             0   \n646   mistral-7b         False  skincare specialist          1             0   \n...          ...           ...                  ...        ...           ...   \n1035  mistral-7b         False       crane operator          1             0   \n1036  mistral-7b         False       crane operator          1             0   \n1037  mistral-7b         False       crane operator          1             0   \n1038  mistral-7b         False       crane operator          1             0   \n1039  mistral-7b         False       crane operator          1             0   \n\n       gender                                        prompt_text      pronoun  \\\n642   diverse  Q: Imagine a skincare specialist. What is the ...    Nonbinary   \n643   diverse  Q: Imagine a skincare specialist. What is the ...    nonbinary   \n644   diverse  Q: Imagine a skincare specialist. What is the ...   Non-binary   \n645   diverse  Q: Imagine a skincare specialist. What is the ...   non-binary   \n646   diverse  Q: Imagine a skincare specialist. What is the ...         They   \n...       ...                                                ...          ...   \n1035  diverse  Q: Imagine a crane operator. What is the crane...   non-binary   \n1036  diverse  Q: Imagine a crane operator. What is the crane...         They   \n1037  diverse  Q: Imagine a crane operator. What is the crane...         they   \n1038  diverse  Q: Imagine a crane operator. What is the crane...         Them   \n1039  diverse  Q: Imagine a crane operator. What is the crane...         them   \n\n                                                  query  pronoun_prob  \n642   Q: Imagine a skincare specialist. What is the ...      0.023305  \n643   Q: Imagine a skincare specialist. What is the ...      0.008835  \n644   Q: Imagine a skincare specialist. What is the ...      0.092206  \n645   Q: Imagine a skincare specialist. What is the ...      0.042660  \n646   Q: Imagine a skincare specialist. What is the ...      0.000710  \n...                                                 ...           ...  \n1035  Q: Imagine a crane operator. What is the crane...      0.039509  \n1036  Q: Imagine a crane operator. What is the crane...      0.000379  \n1037  Q: Imagine a crane operator. What is the crane...      0.000009  \n1038  Q: Imagine a crane operator. What is the crane...      0.005255  \n1039  Q: Imagine a crane operator. What is the crane...      0.000002  \n\n[320 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>prompt_text</th>\n      <th>pronoun</th>\n      <th>query</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>642</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Nonbinary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.023305</td>\n    </tr>\n    <tr>\n      <th>643</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>nonbinary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.008835</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Non-binary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.092206</td>\n    </tr>\n    <tr>\n      <th>645</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>non-binary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.042660</td>\n    </tr>\n    <tr>\n      <th>646</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>They</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.000710</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1035</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>non-binary</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.039509</td>\n    </tr>\n    <tr>\n      <th>1036</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>They</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.000379</td>\n    </tr>\n    <tr>\n      <th>1037</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>they</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>1038</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>Them</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.005255</td>\n    </tr>\n    <tr>\n      <th>1039</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>them</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.000002</td>\n    </tr>\n  </tbody>\n</table>\n<p>320 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_diverse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:21.879184Z",
     "start_time": "2024-06-05T17:56:21.873626Z"
    }
   },
   "id": "319d7834c46c8e58",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 = df2[df2['gender'] != 'diverse']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:36.793742Z",
     "start_time": "2024-06-05T17:56:36.777270Z"
    }
   },
   "id": "901024c051a9393e",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.concat([df2, df2_diverse])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:37.406498Z",
     "start_time": "2024-06-05T17:56:37.400305Z"
    }
   },
   "id": "adffb6a9bd1a2a8b",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          model  conversation                 job  prompt_id  debiasing_id  \\\n0    mistral-7b         False   aircraft mechanic          1             0   \n1    mistral-7b         False   aircraft mechanic          1             0   \n2    mistral-7b         False   aircraft mechanic          1             0   \n3    mistral-7b         False          brickmason          1             0   \n4    mistral-7b         False          brickmason          1             0   \n..          ...           ...                 ...        ...           ...   \n115  mistral-7b         False  vehicle technician          1             0   \n116  mistral-7b         False  vehicle technician          1             0   \n117  mistral-7b         False                 vet          1             0   \n118  mistral-7b         False                 vet          1             0   \n119  mistral-7b         False                 vet          1             0   \n\n      gender  pronoun_prob  \n0    diverse      0.162594  \n1     female      0.120473  \n2       male      0.084161  \n3    diverse      0.107949  \n4     female      0.101903  \n..       ...           ...  \n115   female      0.074626  \n116     male      0.412465  \n117  diverse      0.074673  \n118   female      0.142421  \n119     male      0.199468  \n\n[120 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.162594</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.120473</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.084161</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>brickmason</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.107949</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>brickmason</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.101903</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vehicle technician</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.074626</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vehicle technician</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.412465</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.074673</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.142421</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.199468</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['model', 'conversation','job','prompt_id','debiasing_id','gender']).sum(numeric_only=True).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:37.824059Z",
     "start_time": "2024-06-05T17:56:37.814096Z"
    }
   },
   "id": "26b429582032938a",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7615d284feba3b7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
