{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, pipeline\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "input_dir = '../data/inputs'\n",
    "output_dir = '../data/outputs/s0'\n",
    "results_dir = '../data/results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:17.520303Z",
     "start_time": "2024-06-04T18:13:17.513661Z"
    }
   },
   "id": "f44b57b8ed707cad",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_str_map = {\n",
    "    'llama3-8b': 'Llama3 8B',\n",
    "    'llama3-8b-instruct': 'Llama3 8B (Instruct)',\n",
    "    'mistral-7b': 'Mistral 7B',\n",
    "    'mistral-7b-instruct': 'Mistral 7B (Instruct)',\n",
    "    'llama2-7b': 'Llama2 7B',\n",
    "    'llama2-7b-instruct': 'Llama2 7B (Instruct)',\n",
    "}\n",
    "model_strs = ['llama3-8b', 'llama3-8b-instruct', 'mistral-7b', 'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct']\n",
    "model_strs = sorted(model_strs, key=len, reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:17.774157Z",
     "start_time": "2024-06-04T18:13:17.770809Z"
    }
   },
   "id": "18db9a6c65c4e55f",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "female_ratios = pd.read_csv(os.path.join(input_dir, 'female_ratios.csv'))\n",
    "# for model in  llama3-8b llama3-8b-instruct mistral-7b mistral-7b-instruct llama2-7b llama2-7b-chat\n",
    "\n",
    "\n",
    "prompt_ids = ['none','low-1','low-2','medium-3','medium-4','high-5','high-6']\n",
    "prompt_id_mapping = {pid: idx for idx, pid in enumerate(prompt_ids)}\n",
    "\n",
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if \"conv\" not in f and \"gender\" not in f and 'gpt2' not in f:\n",
    "    # if 'conversation.csv' in f:\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "    # if 'conversation.csv' in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['debiasing_prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            # make sure the three columns add up to 1\n",
    "            # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "            # \n",
    "            # Optionally, drop the original detailed columns if only averages are needed\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'implicit.csv'), index=False)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:22.750757Z",
     "start_time": "2024-06-04T18:13:22.579734Z"
    }
   },
   "id": "9026f5b07325c14a",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df_list = []\n",
    "# for f in os.listdir(output_dir):\n",
    "#     if 'conversation.csv' in f:\n",
    "#         df = pd.read_csv(os.path.join(output_dir, f))\n",
    "#         df = pd.merge(df,female_ratios,on='job')\n",
    "#         df = df.drop(columns=['job','Unnamed: 0'])\n",
    "# \n",
    "#         df['female_dominated'] = df['female_ratio'] > 50\n",
    "#         # Extract prompt ID from filename\n",
    "#         prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "#         prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "#         df['debiasing_prompt_id'] = prompt_id\n",
    "#         \n",
    "#                 # Extract model from filename\n",
    "#         model_str = next((model for model in model_strs if model in f), None)\n",
    "#         df['model'] = model_str\n",
    "#         df['conversation'] = 'conv' in f\n",
    "# \n",
    "#         # Remove model name from other column names\n",
    "#         if model_str:\n",
    "#             df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "# \n",
    "#         \n",
    "#         # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "#         numeric_cols = df.select_dtypes(include='number').columns\n",
    "#         grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "#     \n",
    "#         if 'male_met-met' in df.columns:\n",
    "#             col_ends = ['met-met', 'friend', 'talk-met']\n",
    "#             # Compute averages for male, female, and diverse columns\n",
    "#             male_cols = ['male_' + end for end in col_ends]\n",
    "#             female_cols = ['female_' + end for end in col_ends]\n",
    "#             diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "# \n",
    "#     \n",
    "#             grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "#             grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "#             grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "#             # make sure the three columns add up to 1\n",
    "#             # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "#             # \n",
    "#             # Optionally, drop the original detailed columns if only averages are needed\n",
    "#             grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "# \n",
    "#             \n",
    "#         df_list.append(grouped_df)\n",
    "#     # concat all the dataframes\n",
    "# df = pd.concat(df_list)\n",
    "# df.to_csv(os.path.join(results_dir, 'conversation.csv'), index=False)\n",
    "#     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:22.845255Z",
     "start_time": "2024-06-04T18:13:22.842574Z"
    }
   },
   "id": "e751480d2b8070f5",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if 'genderquestion.csv' in f and 'gpt2' not in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['debiasing_prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            # make sure the three columns add up to 1\n",
    "            # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "            # \n",
    "            # Optionally, drop the original detailed columns if only averages are needed\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'genderquestion.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:23.098762Z",
     "start_time": "2024-06-04T18:13:23.005847Z"
    }
   },
   "id": "6929333781b2efd3",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df_list = []\n",
    "# for f in os.listdir(output_dir):\n",
    "#     if 'genderquestion_conv.csv' in f:\n",
    "#         df = pd.read_csv(os.path.join(output_dir, f))\n",
    "#         df = pd.merge(df,female_ratios,on='job')\n",
    "#         df = df.drop(columns=['job','Unnamed: 0'])\n",
    "#          \n",
    "# \n",
    "#         df['female_dominated'] = df['female_ratio'] > 50\n",
    "#         # Extract prompt ID from filename\n",
    "#         prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "#         prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "#         df['debiasing_prompt_id'] = prompt_id\n",
    "#         \n",
    "#                 # Extract model from filename\n",
    "#         model_str = next((model for model in model_strs if model in f), None)\n",
    "#         df['model'] = model_str\n",
    "#         df['conversation'] = 'conv' in f\n",
    "# \n",
    "#         # Remove model name from other column names\n",
    "#         if model_str:\n",
    "#             df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "# \n",
    "#         \n",
    "#         # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "#         numeric_cols = df.select_dtypes(include='number').columns\n",
    "#         grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "#     \n",
    "#         if 'male_met-met' in df.columns:\n",
    "#             col_ends = ['met-met', 'friend', 'talk-met']\n",
    "#             # Compute averages for male, female, and diverse columns\n",
    "#             male_cols = ['male_' + end for end in col_ends]\n",
    "#             female_cols = ['female_' + end for end in col_ends]\n",
    "#             diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "# \n",
    "#     \n",
    "#             grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "#             grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "#             grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "#             # make sure the three columns add up to 1\n",
    "#             # grouped_df['total'] = grouped_df['male'] + grouped_df['female'] + grouped_df['diverse']\n",
    "#             # \n",
    "#             # Optionally, drop the original detailed columns if only averages are needed\n",
    "#             grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "# \n",
    "#             \n",
    "#         df_list.append(grouped_df)\n",
    "#     # concat all the dataframes\n",
    "# df = pd.concat(df_list)\n",
    "# df.to_csv(os.path.join(results_dir, 'genderquestion_conv.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:23.186535Z",
     "start_time": "2024-06-04T18:13:23.184302Z"
    }
   },
   "id": "97353b98d7dd6a5e",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['llama2-7b-instruct', 'llama2-7b', 'mistral-7b',\n       'llama3-8b-instruct', 'llama3-8b', 'mistral-7b-instruct'],\n      dtype=object)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:23.368220Z",
     "start_time": "2024-06-04T18:13:23.364560Z"
    }
   },
   "id": "e8b094b1d58fc460",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation      male    female  \\\n0              False   llama2-7b-instruct         False  0.118885  0.243215   \n1               True   llama2-7b-instruct         False  0.025260  0.326490   \n0              False            llama2-7b         False  0.066700  0.190445   \n1               True            llama2-7b         False  0.044840  0.245195   \n0              False           mistral-7b         False  0.042675  0.105765   \n..               ...                  ...           ...       ...       ...   \n1               True  mistral-7b-instruct         False  0.008415  0.325820   \n0              False   llama3-8b-instruct         False  0.304505  0.400795   \n1               True   llama3-8b-instruct         False  0.186240  0.583980   \n0              False   llama2-7b-instruct         False  0.261810  0.351445   \n1               True   llama2-7b-instruct         False  0.106900  0.502790   \n\n     diverse  male_prob  female_prob  diverse_prob  female_ratio  \\\n0   0.637920   0.218423     0.457142      1.224341         5.535   \n1   0.648245   0.053856     0.701239      1.464302        89.265   \n0   0.742880   0.094970     0.272386      1.065142         5.535   \n1   0.709965   0.065413     0.355249      1.030877        89.265   \n0   0.851560   0.042873     0.106485      0.866347         5.535   \n..       ...        ...          ...           ...           ...   \n1   0.665775   0.010989     0.406565      0.777257        89.265   \n0   0.294700   0.273480     0.347876      0.247498         5.535   \n1   0.229775   0.178444     0.559818      0.210733        89.265   \n0   0.386760   0.447868     0.600647      0.664409         5.535   \n1   0.390305   0.186738     0.872850      0.687398        89.265   \n\n    debiasing_prompt_id  \n0                   5.0  \n1                   5.0  \n0                   5.0  \n1                   5.0  \n0                   4.0  \n..                  ...  \n1                   4.0  \n0                   4.0  \n1                   4.0  \n0                   3.0  \n1                   3.0  \n\n[84 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>male</th>\n      <th>female</th>\n      <th>diverse</th>\n      <th>male_prob</th>\n      <th>female_prob</th>\n      <th>diverse_prob</th>\n      <th>female_ratio</th>\n      <th>debiasing_prompt_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.118885</td>\n      <td>0.243215</td>\n      <td>0.637920</td>\n      <td>0.218423</td>\n      <td>0.457142</td>\n      <td>1.224341</td>\n      <td>5.535</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.025260</td>\n      <td>0.326490</td>\n      <td>0.648245</td>\n      <td>0.053856</td>\n      <td>0.701239</td>\n      <td>1.464302</td>\n      <td>89.265</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.066700</td>\n      <td>0.190445</td>\n      <td>0.742880</td>\n      <td>0.094970</td>\n      <td>0.272386</td>\n      <td>1.065142</td>\n      <td>5.535</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.044840</td>\n      <td>0.245195</td>\n      <td>0.709965</td>\n      <td>0.065413</td>\n      <td>0.355249</td>\n      <td>1.030877</td>\n      <td>89.265</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.042675</td>\n      <td>0.105765</td>\n      <td>0.851560</td>\n      <td>0.042873</td>\n      <td>0.106485</td>\n      <td>0.866347</td>\n      <td>5.535</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.008415</td>\n      <td>0.325820</td>\n      <td>0.665775</td>\n      <td>0.010989</td>\n      <td>0.406565</td>\n      <td>0.777257</td>\n      <td>89.265</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>0.304505</td>\n      <td>0.400795</td>\n      <td>0.294700</td>\n      <td>0.273480</td>\n      <td>0.347876</td>\n      <td>0.247498</td>\n      <td>5.535</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>0.186240</td>\n      <td>0.583980</td>\n      <td>0.229775</td>\n      <td>0.178444</td>\n      <td>0.559818</td>\n      <td>0.210733</td>\n      <td>89.265</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.261810</td>\n      <td>0.351445</td>\n      <td>0.386760</td>\n      <td>0.447868</td>\n      <td>0.600647</td>\n      <td>0.664409</td>\n      <td>5.535</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.106900</td>\n      <td>0.502790</td>\n      <td>0.390305</td>\n      <td>0.186738</td>\n      <td>0.872850</td>\n      <td>0.687398</td>\n      <td>89.265</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>84 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:23.518349Z",
     "start_time": "2024-06-04T18:13:23.515904Z"
    }
   },
   "id": "1b950e2327d38bf6",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_plain = pd.read_csv(os.path.join(results_dir, 'implicit.csv'))\n",
    "df_conv = pd.read_csv(os.path.join(results_dir, 'conversation.csv'))\n",
    "\n",
    "# if any column starts with a space, remove it\n",
    "df_plain.columns = df_plain.columns.str.strip()\n",
    "df_conv.columns = df_conv.columns.str.strip()\n",
    "\n",
    "df = pd.concat([df_plain, df_conv])\n",
    "for model, group_df in df.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'non_gq.csv'), index=False)\n",
    "\n",
    "    # Optional: Print a message to indicate the file has been saved\n",
    "    # print(f\"Saved {model} non_gq.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:24.035355Z",
     "start_time": "2024-06-04T18:13:24.018711Z"
    }
   },
   "id": "a649ed31f1e5571c",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation  male_met-met_prob  \\\n0              False   llama3-8b-instruct         False           0.364136   \n1               True   llama3-8b-instruct         False           0.034089   \n2              False           mistral-7b         False           0.266743   \n3               True           mistral-7b         False           0.092805   \n4              False            llama2-7b         False           0.219073   \n..               ...                  ...           ...                ...   \n79              True  mistral-7b-instruct          True                NaN   \n80             False       llama2-7b-chat          True                NaN   \n81              True       llama2-7b-chat          True                NaN   \n82             False            llama3-8b          True                NaN   \n83              True            llama3-8b          True                NaN   \n\n    female_met-met_prob  diverse_met-met_prob  male_friend_prob  \\\n0              0.016518              0.018025          0.804092   \n1              0.418602              0.015471          0.052903   \n2              0.080521              0.016623          0.340629   \n3              0.235823              0.018372          0.141831   \n4              0.026362              0.004307          0.410796   \n..                  ...                   ...               ...   \n79                  NaN                   NaN               NaN   \n80                  NaN                   NaN               NaN   \n81                  NaN                   NaN               NaN   \n82                  NaN                   NaN               NaN   \n83                  NaN                   NaN               NaN   \n\n    female_friend_prob  diverse_friend_prob  male_talk-met_prob  ...  \\\n0             0.056074             0.004254            0.844441  ...   \n1             0.862482             0.003430            0.088654  ...   \n2             0.118369             0.010341            0.782206  ...   \n3             0.349621             0.009947            0.321056  ...   \n4             0.037691             0.004513            0.830831  ...   \n..                 ...                  ...                 ...  ...   \n79                 NaN                  NaN                 NaN  ...   \n80                 NaN                  NaN                 NaN  ...   \n81                 NaN                  NaN                 NaN  ...   \n82                 NaN                  NaN                 NaN  ...   \n83                 NaN                  NaN                 NaN  ...   \n\n    prompt_id  alpaca-7b_male_met-met  alpaca-7b_male_friend  \\\n0         NaN                     NaN                    NaN   \n1         NaN                     NaN                    NaN   \n2         NaN                     NaN                    NaN   \n3         NaN                     NaN                    NaN   \n4         NaN                     NaN                    NaN   \n..        ...                     ...                    ...   \n79        4.0                     NaN                    NaN   \n80        2.0                     NaN                    NaN   \n81        2.0                     NaN                    NaN   \n82        0.0                     NaN                    NaN   \n83        0.0                     NaN                    NaN   \n\n    alpaca-7b_male_talk-met  alpaca-7b_female_met-met  \\\n0                       NaN                       NaN   \n1                       NaN                       NaN   \n2                       NaN                       NaN   \n3                       NaN                       NaN   \n4                       NaN                       NaN   \n..                      ...                       ...   \n79                      NaN                       NaN   \n80                      NaN                       NaN   \n81                      NaN                       NaN   \n82                      NaN                       NaN   \n83                      NaN                       NaN   \n\n    alpaca-7b_female_friend  alpaca-7b_female_talk-met  \\\n0                       NaN                        NaN   \n1                       NaN                        NaN   \n2                       NaN                        NaN   \n3                       NaN                        NaN   \n4                       NaN                        NaN   \n..                      ...                        ...   \n79                      NaN                        NaN   \n80                      NaN                        NaN   \n81                      NaN                        NaN   \n82                      NaN                        NaN   \n83                      NaN                        NaN   \n\n    alpaca-7b_diverse_met-met  alpaca-7b_diverse_friend  \\\n0                         NaN                       NaN   \n1                         NaN                       NaN   \n2                         NaN                       NaN   \n3                         NaN                       NaN   \n4                         NaN                       NaN   \n..                        ...                       ...   \n79                        NaN                       NaN   \n80                        NaN                       NaN   \n81                        NaN                       NaN   \n82                        NaN                       NaN   \n83                        NaN                       NaN   \n\n    alpaca-7b_diverse_talk-met  \n0                          NaN  \n1                          NaN  \n2                          NaN  \n3                          NaN  \n4                          NaN  \n..                         ...  \n79                         NaN  \n80                         NaN  \n81                         NaN  \n82                         NaN  \n83                         NaN  \n\n[168 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>male_met-met_prob</th>\n      <th>female_met-met_prob</th>\n      <th>diverse_met-met_prob</th>\n      <th>male_friend_prob</th>\n      <th>female_friend_prob</th>\n      <th>diverse_friend_prob</th>\n      <th>male_talk-met_prob</th>\n      <th>...</th>\n      <th>prompt_id</th>\n      <th>alpaca-7b_male_met-met</th>\n      <th>alpaca-7b_male_friend</th>\n      <th>alpaca-7b_male_talk-met</th>\n      <th>alpaca-7b_female_met-met</th>\n      <th>alpaca-7b_female_friend</th>\n      <th>alpaca-7b_female_talk-met</th>\n      <th>alpaca-7b_diverse_met-met</th>\n      <th>alpaca-7b_diverse_friend</th>\n      <th>alpaca-7b_diverse_talk-met</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>0.364136</td>\n      <td>0.016518</td>\n      <td>0.018025</td>\n      <td>0.804092</td>\n      <td>0.056074</td>\n      <td>0.004254</td>\n      <td>0.844441</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>0.034089</td>\n      <td>0.418602</td>\n      <td>0.015471</td>\n      <td>0.052903</td>\n      <td>0.862482</td>\n      <td>0.003430</td>\n      <td>0.088654</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.266743</td>\n      <td>0.080521</td>\n      <td>0.016623</td>\n      <td>0.340629</td>\n      <td>0.118369</td>\n      <td>0.010341</td>\n      <td>0.782206</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.092805</td>\n      <td>0.235823</td>\n      <td>0.018372</td>\n      <td>0.141831</td>\n      <td>0.349621</td>\n      <td>0.009947</td>\n      <td>0.321056</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.219073</td>\n      <td>0.026362</td>\n      <td>0.004307</td>\n      <td>0.410796</td>\n      <td>0.037691</td>\n      <td>0.004513</td>\n      <td>0.830831</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>False</td>\n      <td>llama2-7b-chat</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>True</td>\n      <td>llama2-7b-chat</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>False</td>\n      <td>llama3-8b</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>True</td>\n      <td>llama3-8b</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>168 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:24.787036Z",
     "start_time": "2024-06-04T18:13:24.781155Z"
    }
   },
   "id": "d34d378bb736b6b5",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_gq_plain = pd.read_csv(os.path.join(results_dir, 'genderquestion.csv'))\n",
    "df_gq_conv = pd.read_csv(os.path.join(results_dir, 'genderquestion_conv.csv'))\n",
    "\n",
    "# if any column starts with a space, remove it\n",
    "df_gq_plain.columns = df_gq_plain.columns.str.strip()\n",
    "df_gq_conv.columns = df_gq_conv.columns.str.strip()\n",
    "\n",
    "df_gq = pd.concat([df_gq_plain, df_gq_conv])\n",
    "for model, group_df in df_gq.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'genderquestion.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:25.300429Z",
     "start_time": "2024-06-04T18:13:25.287678Z"
    }
   },
   "id": "90915c22ac13a2ac",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation      male    female  \\\n0              False   llama2-7b-instruct         False  0.118885  0.243215   \n1               True   llama2-7b-instruct         False  0.025260  0.326490   \n2              False            llama2-7b         False  0.066700  0.190445   \n3               True            llama2-7b         False  0.044840  0.245195   \n4              False           mistral-7b         False  0.042675  0.105765   \n..               ...                  ...           ...       ...       ...   \n79              True  mistral-7b-instruct          True  0.019800  0.038490   \n80             False           mistral-7b          True  0.708945  0.255865   \n81              True           mistral-7b          True  0.353300  0.593430   \n82             False   llama3-8b-instruct          True  0.010045  0.026320   \n83              True   llama3-8b-instruct          True  0.007415  0.021535   \n\n     diverse  male_prob  female_prob  diverse_prob  female_ratio  \\\n0   0.637920   0.218423     0.457142      1.224341         5.535   \n1   0.648245   0.053856     0.701239      1.464302        89.265   \n2   0.742880   0.094970     0.272386      1.065142         5.535   \n3   0.709965   0.065413     0.355249      1.030877        89.265   \n4   0.851560   0.042873     0.106485      0.866347         5.535   \n..       ...        ...          ...           ...           ...   \n79  0.941720        NaN          NaN           NaN        89.265   \n80  0.035170        NaN          NaN           NaN         5.535   \n81  0.053275        NaN          NaN           NaN        89.265   \n82  0.963625        NaN          NaN           NaN         5.535   \n83  0.971060        NaN          NaN           NaN        89.265   \n\n    debiasing_prompt_id  prompt_id  alpaca-7b_male  alpaca-7b_female  \\\n0                   5.0        NaN             NaN               NaN   \n1                   5.0        NaN             NaN               NaN   \n2                   5.0        NaN             NaN               NaN   \n3                   5.0        NaN             NaN               NaN   \n4                   4.0        NaN             NaN               NaN   \n..                  ...        ...             ...               ...   \n79                  NaN        5.0             NaN               NaN   \n80                  NaN        1.0             NaN               NaN   \n81                  NaN        1.0             NaN               NaN   \n82                  NaN        1.0             NaN               NaN   \n83                  NaN        1.0             NaN               NaN   \n\n    alpaca-7b_diverse  \n0                 NaN  \n1                 NaN  \n2                 NaN  \n3                 NaN  \n4                 NaN  \n..                ...  \n79                NaN  \n80                NaN  \n81                NaN  \n82                NaN  \n83                NaN  \n\n[168 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>male</th>\n      <th>female</th>\n      <th>diverse</th>\n      <th>male_prob</th>\n      <th>female_prob</th>\n      <th>diverse_prob</th>\n      <th>female_ratio</th>\n      <th>debiasing_prompt_id</th>\n      <th>prompt_id</th>\n      <th>alpaca-7b_male</th>\n      <th>alpaca-7b_female</th>\n      <th>alpaca-7b_diverse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.118885</td>\n      <td>0.243215</td>\n      <td>0.637920</td>\n      <td>0.218423</td>\n      <td>0.457142</td>\n      <td>1.224341</td>\n      <td>5.535</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.025260</td>\n      <td>0.326490</td>\n      <td>0.648245</td>\n      <td>0.053856</td>\n      <td>0.701239</td>\n      <td>1.464302</td>\n      <td>89.265</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.066700</td>\n      <td>0.190445</td>\n      <td>0.742880</td>\n      <td>0.094970</td>\n      <td>0.272386</td>\n      <td>1.065142</td>\n      <td>5.535</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.044840</td>\n      <td>0.245195</td>\n      <td>0.709965</td>\n      <td>0.065413</td>\n      <td>0.355249</td>\n      <td>1.030877</td>\n      <td>89.265</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.042675</td>\n      <td>0.105765</td>\n      <td>0.851560</td>\n      <td>0.042873</td>\n      <td>0.106485</td>\n      <td>0.866347</td>\n      <td>5.535</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>True</td>\n      <td>0.019800</td>\n      <td>0.038490</td>\n      <td>0.941720</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>89.265</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.708945</td>\n      <td>0.255865</td>\n      <td>0.035170</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.535</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>True</td>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>0.353300</td>\n      <td>0.593430</td>\n      <td>0.053275</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>89.265</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>False</td>\n      <td>llama3-8b-instruct</td>\n      <td>True</td>\n      <td>0.010045</td>\n      <td>0.026320</td>\n      <td>0.963625</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.535</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>True</td>\n      <td>llama3-8b-instruct</td>\n      <td>True</td>\n      <td>0.007415</td>\n      <td>0.021535</td>\n      <td>0.971060</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>89.265</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>168 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:25.928144Z",
     "start_time": "2024-06-04T18:13:25.923889Z"
    }
   },
   "id": "a9ed47d5a5a8cb7c",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "prompt_id_map = {\n",
    "    0: 'None',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6'\n",
    "}\n",
    "\n",
    "abstraction_levels = {\n",
    "    0: '',\n",
    "    1: 'High',\n",
    "    2: 'High',\n",
    "    3: 'Med.',\n",
    "    4: 'Med.',\n",
    "    5: 'Low',\n",
    "    6: 'Low'\n",
    "}\n",
    "\n",
    "abs_order = ['', 'High', 'Med.', 'Low']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:26.317059Z",
     "start_time": "2024-06-04T18:13:26.314111Z"
    }
   },
   "id": "7f353fee7e286d0c",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/aggregated_results.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/972919388.py:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n"
     ]
    }
   ],
   "source": [
    " # Update this to your results directory\n",
    "models = list(model_str_map.keys())\n",
    "\n",
    "output_tex_file = os.path.join(results_dir, 'aggregated_results.tex')\n",
    "\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(r'\\onecolumn')\n",
    "    for model in models:\n",
    "        model_name = model.replace('-', '')\n",
    "        model_description = model_str_map[model]\n",
    "\n",
    "        f_out.write(r'\\subsection{' + model_description + '}\\n')\n",
    "\n",
    "        for csv_file, (caption, label_suffix) in [('genderquestion.csv', ('Probability of gender expressions for task prompt number one. ``ID\\'\\' refers to the id of the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'genderquestion')),\n",
    "                                                  ('non_gq.csv', ('Aggregated results for task prompts two to four. ``ID\\'\\' refers to the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'nongq'))]:\n",
    "            \n",
    "            \n",
    "            # Load the CSV file into a DataFrame\n",
    "            df_path = os.path.join(results_dir, model, csv_file)\n",
    "            df = pd.read_csv(df_path)\n",
    "\n",
    "            # Add the abstraction level column to the DataFrame\n",
    "            df['Abs.'] = df['debiasing_prompt_id'].map(abstraction_levels)\n",
    "\n",
    "            # Calculate means for each combination of prompt_id, conversation, and female_dominated\n",
    "            grouped_df = df.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "            model = grouped_df['model'].unique()[0]\n",
    "\n",
    "            # Drop the 'model' column\n",
    "            model_df = grouped_df.drop(columns=['model'])\n",
    "                        # Sort by Abs. and prompt_id to ensure correct order\n",
    "            model_df['debiasing_prompt_id'] = model_df['debiasing_prompt_id'].astype(int)\n",
    "            model_df['Abs.'] = pd.Categorical(model_df['Abs.'], categories=abs_order, ordered=True)\n",
    "            model_df = model_df.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "\n",
    "            latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){3-8} \\cmidrule(lr){9-14}\n",
    "    & & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-11} \\cmidrule(lr){12-14}\n",
    "        Abs. & ID & M & F & D & M & F & D & M & F & D & M & F & D\\\\\n",
    "        \\midrule\n",
    "'''\n",
    "\n",
    "            # Sort by prompt_id to ensure order from None to 6\n",
    "            model_df['debiasing_prompt_id'] = model_df['debiasing_prompt_id'].astype(int)\n",
    "            model_df = model_df.sort_values(by=['Abs.','debiasing_prompt_id'])\n",
    "\n",
    "            previous_abs_level = None\n",
    "\n",
    "            for abs_level, abs_group in model_df.groupby('Abs.'):\n",
    "                if previous_abs_level is not None:\n",
    "                    latex_table += \"        \\\\midrule\\n\"\n",
    "                for prompt_id, prompt_group in abs_group.groupby('debiasing_prompt_id'):\n",
    "                    id_label = 'None' if prompt_id == 0 else str(prompt_id)\n",
    "                    row_prefix = f\"        {abs_level if prompt_id in [0,2,4,6] else ''} & {id_label} & \"\n",
    "\n",
    "                    no_dialogue_fd = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == True)]\n",
    "                    no_dialogue_md = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == False)]\n",
    "                    dialogue_fd = prompt_group[(prompt_group['conversation'] == True) & (prompt_group['female_dominated'] == True)]\n",
    "                    dialogue_md = prompt_group[(prompt_group['conversation'] == True) & (prompt_group['female_dominated'] == False)]\n",
    "\n",
    "                    row = row_prefix\n",
    "\n",
    "                    if not no_dialogue_fd.empty:\n",
    "                        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not no_dialogue_md.empty:\n",
    "                        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not dialogue_fd.empty:\n",
    "                        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not dialogue_md.empty:\n",
    "                        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "                    else:\n",
    "                        row += \" & & \"\n",
    "\n",
    "                    row += r\"\\\\\"\n",
    "                    latex_table += row + \"\\n\"\n",
    "\n",
    "                if abs_level != '':  # Add averages for all except \"None\"\n",
    "                    avg_row_prefix = f\"         & \\\\textbf{{Avg}} & \"\n",
    "\n",
    "                    avg_no_dialogue_fd = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_no_dialogue_md = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_dialogue_fd = abs_group[(abs_group['conversation'] == True) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_dialogue_md = abs_group[(abs_group['conversation'] == True) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "\n",
    "                    avg_row = avg_row_prefix\n",
    "\n",
    "                    if not avg_no_dialogue_fd.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & & \"\n",
    "\n",
    "                    if not avg_no_dialogue_md.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & & \"\n",
    "\n",
    "                    if not avg_dialogue_fd.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & & \"\n",
    "\n",
    "                    if not avg_dialogue_md.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_dialogue_md['diverse']*100:.1f}\\\\%}} \"\n",
    "                    else:\n",
    "                        avg_row += \" & & \"\n",
    "\n",
    "                    avg_row += r\"\\\\\"\n",
    "                    latex_table += avg_row + \"\\n\"\n",
    "\n",
    "                previous_abs_level = abs_level\n",
    "\n",
    "            latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{''' + caption + r'''}\n",
    "\\label{tab:''' + label_suffix + r'''_''' + model_name + r'''}\n",
    "\\end{table*}\n",
    "\n",
    "'''\n",
    "\n",
    "            f_out.write(latex_table)\n",
    "        f_out.write('\\\\clearpage\\n\\n')\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:28.246400Z",
     "start_time": "2024-06-04T18:13:28.101202Z"
    }
   },
   "id": "262f5966f8e50558",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/aggregated_results_no_diag.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n",
      "/var/folders/h3/mg_n_0ls7kgb1369wvkmb_dh0000gq/T/ipykernel_56556/2463538195.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for abs_level, abs_group in model_df.groupby('Abs.'):\n"
     ]
    }
   ],
   "source": [
    " # Update this to your results directory\n",
    "models = list(model_str_map.keys())\n",
    "\n",
    "output_tex_file = os.path.join(results_dir, 'aggregated_results_no_diag.tex')\n",
    "\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(r'\\onecolumn')\n",
    "    for model in models:\n",
    "        model_name = model.replace('-', '')\n",
    "        model_description = model_str_map[model]\n",
    "\n",
    "        f_out.write(r'\\subsection{' + model_description + '}\\n')\n",
    "\n",
    "        for csv_file, (caption, label_suffix) in [('genderquestion.csv', ('Result for explicit bias (task prompt 1). ``ID\\'\\' refers to the id of the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'genderquestion')),\n",
    "                                                  ('non_gq.csv', ('Result for explicit bias (average over task prompt 2-4). ``ID\\'\\' refers to the debiasing prompt, ``Abs.\\'\\' indicates its degree of abstraction.', 'nongq'))]:\n",
    "            \n",
    "            \n",
    "            # Load the CSV file into a DataFrame\n",
    "            df_path = os.path.join(results_dir, model, csv_file)\n",
    "            df = pd.read_csv(df_path)\n",
    "\n",
    "            # Add the abstraction level column to the DataFrame\n",
    "            df['Abs.'] = df['debiasing_prompt_id'].map(abstraction_levels)\n",
    "\n",
    "            # Calculate means for each combination of prompt_id, conversation, and female_dominated\n",
    "            grouped_df = df.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "            model = grouped_df['model'].unique()[0]\n",
    "\n",
    "            # Drop the 'model' column\n",
    "            model_df = grouped_df.drop(columns=['model'])\n",
    "                        # Sort by Abs. and prompt_id to ensure correct order\n",
    "            model_df['debiasing_prompt_id'] = model_df['debiasing_prompt_id'].astype(int)\n",
    "            model_df['Abs.'] = pd.Categorical(model_df['Abs.'], categories=abs_order, ordered=True)\n",
    "            model_df = model_df.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "\n",
    "            latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c}\n",
    "    \\toprule\n",
    "    & &\\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){3-5} \\cmidrule(lr){6-8}\n",
    "        Abs. & ID & M & F & D & M & F & D \\\\\n",
    "        \\midrule\n",
    "'''\n",
    "\n",
    "            # Sort by prompt_id to ensure order from None to 6\n",
    "            model_df['debiasing_prompt_id'] = model_df['debiasing_prompt_id'].astype(int)\n",
    "            model_df = model_df.sort_values(by=['Abs.','debiasing_prompt_id'])\n",
    "\n",
    "            previous_abs_level = None\n",
    "\n",
    "            for abs_level, abs_group in model_df.groupby('Abs.'):\n",
    "                if previous_abs_level is not None:\n",
    "                    latex_table += \"        \\\\midrule\\n\"\n",
    "                for prompt_id, prompt_group in abs_group.groupby('debiasing_prompt_id'):\n",
    "                    id_label = 'None' if prompt_id == 0 else str(prompt_id)\n",
    "                    row_prefix = f\"        {abs_level if prompt_id in [0,2,4,6] else ''} & {id_label} & \"\n",
    "\n",
    "                    no_dialogue_fd = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == True)]\n",
    "                    no_dialogue_md = prompt_group[(prompt_group['conversation'] == False) & (prompt_group['female_dominated'] == False)]\n",
    "\n",
    "\n",
    "                    row = row_prefix\n",
    "\n",
    "                    if not no_dialogue_fd.empty:\n",
    "                        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                    else:\n",
    "                        row += \" & & & \"\n",
    "\n",
    "                    if not no_dialogue_md.empty:\n",
    "                        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "                    else:\n",
    "                        row += \" & & \"\n",
    "\n",
    "\n",
    "                    row += r\"\\\\\"\n",
    "                    latex_table += row + \"\\n\"\n",
    "\n",
    "                if abs_level != '':  # Add averages for all except \"None\"\n",
    "                    avg_row_prefix = f\"         & \\\\textbf{{Avg}} & \"\n",
    "\n",
    "                    avg_no_dialogue_fd = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                    avg_no_dialogue_md = abs_group[(abs_group['conversation'] == False) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "\n",
    "                    avg_row = avg_row_prefix\n",
    "\n",
    "                    if not avg_no_dialogue_fd.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                    else:\n",
    "                        avg_row += \" & & &\"\n",
    "\n",
    "                    if not avg_no_dialogue_md.empty:\n",
    "                        avg_row += f\"\\\\textbf{{{avg_no_dialogue_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_no_dialogue_md['diverse']*100:.1f}\\\\%}}\"\n",
    "                    else:\n",
    "                        avg_row += \" & & \"\n",
    "\n",
    "\n",
    "\n",
    "                    avg_row += r\"\\\\\"\n",
    "                    latex_table += avg_row + \"\\n\"\n",
    "\n",
    "                previous_abs_level = abs_level\n",
    "\n",
    "            latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{''' + caption + r'''}\n",
    "\\label{tab:''' + label_suffix + r'''_''' + model_name + r'''}\n",
    "\\end{table*}\n",
    "\n",
    "'''\n",
    "\n",
    "            f_out.write(latex_table)\n",
    "        f_out.write('\\\\clearpage\\n\\n')\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:31.306971Z",
     "start_time": "2024-06-04T18:13:31.196604Z"
    }
   },
   "id": "4d9ca328379ec1c3",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:13:34.915464Z",
     "start_time": "2024-06-04T18:13:34.904672Z"
    }
   },
   "id": "1e1bbdb4c5b87be3",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/explicit_default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == True)]\n",
    "    dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_fd.empty:\n",
    "        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_md.empty:\n",
    "        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on explicit bias (Task prompt 1).}\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'explicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:17:07.429381Z",
     "start_time": "2024-06-04T18:17:07.408656Z"
    }
   },
   "id": "d39208ea5f1d3a9c",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/implicit_default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == True)]\n",
    "    dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == True) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_fd.empty:\n",
    "        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_md.empty:\n",
    "        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (Average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:17:03.301415Z",
     "start_time": "2024-06-04T18:17:03.281790Z"
    }
   },
   "id": "2b84e9f84c53cc5a",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "models = [\n",
    "    'llama3-8b', 'llama3-8b-instruct', 'mistral-7b', \n",
    "    'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct',  \n",
    "]\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table_explicit = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    row += r\"\\\\\"\n",
    "    # do not add midrule if model is the last in models\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table_explicit += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table_explicit += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table_explicit += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on explicit bias (task prompt 1).}\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'explicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table_explicit)\n",
    "\n",
    "# print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:38:51.595144Z",
     "start_time": "2024-06-04T18:38:51.579177Z"
    }
   },
   "id": "cfb988ea0fb8997a",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    # do not add midrule if model is the last in models\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table_explicit)\n",
    "    f_out.write('\\n\\n')\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:39:45.282308Z",
     "start_time": "2024-06-04T18:39:45.264801Z"
    }
   },
   "id": "2cb37de0ed62e51a",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}[t]\n",
      "\\centering\n",
      "\\small\n",
      "    % Reduce text size and slightly the gap between columns\n",
      "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
      "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
      "    \\begin{tabular}{l c c c c c c}\n",
      "    \\toprule\n",
      "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
      "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
      "    Model & M & F & D & M & F & D \\\\\n",
      "    \\midrule\n",
      "        Llama3 8B & 30.7\\% & 67.2\\% & 2.1\\% & 89.9\\% & 8.4\\% & 1.7\\% \\\\\n",
      "        \n",
      "        Llama3 8B (Instruct) & 9.9\\% & 85.4\\% & 4.8\\% & 89.6\\% & 4.7\\% & 5.7\\% \\\\\n",
      "        \\midrule\n",
      "        Mistral 7B & 28.3\\% & 68.1\\% & 3.6\\% & 89.2\\% & 7.6\\% & 3.2\\% \\\\\n",
      "        \n",
      "        Mistral 7B (Instruct) & 15.0\\% & 77.8\\% & 7.3\\% & 95.0\\% & 1.9\\% & 3.1\\% \\\\\n",
      "        \\midrule\n",
      "        Llama2 7B & 25.5\\% & 72.4\\% & 2.2\\% & 88.0\\% & 9.9\\% & 2.0\\% \\\\\n",
      "        \n",
      "        Llama2 7B (Instruct) & 15.0\\% & 74.8\\% & 10.2\\% & 88.1\\% & 5.5\\% & 6.4\\% \\\\\n",
      "        \\midrule\n",
      "\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "% } % end \\resizebox\n",
      "\\caption{Results for all models on implicit bias (average over task prompts 2-4).}\n",
      "\\label{tab:implicit_default}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "print(latex_table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-04T18:22:48.321566Z",
     "start_time": "2024-06-04T18:22:48.319998Z"
    }
   },
   "id": "173a7a330f58bf2e",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aa917b5bc18fcc56"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
