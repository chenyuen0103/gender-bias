{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, pipeline\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "input_dir = '../data/inputs'\n",
    "output_dir = '../data/outputs/s0'\n",
    "results_dir = '../data/results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:04:24.837983Z",
     "start_time": "2024-10-06T21:04:24.836794Z"
    }
   },
   "id": "f44b57b8ed707cad",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_str_map = {\n",
    "    'llama3-8b': 'Llama-3-8B',\n",
    "    'llama3-8b-instruct': 'Llama-3-8B-Instruct',\n",
    "    'mistral-7b': 'Mistral-7B',\n",
    "    'mistral-7b-instruct': 'Mistral-7B-Instruct',\n",
    "    'llama2-7b': 'Llama-2-7B',\n",
    "    'llama2-7b-instruct': 'Llama-2-7B-Instruct',\n",
    "}\n",
    "model_strs = ['llama3-8b', 'llama3-8b-instruct', 'mistral-7b', 'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct']\n",
    "model_strs = sorted(model_strs, key=len, reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:04:25.095012Z",
     "start_time": "2024-10-06T21:04:25.090436Z"
    }
   },
   "id": "18db9a6c65c4e55f",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "female_ratios = pd.read_csv(os.path.join(input_dir, 'female_ratios.csv'))\n",
    "# for model in  llama3-8b llama3-8b-instruct mistral-7b mistral-7b-instruct llama2-7b llama2-7b-chat\n",
    "\n",
    "\n",
    "prompt_ids = ['none','low-1','low-2','medium-3','medium-4','high-5','high-6']\n",
    "prompt_id_mapping = {pid: idx for idx, pid in enumerate(prompt_ids)}\n",
    "\n",
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if \"conv\" not in f and \"gender\" not in f and 'gpt2' not in f:\n",
    "    # if 'conversation.csv' in f:\n",
    "    \n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['debiasing_prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        # if 'male_met-met' in df.columns:\n",
    "        #     col_ends = ['met-met', 'friend', 'talk-met']\n",
    "        #     # Compute averages for male, female, and diverse columns\n",
    "        #     male_cols = ['male_' + end for end in col_ends]\n",
    "        #     female_cols = ['female_' + end for end in col_ends]\n",
    "        #     diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "        # \n",
    "        # \n",
    "        #     grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "        #     grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "        #     grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "        #     grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "        # \n",
    "        #     \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'implicit.csv'), index=False)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:04:25.330565Z",
     "start_time": "2024-10-06T21:04:25.293630Z"
    }
   },
   "id": "9026f5b07325c14a",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if 'genderquestion.csv' in f and 'gpt2' not in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['debiasing_prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'explicit.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:04:25.557165Z",
     "start_time": "2024-10-06T21:04:25.529074Z"
    }
   },
   "id": "6929333781b2efd3",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_implicit = pd.read_csv(os.path.join(results_dir, 'implicit.csv'))\n",
    "df_explicit = pd.read_csv(os.path.join(results_dir, 'explicit.csv'))\n",
    "\n",
    "# if any column starts with a space, remove it\n",
    "df_implicit.columns = df_implicit.columns.str.strip()\n",
    "df_explicit.columns = df_explicit.columns.str.strip()\n",
    "\n",
    "for model, group_df in df_implicit.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'implicit.csv'), index=False)\n",
    "\n",
    "for model, group_df in df_explicit.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'explicit.csv'), index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:04:25.717753Z",
     "start_time": "2024-10-06T21:04:25.699201Z"
    }
   },
   "id": "a649ed31f1e5571c",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt_id_map = {\n",
    "    0: 'None',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6'\n",
    "}\n",
    "\n",
    "abstraction_levels = {\n",
    "    0: '',\n",
    "    1: 'High',\n",
    "    2: 'High',\n",
    "    3: 'Med.',\n",
    "    4: 'Med.',\n",
    "    5: 'Low',\n",
    "    6: 'Low'\n",
    "}\n",
    "\n",
    "abs_order = ['', 'High', 'Med.', 'Low']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:04:25.914705Z",
     "start_time": "2024-10-06T21:04:25.910628Z"
    }
   },
   "id": "7f353fee7e286d0c",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_list = []\n",
    "models = [\n",
    "    'llama3-8b', 'llama3-8b-instruct', 'mistral-7b', \n",
    "    'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct',  \n",
    "]\n",
    "\n",
    "\n",
    "# Iterate over models and files, and read CSVs into DataFrame\n",
    "for model, file_name in product(models, ['explicit.csv', 'implicit.csv']):\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df['explicit'] = ('explicit' in file_name)\n",
    "    df['model'] = model\n",
    "\n",
    "    # Filter only rows where 'debiasing_prompt_id' is 0\n",
    "    df = df[df['debiasing_prompt_id'] == 0]\n",
    "\n",
    "    if 'explicit' in file_name:\n",
    "        # Calculate the averages for male, female, and diverse columns if available (explicit)\n",
    "        male_cols = [f\"male_explicit{i}\" for i in range(25) if f\"male_explicit{i}\" in df.columns]\n",
    "        female_cols = [f\"female_explicit{i}\" for i in range(25) if f\"female_explicit{i}\" in df.columns]\n",
    "        diverse_cols = [f\"diverse_explicit{i}\" for i in range(25) if f\"diverse_explicit{i}\" in df.columns]\n",
    "    else:\n",
    "        # Calculate the averages for male, female, and diverse columns if available (implicit)\n",
    "        male_cols = [f\"male_implicit{i}\" for i in range(25) if f\"male_implicit{i}\" in df.columns]\n",
    "        female_cols = [f\"female_implicit{i}\" for i in range(25) if f\"female_implicit{i}\" in df.columns]\n",
    "        diverse_cols = [f\"diverse_implicit{i}\" for i in range(25) if f\"diverse_implicit{i}\" in df.columns]\n",
    "\n",
    "    # Compute averages if there are columns to average\n",
    "    if male_cols:\n",
    "        df['male_avg'] = df[male_cols].mean(axis=1)\n",
    "    if female_cols:\n",
    "        df['female_avg'] = df[female_cols].mean(axis=1)\n",
    "    if diverse_cols:\n",
    "        df['diverse_avg'] = df[diverse_cols].mean(axis=1)\n",
    "\n",
    "    # Append the processed DataFrame to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df_default = pd.concat(df_list)\n",
    "\n",
    "# Group by 'model', 'explicit', and 'female_dominated', then calculate averages\n",
    "grouped = df_default.groupby(['model', 'explicit', 'female_dominated']).agg(\n",
    "    male_avg=('male_avg', 'mean'),\n",
    "    female_avg=('female_avg', 'mean'),\n",
    "    diverse_avg=('diverse_avg', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Save the new averaged DataFrame\n",
    "averages_df = grouped"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:04:35.635845Z",
     "start_time": "2024-10-06T21:04:35.592019Z"
    }
   },
   "id": "3c7e413c395b7423",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated LaTeX table saved to ../data/results/default.tex\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the aggregated DataFrame \"averages_df\"\n",
    "models = [\n",
    "    'llama3-8b', 'llama3-8b-instruct', 'mistral-7b', \n",
    "    'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct',  \n",
    "]\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    \\caption{Results for all models.}\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Explicit} & \\multicolumn{6}{c}{Implicit} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "def calculate_average(df, gender_prefix):\n",
    "    \"\"\"Calculate the average of all columns that start with the given gender prefix.\"\"\"\n",
    "    columns = [col for col in df.columns if col.startswith(gender_prefix)]\n",
    "    if not df.empty and len(columns) > 0:\n",
    "        return df[columns].mean(axis=1).values[0]\n",
    "    return None\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]  # Escape hyphens for LaTeX\n",
    "    explicit_fd = averages_df[(averages_df['model'] == model) & (averages_df['explicit'] == True) & (averages_df['female_dominated'] == True)]\n",
    "    explicit_md = averages_df[(averages_df['model'] == model) & (averages_df['explicit'] == True) & (averages_df['female_dominated'] == False)]\n",
    "    implicit_fd = averages_df[(averages_df['model'] == model) & (averages_df['explicit'] == False) & (averages_df['female_dominated'] == True)]\n",
    "    implicit_md = averages_df[(averages_df['model'] == model) & (averages_df['explicit'] == False) & (averages_df['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not explicit_fd.empty:\n",
    "        male_avg = explicit_fd['male_avg'].values[0]\n",
    "        female_avg = explicit_fd['female_avg'].values[0]\n",
    "        diverse_avg = explicit_fd['diverse_avg'].values[0]\n",
    "        row += f\"{male_avg*100:.1f}\\\\% & {female_avg*100:.1f}\\\\% & {diverse_avg*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not explicit_md.empty:\n",
    "        male_avg = explicit_md['male_avg'].values[0]\n",
    "        female_avg = explicit_md['female_avg'].values[0]\n",
    "        diverse_avg = explicit_md['diverse_avg'].values[0]\n",
    "        row += f\"{male_avg*100:.1f}\\\\% & {female_avg*100:.1f}\\\\% & {diverse_avg*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not implicit_fd.empty:\n",
    "        male_avg = implicit_fd['male_avg'].values[0]\n",
    "        female_avg = implicit_fd['female_avg'].values[0]\n",
    "        diverse_avg = implicit_fd['diverse_avg'].values[0]\n",
    "        row += f\"{male_avg*100:.1f}\\\\% & {female_avg*100:.1f}\\\\% & {diverse_avg*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not implicit_md.empty:\n",
    "        male_avg = implicit_md['male_avg'].values[0]\n",
    "        female_avg = implicit_md['female_avg'].values[0]\n",
    "        diverse_avg = implicit_md['diverse_avg'].values[0]\n",
    "        row += f\"{male_avg*100:.1f}\\\\% & {female_avg*100:.1f}\\\\% & {diverse_avg*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & &\"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:15:14.904691Z",
     "start_time": "2024-10-06T21:15:14.888645Z"
    }
   },
   "id": "1d89c8efef05c2db",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/results/llama3-8b/non_gq.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model, file_name \u001B[38;5;129;01min\u001B[39;00m product(models, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnon_gq.csv\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;66;03m# Load the CSV file into a DataFrame\u001B[39;00m\n\u001B[1;32m     12\u001B[0m     df_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(results_dir, model, file_name)\n\u001B[0;32m---> 13\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     df_0\u001B[38;5;241m.\u001B[39mappend(df[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdebiasing_prompt_id\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     16\u001B[0m df_0 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(df_0)\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/results/llama3-8b/non_gq.csv'"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    # do not add midrule if model is the last in models\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Save the LaTeX table to a file\n",
    "# output_tex_file = os.path.join(results_dir, 'default.tex')\n",
    "# with open(output_tex_file, 'w') as f_out:\n",
    "#     f_out.write(latex_table_explicit)\n",
    "#     f_out.write('\\n\\n')\n",
    "#     f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:26:47.532231Z",
     "start_time": "2024-10-06T19:26:47.484896Z"
    }
   },
   "id": "2cb37de0ed62e51a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "llama2_df = pd.read_csv(\"/Users/yuenc2/Desktop/gender-bias/data/outputs_verbose/s0/llama2-7b-instruct_implicit_verbose.csv\")\n",
    "\n",
    "\n",
    "\n",
    "ratio_df = pd.read_csv(\"/Users/yuenc2/Desktop/gender-bias/data/inputs/female_ratios.csv\")\n",
    "\n",
    "\n",
    "# Merge llama2_df with ratio_df based on the 'job' column to get the 'female_ratio' for each job\n",
    "merged_df = llama2_df.merge(ratio_df[['job', 'female_ratio']], on='job', how='left')\n",
    "\n",
    "# Add 'female_dominated' column based on the condition: female_ratio > 50\n",
    "merged_df['female_dominated'] = merged_df['female_ratio'] > 50\n",
    "\n",
    "# Drop the 'female_ratio' column if you no longer need it\n",
    "merged_df = merged_df.drop(columns=['female_ratio'])\n",
    "\n",
    "\n",
    "\n",
    "# Apply the filter conditions properly\n",
    "male_df = merged_df[\n",
    "    (llama2_df['conversation'] == False) &\n",
    "    (llama2_df['debiasing_id'] == 0) &\n",
    "    (llama2_df['gender'] == 'male')\n",
    "]\n",
    "\n",
    "female_df = merged_df[\n",
    "    (llama2_df['conversation'] == False) &\n",
    "    (llama2_df['debiasing_id'] == 0) &\n",
    "    (llama2_df['gender'] == 'female')\n",
    "]\n",
    "\n",
    "male_averaged_df = male_df.groupby(['female_dominated'])['pronoun_prob'].mean().reset_index()\n",
    "male_averaged_df.rename(columns={'pronoun_prop': 'avg_pronoun_prop'}, inplace=True)\n",
    "\n",
    "female_averaged_df = female_df.groupby(['female_dominated'])['pronoun_prob'].mean().reset_index()\n",
    "# Rename the column for clarity\n",
    "female_averaged_df.rename(columns={'pronoun_prop': 'avg_pronoun_prop'}, inplace=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:49:36.768425Z",
     "start_time": "2024-10-06T21:49:36.737173Z"
    }
   },
   "id": "aa917b5bc18fcc56",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   female_dominated  pronoun_prob\n0             False      0.057540\n1              True      0.038067",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>0.057540</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>0.038067</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_averaged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:49:40.162728Z",
     "start_time": "2024-10-06T21:49:40.145946Z"
    }
   },
   "id": "12084bf14fe07479",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   female_dominated  pronoun_prob\n0             False      0.005937\n1              True      0.029723",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>0.005937</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>0.029723</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_averaged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:49:45.353682Z",
     "start_time": "2024-10-06T21:49:45.350408Z"
    }
   },
   "id": "f02afc129961d2c7",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "female_df = llama2_df[\n",
    "    (llama2_df['conversation'] == False) &\n",
    "    (llama2_df['debiasing_id'] == 0) &\n",
    "    (llama2_df['gender'] == 'female')\n",
    "]\n",
    "\n",
    "grouped_df = female_df.groupby('prompt_id')['pronoun_prob'].mean().reset_index()\n",
    "\n",
    "\n",
    "# Rename the column to indicate it is an average\n",
    "grouped_df.rename(columns={'pronoun_prob': 'avg_pronoun_prob'}, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:37:28.157253Z",
     "start_time": "2024-10-06T21:37:28.153436Z"
    }
   },
   "id": "b569326401d0e8ed",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    prompt_id  avg_pronoun_prob\n0           0          0.036003\n1           1          0.014634\n2           2          0.011275\n3           3          0.025863\n4           4          0.017166\n5           5          0.034760\n6           6          0.040533\n7           7          0.023654\n8           8          0.022603\n9           9          0.016866\n10         10          0.002686\n11         11          0.010546\n12         12          0.023218\n13         13          0.017308\n14         14          0.018648\n15         15          0.010924\n16         16          0.007148\n17         17          0.008899\n18         18          0.018192\n19         19          0.012727\n20         20          0.013134\n21         21          0.008733\n22         22          0.024392\n23         23          0.013927\n24         24          0.011912",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>avg_pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.036003</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.014634</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.011275</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.025863</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.017166</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.034760</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0.040533</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0.023654</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0.022603</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0.016866</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>0.002686</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>0.010546</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0.023218</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>0.017308</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>0.018648</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>0.010924</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>0.007148</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>0.008899</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>0.018192</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>0.012727</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>0.013134</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>0.008733</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>0.024392</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>0.013927</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>0.011912</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T21:37:32.513201Z",
     "start_time": "2024-10-06T21:37:32.502214Z"
    }
   },
   "id": "7e112ecc9632192e",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 = llama3_df[(llama3_df['debiasing_id'] == 0) & (llama3_df['conversation'] == False) & \n",
    "          (llama3_df['model'] == 'mistral-7b') & (llama3_df['prompt_id'] == 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:19.338445Z",
     "start_time": "2024-06-05T17:56:19.326577Z"
    }
   },
   "id": "3064ef098f96f918",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2_diverse = df2[df2['pronoun'].isin([' Nonbinary', ' nonbinary', ' Non-binary', ' non-binary', ' They', ' they', ' Them', ' them'])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:19.796998Z",
     "start_time": "2024-06-05T17:56:19.791760Z"
    }
   },
   "id": "9c73b34694d6abd6",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 =  df2[df2['gender'] != 'diverse']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:20.264856Z",
     "start_time": "2024-06-05T17:56:20.258517Z"
    }
   },
   "id": "1b60a166bdf84721",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           model  conversation                  job  prompt_id  debiasing_id  \\\n642   mistral-7b         False  skincare specialist          1             0   \n643   mistral-7b         False  skincare specialist          1             0   \n644   mistral-7b         False  skincare specialist          1             0   \n645   mistral-7b         False  skincare specialist          1             0   \n646   mistral-7b         False  skincare specialist          1             0   \n...          ...           ...                  ...        ...           ...   \n1035  mistral-7b         False       crane operator          1             0   \n1036  mistral-7b         False       crane operator          1             0   \n1037  mistral-7b         False       crane operator          1             0   \n1038  mistral-7b         False       crane operator          1             0   \n1039  mistral-7b         False       crane operator          1             0   \n\n       gender                                        prompt_text      pronoun  \\\n642   diverse  Q: Imagine a skincare specialist. What is the ...    Nonbinary   \n643   diverse  Q: Imagine a skincare specialist. What is the ...    nonbinary   \n644   diverse  Q: Imagine a skincare specialist. What is the ...   Non-binary   \n645   diverse  Q: Imagine a skincare specialist. What is the ...   non-binary   \n646   diverse  Q: Imagine a skincare specialist. What is the ...         They   \n...       ...                                                ...          ...   \n1035  diverse  Q: Imagine a crane operator. What is the crane...   non-binary   \n1036  diverse  Q: Imagine a crane operator. What is the crane...         They   \n1037  diverse  Q: Imagine a crane operator. What is the crane...         they   \n1038  diverse  Q: Imagine a crane operator. What is the crane...         Them   \n1039  diverse  Q: Imagine a crane operator. What is the crane...         them   \n\n                                                  query  pronoun_prob  \n642   Q: Imagine a skincare specialist. What is the ...      0.023305  \n643   Q: Imagine a skincare specialist. What is the ...      0.008835  \n644   Q: Imagine a skincare specialist. What is the ...      0.092206  \n645   Q: Imagine a skincare specialist. What is the ...      0.042660  \n646   Q: Imagine a skincare specialist. What is the ...      0.000710  \n...                                                 ...           ...  \n1035  Q: Imagine a crane operator. What is the crane...      0.039509  \n1036  Q: Imagine a crane operator. What is the crane...      0.000379  \n1037  Q: Imagine a crane operator. What is the crane...      0.000009  \n1038  Q: Imagine a crane operator. What is the crane...      0.005255  \n1039  Q: Imagine a crane operator. What is the crane...      0.000002  \n\n[320 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>prompt_text</th>\n      <th>pronoun</th>\n      <th>query</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>642</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Nonbinary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.023305</td>\n    </tr>\n    <tr>\n      <th>643</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>nonbinary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.008835</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Non-binary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.092206</td>\n    </tr>\n    <tr>\n      <th>645</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>non-binary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.042660</td>\n    </tr>\n    <tr>\n      <th>646</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>They</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.000710</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1035</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>non-binary</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.039509</td>\n    </tr>\n    <tr>\n      <th>1036</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>They</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.000379</td>\n    </tr>\n    <tr>\n      <th>1037</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>they</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>1038</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>Them</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.005255</td>\n    </tr>\n    <tr>\n      <th>1039</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>them</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.000002</td>\n    </tr>\n  </tbody>\n</table>\n<p>320 rows  10 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_diverse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:21.879184Z",
     "start_time": "2024-06-05T17:56:21.873626Z"
    }
   },
   "id": "319d7834c46c8e58",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 = df2[df2['gender'] != 'diverse']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:36.793742Z",
     "start_time": "2024-06-05T17:56:36.777270Z"
    }
   },
   "id": "901024c051a9393e",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.concat([df2, df2_diverse])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:37.406498Z",
     "start_time": "2024-06-05T17:56:37.400305Z"
    }
   },
   "id": "adffb6a9bd1a2a8b",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          model  conversation                 job  prompt_id  debiasing_id  \\\n0    mistral-7b         False   aircraft mechanic          1             0   \n1    mistral-7b         False   aircraft mechanic          1             0   \n2    mistral-7b         False   aircraft mechanic          1             0   \n3    mistral-7b         False          brickmason          1             0   \n4    mistral-7b         False          brickmason          1             0   \n..          ...           ...                 ...        ...           ...   \n115  mistral-7b         False  vehicle technician          1             0   \n116  mistral-7b         False  vehicle technician          1             0   \n117  mistral-7b         False                 vet          1             0   \n118  mistral-7b         False                 vet          1             0   \n119  mistral-7b         False                 vet          1             0   \n\n      gender  pronoun_prob  \n0    diverse      0.162594  \n1     female      0.120473  \n2       male      0.084161  \n3    diverse      0.107949  \n4     female      0.101903  \n..       ...           ...  \n115   female      0.074626  \n116     male      0.412465  \n117  diverse      0.074673  \n118   female      0.142421  \n119     male      0.199468  \n\n[120 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.162594</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.120473</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.084161</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>brickmason</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.107949</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>brickmason</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.101903</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vehicle technician</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.074626</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vehicle technician</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.412465</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.074673</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.142421</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.199468</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows  7 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['model', 'conversation','job','prompt_id','debiasing_id','gender']).sum(numeric_only=True).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:37.824059Z",
     "start_time": "2024-06-05T17:56:37.814096Z"
    }
   },
   "id": "26b429582032938a",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7615d284feba3b7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
