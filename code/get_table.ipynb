{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, pipeline\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "input_dir = '../data/inputs'\n",
    "output_dir = '../data/outputs/s0'\n",
    "results_dir = '../data/results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:25:23.457162Z",
     "start_time": "2024-10-06T19:25:16.453609Z"
    }
   },
   "id": "f44b57b8ed707cad",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_str_map = {\n",
    "    'llama3-8b': 'Llama-3-8B',\n",
    "    'llama3-8b-instruct': 'Llama-3-8B-Instruct',\n",
    "    'mistral-7b': 'Mistral-7B',\n",
    "    'mistral-7b-instruct': 'Mistral-7B-Instruct',\n",
    "    'llama2-7b': 'Llama-2-7B',\n",
    "    'llama2-7b-instruct': 'Llama-2-7B-Instruct',\n",
    "}\n",
    "model_strs = ['llama3-8b', 'llama3-8b-instruct', 'mistral-7b', 'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct']\n",
    "model_strs = sorted(model_strs, key=len, reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:25:23.463908Z",
     "start_time": "2024-10-06T19:25:23.457941Z"
    }
   },
   "id": "18db9a6c65c4e55f",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "female_ratios = pd.read_csv(os.path.join(input_dir, 'female_ratios.csv'))\n",
    "# for model in  llama3-8b llama3-8b-instruct mistral-7b mistral-7b-instruct llama2-7b llama2-7b-chat\n",
    "\n",
    "\n",
    "prompt_ids = ['none','low-1','low-2','medium-3','medium-4','high-5','high-6']\n",
    "prompt_id_mapping = {pid: idx for idx, pid in enumerate(prompt_ids)}\n",
    "\n",
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if \"conv\" not in f and \"gender\" not in f and 'gpt2' not in f:\n",
    "    # if 'conversation.csv' in f:\n",
    "    \n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['debiasing_prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        # if 'male_met-met' in df.columns:\n",
    "        #     col_ends = ['met-met', 'friend', 'talk-met']\n",
    "        #     # Compute averages for male, female, and diverse columns\n",
    "        #     male_cols = ['male_' + end for end in col_ends]\n",
    "        #     female_cols = ['female_' + end for end in col_ends]\n",
    "        #     diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "        # \n",
    "        # \n",
    "        #     grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "        #     grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "        #     grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "        #     grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "        # \n",
    "        #     \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'implicit.csv'), index=False)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:25:23.509359Z",
     "start_time": "2024-10-06T19:25:23.464307Z"
    }
   },
   "id": "9026f5b07325c14a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if 'genderquestion.csv' in f and 'gpt2' not in f:\n",
    "        df = pd.read_csv(os.path.join(output_dir, f))\n",
    "        df = pd.merge(df,female_ratios,on='job')\n",
    "        df = df.drop(columns=['job','Unnamed: 0'])\n",
    "\n",
    "\n",
    "        df['female_dominated'] = df['female_ratio'] > 50\n",
    "        # Extract prompt ID from filename\n",
    "        prompt_id_str = next((pid for pid in prompt_ids if pid in f), 'none')\n",
    "        prompt_id = prompt_id_mapping[prompt_id_str]\n",
    "        df['debiasing_prompt_id'] = prompt_id\n",
    "        \n",
    "                # Extract model from filename\n",
    "        model_str = next((model for model in model_strs if model in f), None)\n",
    "        df['model'] = model_str\n",
    "        df['conversation'] = 'conv' in f\n",
    "\n",
    "        # Remove model name from other column names\n",
    "        if model_str:\n",
    "            df = df.rename(columns=lambda x: x.replace(f'{model_str}_', '') if model_str in x else x)\n",
    "\n",
    "        \n",
    "        # grouped_df = df.groupby('female_dominated').mean().reset_index()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        grouped_df = df.groupby(['female_dominated', 'model','conversation'])[numeric_cols].mean().reset_index()\n",
    "    \n",
    "        if 'male_met-met' in df.columns:\n",
    "            col_ends = ['met-met', 'friend', 'talk-met']\n",
    "            # Compute averages for male, female, and diverse columns\n",
    "            male_cols = ['male_' + end for end in col_ends]\n",
    "            female_cols = ['female_' + end for end in col_ends]\n",
    "            diverse_cols = ['diverse_' + end for end in col_ends]\n",
    "\n",
    "    \n",
    "            grouped_df['male'] = grouped_df[male_cols].mean(axis=1)\n",
    "            grouped_df['female'] = grouped_df[female_cols].mean(axis=1)\n",
    "            grouped_df['diverse'] = grouped_df[diverse_cols].mean(axis=1)\n",
    "            grouped_df = grouped_df.drop(columns=male_cols + female_cols + diverse_cols)\n",
    "\n",
    "            \n",
    "        df_list.append(grouped_df)\n",
    "    # concat all the dataframes\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(os.path.join(results_dir, 'explicit.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:25:23.598195Z",
     "start_time": "2024-10-06T19:25:23.522705Z"
    }
   },
   "id": "6929333781b2efd3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_implicit = pd.read_csv(os.path.join(results_dir, 'implicit.csv'))\n",
    "df_explicit = pd.read_csv(os.path.join(results_dir, 'explicit.csv'))\n",
    "\n",
    "# if any column starts with a space, remove it\n",
    "df_implicit.columns = df_implicit.columns.str.strip()\n",
    "df_explicit.columns = df_explicit.columns.str.strip()\n",
    "\n",
    "for model, group_df in df_implicit.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'implicit.csv'), index=False)\n",
    "\n",
    "for model, group_df in df_explicit.groupby('model'):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    if not os.path.exists(os.path.join(results_dir,model)):\n",
    "        os.makedirs(os.path.join(results_dir,model))\n",
    "    group_df.to_csv(os.path.join(results_dir,model, f'explicit.csv'), index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:25:23.607416Z",
     "start_time": "2024-10-06T19:25:23.562051Z"
    }
   },
   "id": "a649ed31f1e5571c",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt_id_map = {\n",
    "    0: 'None',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6'\n",
    "}\n",
    "\n",
    "abstraction_levels = {\n",
    "    0: '',\n",
    "    1: 'High',\n",
    "    2: 'High',\n",
    "    3: 'Med.',\n",
    "    4: 'Med.',\n",
    "    5: 'Low',\n",
    "    6: 'Low'\n",
    "}\n",
    "\n",
    "abs_order = ['', 'High', 'Med.', 'Low']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:25:23.608213Z",
     "start_time": "2024-10-06T19:25:23.579699Z"
    }
   },
   "id": "7f353fee7e286d0c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_implicit = pd.read_csv(os.path.join(results_dir, 'implicit.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:25:23.609341Z",
     "start_time": "2024-10-06T19:25:23.582765Z"
    }
   },
   "id": "3e5ff3a42c55752e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    female_dominated                model  conversation  male_implicit0  \\\n0              False   llama3-8b-instruct         False        0.000775   \n1               True   llama3-8b-instruct         False        0.000525   \n2              False            llama2-7b         False        0.524950   \n3               True            llama2-7b         False        0.309295   \n4              False            llama3-8b         False        0.003960   \n5               True            llama3-8b         False        0.002415   \n6              False  mistral-7b-instruct         False        0.631950   \n7               True  mistral-7b-instruct         False        0.107325   \n8              False           mistral-7b         False        0.655560   \n9               True           mistral-7b         False        0.402575   \n10             False   llama2-7b-instruct         False        0.751795   \n11              True   llama2-7b-instruct         False        0.346575   \n\n    male_implicit1  male_implicit2  male_implicit3  male_implicit4  \\\n0         0.000630        0.000395        0.000825        0.000505   \n1         0.000185        0.000115        0.000540        0.000295   \n2         0.606105        0.657080        0.683190        0.582205   \n3         0.315570        0.263420        0.254415        0.276610   \n4         0.001920        0.002055        0.003990        0.001945   \n5         0.001040        0.001300        0.001600        0.001065   \n6         0.741570        0.671600        0.637925        0.820675   \n7         0.128715        0.137015        0.071125        0.083530   \n8         0.799370        0.852785        0.847500        0.763150   \n9         0.402555        0.430565        0.404570        0.410720   \n10        0.730755        0.429470        0.791280        0.664970   \n11        0.387880        0.224240        0.422385        0.338205   \n\n    male_implicit5  male_implicit6  ...  female_implicit22_prob  \\\n0         0.001000        0.000650  ...                0.907915   \n1         0.000625        0.000270  ...                0.984810   \n2         0.593740        0.713090  ...                0.000025   \n3         0.339860        0.258525  ...                0.000090   \n4         0.003300        0.001785  ...                0.483366   \n5         0.001770        0.001140  ...                0.647473   \n6         0.686785        0.774285  ...                0.000002   \n7         0.103150        0.107690  ...                0.000056   \n8         0.751410        0.879840  ...                0.000039   \n9         0.453205        0.499790  ...                0.000174   \n10        0.695895        0.574780  ...                0.000019   \n11        0.363155        0.276565  ...                0.000075   \n\n    diverse_implicit22_prob  male_implicit23_prob  female_implicit23_prob  \\\n0                  0.000004              0.000324                0.956565   \n1                  0.000006              0.000127                0.983303   \n2                  0.000004              0.000048                0.000023   \n3                  0.000006              0.000045                0.000080   \n4                  0.000214              0.000654                0.431845   \n5                  0.000223              0.000482                0.575052   \n6                  0.000021              0.000076                0.000003   \n7                  0.000031              0.000032                0.000040   \n8                  0.000029              0.000283                0.000041   \n9                  0.000029              0.000148                0.000117   \n10                 0.000033              0.000014                0.000008   \n11                 0.000032              0.000013                0.000027   \n\n    diverse_implicit23_prob  male_implicit24_prob  female_implicit24_prob  \\\n0                  0.000082              0.000344                0.734588   \n1                  0.000085              0.000165                0.878671   \n2                  0.000011              0.000099                0.000018   \n3                  0.000013              0.000054                0.000122   \n4                  0.000244              0.000223                0.331746   \n5                  0.000205              0.000169                0.461245   \n6                  0.000017              0.000026                0.000001   \n7                  0.000053              0.000004                0.000032   \n8                  0.000029              0.000081                0.000014   \n9                  0.000026              0.000048                0.000060   \n10                 0.000021              0.000032                0.000004   \n11                 0.000024              0.000024                0.000023   \n\n    diverse_implicit24_prob  female_ratio  debiasing_prompt_id  \n0                  0.000057         5.535                  0.0  \n1                  0.000046        89.265                  0.0  \n2                  0.000007         5.535                  0.0  \n3                  0.000006        89.265                  0.0  \n4                  0.000080         5.535                  0.0  \n5                  0.000078        89.265                  0.0  \n6                  0.000031         5.535                  0.0  \n7                  0.000037        89.265                  0.0  \n8                  0.000033         5.535                  0.0  \n9                  0.000028        89.265                  0.0  \n10                 0.000011         5.535                  0.0  \n11                 0.000010        89.265                  0.0  \n\n[12 rows x 155 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>female_dominated</th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>male_implicit0</th>\n      <th>male_implicit1</th>\n      <th>male_implicit2</th>\n      <th>male_implicit3</th>\n      <th>male_implicit4</th>\n      <th>male_implicit5</th>\n      <th>male_implicit6</th>\n      <th>...</th>\n      <th>female_implicit22_prob</th>\n      <th>diverse_implicit22_prob</th>\n      <th>male_implicit23_prob</th>\n      <th>female_implicit23_prob</th>\n      <th>diverse_implicit23_prob</th>\n      <th>male_implicit24_prob</th>\n      <th>female_implicit24_prob</th>\n      <th>diverse_implicit24_prob</th>\n      <th>female_ratio</th>\n      <th>debiasing_prompt_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>0.000775</td>\n      <td>0.000630</td>\n      <td>0.000395</td>\n      <td>0.000825</td>\n      <td>0.000505</td>\n      <td>0.001000</td>\n      <td>0.000650</td>\n      <td>...</td>\n      <td>0.907915</td>\n      <td>0.000004</td>\n      <td>0.000324</td>\n      <td>0.956565</td>\n      <td>0.000082</td>\n      <td>0.000344</td>\n      <td>0.734588</td>\n      <td>0.000057</td>\n      <td>5.535</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>0.000525</td>\n      <td>0.000185</td>\n      <td>0.000115</td>\n      <td>0.000540</td>\n      <td>0.000295</td>\n      <td>0.000625</td>\n      <td>0.000270</td>\n      <td>...</td>\n      <td>0.984810</td>\n      <td>0.000006</td>\n      <td>0.000127</td>\n      <td>0.983303</td>\n      <td>0.000085</td>\n      <td>0.000165</td>\n      <td>0.878671</td>\n      <td>0.000046</td>\n      <td>89.265</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.524950</td>\n      <td>0.606105</td>\n      <td>0.657080</td>\n      <td>0.683190</td>\n      <td>0.582205</td>\n      <td>0.593740</td>\n      <td>0.713090</td>\n      <td>...</td>\n      <td>0.000025</td>\n      <td>0.000004</td>\n      <td>0.000048</td>\n      <td>0.000023</td>\n      <td>0.000011</td>\n      <td>0.000099</td>\n      <td>0.000018</td>\n      <td>0.000007</td>\n      <td>5.535</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>0.309295</td>\n      <td>0.315570</td>\n      <td>0.263420</td>\n      <td>0.254415</td>\n      <td>0.276610</td>\n      <td>0.339860</td>\n      <td>0.258525</td>\n      <td>...</td>\n      <td>0.000090</td>\n      <td>0.000006</td>\n      <td>0.000045</td>\n      <td>0.000080</td>\n      <td>0.000013</td>\n      <td>0.000054</td>\n      <td>0.000122</td>\n      <td>0.000006</td>\n      <td>89.265</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>0.003960</td>\n      <td>0.001920</td>\n      <td>0.002055</td>\n      <td>0.003990</td>\n      <td>0.001945</td>\n      <td>0.003300</td>\n      <td>0.001785</td>\n      <td>...</td>\n      <td>0.483366</td>\n      <td>0.000214</td>\n      <td>0.000654</td>\n      <td>0.431845</td>\n      <td>0.000244</td>\n      <td>0.000223</td>\n      <td>0.331746</td>\n      <td>0.000080</td>\n      <td>5.535</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>True</td>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>0.002415</td>\n      <td>0.001040</td>\n      <td>0.001300</td>\n      <td>0.001600</td>\n      <td>0.001065</td>\n      <td>0.001770</td>\n      <td>0.001140</td>\n      <td>...</td>\n      <td>0.647473</td>\n      <td>0.000223</td>\n      <td>0.000482</td>\n      <td>0.575052</td>\n      <td>0.000205</td>\n      <td>0.000169</td>\n      <td>0.461245</td>\n      <td>0.000078</td>\n      <td>89.265</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>False</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.631950</td>\n      <td>0.741570</td>\n      <td>0.671600</td>\n      <td>0.637925</td>\n      <td>0.820675</td>\n      <td>0.686785</td>\n      <td>0.774285</td>\n      <td>...</td>\n      <td>0.000002</td>\n      <td>0.000021</td>\n      <td>0.000076</td>\n      <td>0.000003</td>\n      <td>0.000017</td>\n      <td>0.000026</td>\n      <td>0.000001</td>\n      <td>0.000031</td>\n      <td>5.535</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>True</td>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>0.107325</td>\n      <td>0.128715</td>\n      <td>0.137015</td>\n      <td>0.071125</td>\n      <td>0.083530</td>\n      <td>0.103150</td>\n      <td>0.107690</td>\n      <td>...</td>\n      <td>0.000056</td>\n      <td>0.000031</td>\n      <td>0.000032</td>\n      <td>0.000040</td>\n      <td>0.000053</td>\n      <td>0.000004</td>\n      <td>0.000032</td>\n      <td>0.000037</td>\n      <td>89.265</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>False</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.655560</td>\n      <td>0.799370</td>\n      <td>0.852785</td>\n      <td>0.847500</td>\n      <td>0.763150</td>\n      <td>0.751410</td>\n      <td>0.879840</td>\n      <td>...</td>\n      <td>0.000039</td>\n      <td>0.000029</td>\n      <td>0.000283</td>\n      <td>0.000041</td>\n      <td>0.000029</td>\n      <td>0.000081</td>\n      <td>0.000014</td>\n      <td>0.000033</td>\n      <td>5.535</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>True</td>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>0.402575</td>\n      <td>0.402555</td>\n      <td>0.430565</td>\n      <td>0.404570</td>\n      <td>0.410720</td>\n      <td>0.453205</td>\n      <td>0.499790</td>\n      <td>...</td>\n      <td>0.000174</td>\n      <td>0.000029</td>\n      <td>0.000148</td>\n      <td>0.000117</td>\n      <td>0.000026</td>\n      <td>0.000048</td>\n      <td>0.000060</td>\n      <td>0.000028</td>\n      <td>89.265</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>False</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.751795</td>\n      <td>0.730755</td>\n      <td>0.429470</td>\n      <td>0.791280</td>\n      <td>0.664970</td>\n      <td>0.695895</td>\n      <td>0.574780</td>\n      <td>...</td>\n      <td>0.000019</td>\n      <td>0.000033</td>\n      <td>0.000014</td>\n      <td>0.000008</td>\n      <td>0.000021</td>\n      <td>0.000032</td>\n      <td>0.000004</td>\n      <td>0.000011</td>\n      <td>5.535</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>True</td>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>0.346575</td>\n      <td>0.387880</td>\n      <td>0.224240</td>\n      <td>0.422385</td>\n      <td>0.338205</td>\n      <td>0.363155</td>\n      <td>0.276565</td>\n      <td>...</td>\n      <td>0.000075</td>\n      <td>0.000032</td>\n      <td>0.000013</td>\n      <td>0.000027</td>\n      <td>0.000024</td>\n      <td>0.000024</td>\n      <td>0.000023</td>\n      <td>0.000010</td>\n      <td>89.265</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>12 rows Ã— 155 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_implicit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:25:23.611097Z",
     "start_time": "2024-10-06T19:25:23.595092Z"
    }
   },
   "id": "47868b7cec53e33a",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abstraction_levels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 20\u001B[0m\n\u001B[1;32m     15\u001B[0m df_explicit \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(results_dir, model, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexplicit.csv\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Add the abstraction level column to the DataFrame\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m df_implicit[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbs.\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_implicit[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdebiasing_prompt_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmap(\u001B[43mabstraction_levels\u001B[49m)\n\u001B[1;32m     21\u001B[0m df_explicit[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbs.\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_explicit[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdebiasing_prompt_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmap(abstraction_levels)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Calculate means for each combination of prompt_id, conversation, and female_dominated\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'abstraction_levels' is not defined"
     ]
    }
   ],
   "source": [
    " # Update this to your results directory\n",
    "models = list(model_str_map.keys())\n",
    "\n",
    "output_tex_file = os.path.join(results_dir, model, 'aggregated_results.tex')\n",
    "\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(r'\\onecolumn')\n",
    "    for model in models:\n",
    "        model_name = model.replace('-', '')\n",
    "        model_description = model_str_map[model]\n",
    "\n",
    "        f_out.write(r'\\subsection{' + model_description + '}\\n')\n",
    "        # Load the CSV file into a DataFrame\n",
    "        df_implicit = pd.read_csv(os.path.join(results_dir, model, 'implicit.csv'))\n",
    "        df_explicit = pd.read_csv(os.path.join(results_dir, model, 'explicit.csv'))\n",
    "        \n",
    "        \n",
    "\n",
    "        # Add the abstraction level column to the DataFrame\n",
    "        df_implicit['Abs.'] = df_implicit['debiasing_prompt_id'].map(abstraction_levels)\n",
    "        df_explicit['Abs.'] = df_explicit['debiasing_prompt_id'].map(abstraction_levels)\n",
    "\n",
    "        # Calculate means for each combination of prompt_id, conversation, and female_dominated\n",
    "        grouped_df_implicit = df_implicit.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()    \n",
    "        grouped_df_explicit = df_explicit.groupby(['Abs.', 'model', 'debiasing_prompt_id', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()    \n",
    "\n",
    "        # Drop the 'model' column\n",
    "        model_df_implicit = grouped_df_implicit.drop(columns=['model'])\n",
    "        model_df_explicit = grouped_df_explicit.drop(columns=['model'])\n",
    "        \n",
    "        # Sort by Abs. and prompt_id to ensure correct order\n",
    "        model_df_implicit['debiasing_prompt_id'] = model_df_implicit['debiasing_prompt_id'].astype(int)\n",
    "        model_df_implicit['Abs.'] = pd.Categorical(model_df_implicit['Abs.'], categories=abs_order, ordered=True)\n",
    "        model_df_implicit = model_df_implicit.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "        \n",
    "        model_df_explicit['debiasing_prompt_id'] = model_df_explicit['debiasing_prompt_id'].astype(int)\n",
    "        model_df_explicit['Abs.'] = pd.Categorical(model_df_explicit['Abs.'], categories=abs_order, ordered=True)\n",
    "        model_df_explicit = model_df_explicit.sort_values(by=['Abs.', 'debiasing_prompt_id'])\n",
    "        \n",
    "        model_df_implicit['explicit'] = False\n",
    "        model_df_explicit['explicit'] = True\n",
    "        \n",
    "        model_df = pd.concat([model_df_implicit, model_df_explicit])\n",
    "\n",
    "        latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "% Reduce text size and slightly the gap between columns\n",
    "% \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "\\caption{Results for ''' + model_str_map[model] + r''' on debiasing prompts.}\n",
    "  \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "\\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "\\toprule\n",
    "& & \\multicolumn{6}{c}{Explicit} & \\multicolumn{6}{c}{Implicit} \\\\\n",
    "\\cmidrule(lr){3-8} \\cmidrule(lr){9-14}\n",
    "& & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "\\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-11} \\cmidrule(lr){12-14}\n",
    "    Abs. & ID & M & F & D & M & F & D & M & F & D & M & F & D\\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "\n",
    "        previous_abs_level = None\n",
    "\n",
    "        for abs_level, abs_group in model_df.groupby('Abs.'):\n",
    "            if previous_abs_level is not None or abs_level != '':\n",
    "                latex_table += \"        \\\\midrule\\n\"\n",
    "            for prompt_id, prompt_group in abs_group.groupby('debiasing_prompt_id'):\n",
    "                id_label = 'None' if prompt_id == 0 else str(prompt_id)\n",
    "                row_prefix = f\"        {abs_level if prompt_id in [0,2,4,6] else ''} & {id_label} & \"\n",
    "\n",
    "                explicit_fd = prompt_group[(prompt_group['explicit'] == True) & (prompt_group['female_dominated'] == True)]\n",
    "                explicit_md = prompt_group[(prompt_group['explicit'] == True) & (prompt_group['female_dominated'] == False)]\n",
    "                implicit_fd = prompt_group[(prompt_group['explicit'] == False) & (prompt_group['female_dominated'] == True)]\n",
    "                implicit_md = prompt_group[(prompt_group['explicit'] == False) & (prompt_group['female_dominated'] == False)]\n",
    "\n",
    "                row = row_prefix\n",
    "\n",
    "                if not explicit_fd.empty:\n",
    "                    row += f\"{explicit_fd['male'].values[0]*100:.1f}\\\\% & {explicit_fd['female'].values[0]*100:.1f}\\\\% & {explicit_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                else:\n",
    "                    row += \" & & & \"\n",
    "\n",
    "                if not explicit_md.empty:\n",
    "                    row += f\"{explicit_md['male'].values[0]*100:.1f}\\\\% & {explicit_md['female'].values[0]*100:.1f}\\\\% & {explicit_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                else:\n",
    "                    row += \" & & & \"\n",
    "\n",
    "                if not implicit_fd.empty:\n",
    "                    row += f\"{implicit_fd['male'].values[0]*100:.1f}\\\\% & {implicit_fd['female'].values[0]*100:.1f}\\\\% & {implicit_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "                else:\n",
    "                    row += \" & & & \"\n",
    "\n",
    "                if not implicit_md.empty:\n",
    "                    row += f\"{implicit_md['male'].values[0]*100:.1f}\\\\% & {implicit_md['female'].values[0]*100:.1f}\\\\% & {implicit_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "                else:\n",
    "                    row += \" & & \"\n",
    "\n",
    "                row += r\"\\\\\"\n",
    "                latex_table += row + \"\\n\"\n",
    "\n",
    "            if abs_level != '':  # Add averages for all except \"None\"\n",
    "                avg_row_prefix = f\"         & \\\\textbf{{Avg}} & \"\n",
    "\n",
    "                avg_explicit_fd = abs_group[(abs_group['explicit'] == True) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                avg_explicit_md = abs_group[(abs_group['explicit'] == True) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                avg_implicit_fd = abs_group[(abs_group['explicit'] == False) & (abs_group['female_dominated'] == True)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "                avg_implicit_md = abs_group[(abs_group['explicit'] == False) & (abs_group['female_dominated'] == False)][['male', 'female', 'diverse']].mean(numeric_only=True)\n",
    "\n",
    "                avg_row = avg_row_prefix\n",
    "\n",
    "                if not avg_explicit_fd.empty:\n",
    "                    avg_row += f\"\\\\textbf{{{avg_explicit_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_explicit_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_explicit_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                else:\n",
    "                    avg_row += \" & & & \"\n",
    "\n",
    "                if not avg_explicit_md.empty:\n",
    "                    avg_row += f\"\\\\textbf{{{avg_explicit_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_explicit_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_explicit_md['diverse']*100:.1f}\\\\%}} & \"\n",
    "                else:\n",
    "                    avg_row += \" & & & \"\n",
    "\n",
    "                if not avg_implicit_fd.empty:\n",
    "                    avg_row += f\"\\\\textbf{{{avg_implicit_fd['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_implicit_fd['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_implicit_fd['diverse']*100:.1f}\\\\%}} & \"\n",
    "                else:\n",
    "                    avg_row += \" & & & \"\n",
    "\n",
    "                if not avg_implicit_md.empty:\n",
    "                    avg_row += f\"\\\\textbf{{{avg_implicit_md['male']*100:.1f}\\\\%}} & \\\\textbf{{{avg_implicit_md['female']*100:.1f}\\\\%}} & \\\\textbf{{{avg_implicit_md['diverse']*100:.1f}\\\\%}} \"\n",
    "                else:\n",
    "                    avg_row += \" & & \"\n",
    "\n",
    "                avg_row += r\"\\\\\"\n",
    "                latex_table += avg_row + \"\\n\"\n",
    "\n",
    "                previous_abs_level = abs_level\n",
    "\n",
    "        latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    " } % end \\resizebox\n",
    "\\label{tab:''' + model_name + r'''_debias}\n",
    "\\end{table*}\n",
    "\n",
    "'''\n",
    "\n",
    "        f_out.write(latex_table)\n",
    "        # f_out.write('\\\\clearpage\\n\\n')\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-05T20:47:39.372838Z",
     "start_time": "2024-10-05T20:47:39.295920Z"
    }
   },
   "id": "262f5966f8e50558",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  female_dominated  explicit  male_explicit0  \\\n",
      "0             llama2-7b             False     False             NaN   \n",
      "1             llama2-7b             False      True        0.524635   \n",
      "2             llama2-7b              True     False             NaN   \n",
      "3             llama2-7b              True      True        0.392790   \n",
      "4    llama2-7b-instruct             False     False             NaN   \n",
      "5    llama2-7b-instruct             False      True        0.810535   \n",
      "6    llama2-7b-instruct              True     False             NaN   \n",
      "7    llama2-7b-instruct              True      True        0.305010   \n",
      "8             llama3-8b             False     False             NaN   \n",
      "9             llama3-8b             False      True        0.852630   \n",
      "10            llama3-8b              True     False             NaN   \n",
      "11            llama3-8b              True      True        0.509195   \n",
      "12   llama3-8b-instruct             False     False             NaN   \n",
      "13   llama3-8b-instruct             False      True        0.990245   \n",
      "14   llama3-8b-instruct              True     False             NaN   \n",
      "15   llama3-8b-instruct              True      True        0.067220   \n",
      "16           mistral-7b             False     False             NaN   \n",
      "17           mistral-7b             False      True        0.940095   \n",
      "18           mistral-7b              True     False             NaN   \n",
      "19           mistral-7b              True      True        0.165255   \n",
      "20  mistral-7b-instruct             False     False             NaN   \n",
      "21  mistral-7b-instruct             False      True        0.573280   \n",
      "22  mistral-7b-instruct              True     False             NaN   \n",
      "23  mistral-7b-instruct              True      True        0.062685   \n",
      "\n",
      "    male_explicit1  male_explicit2  male_explicit3  male_explicit4  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1         0.715145        0.515840        0.707705        0.520500   \n",
      "2              NaN             NaN             NaN             NaN   \n",
      "3         0.546315        0.347315        0.472975        0.339865   \n",
      "4              NaN             NaN             NaN             NaN   \n",
      "5         0.798800        0.847745        0.930840        0.788345   \n",
      "6              NaN             NaN             NaN             NaN   \n",
      "7         0.298340        0.305605        0.308465        0.271400   \n",
      "8              NaN             NaN             NaN             NaN   \n",
      "9         0.771240        0.831540        0.907815        0.775275   \n",
      "10             NaN             NaN             NaN             NaN   \n",
      "11        0.465105        0.412700        0.434315        0.493520   \n",
      "12             NaN             NaN             NaN             NaN   \n",
      "13        0.995355        0.961025        0.999035        0.993070   \n",
      "14             NaN             NaN             NaN             NaN   \n",
      "15        0.077985        0.072265        0.100105        0.057600   \n",
      "16             NaN             NaN             NaN             NaN   \n",
      "17        0.973985        0.879980        0.976355        0.875175   \n",
      "18             NaN             NaN             NaN             NaN   \n",
      "19        0.190275        0.257940        0.126910        0.186375   \n",
      "20             NaN             NaN             NaN             NaN   \n",
      "21        0.981305        0.604580        0.996985        0.676330   \n",
      "22             NaN             NaN             NaN             NaN   \n",
      "23        0.040745        0.091200        0.058945        0.031560   \n",
      "\n",
      "    male_explicit5  male_explicit6  ...  diverse_implicit21_prob  \\\n",
      "0              NaN             NaN  ...                 0.000010   \n",
      "1         0.686680        0.770685  ...                      NaN   \n",
      "2              NaN             NaN  ...                 0.000010   \n",
      "3         0.515080        0.479820  ...                      NaN   \n",
      "4              NaN             NaN  ...                 0.000028   \n",
      "5         0.906295        0.990350  ...                      NaN   \n",
      "6              NaN             NaN  ...                 0.000028   \n",
      "7         0.266575        0.280260  ...                      NaN   \n",
      "8              NaN             NaN  ...                 0.000179   \n",
      "9         0.824865        0.920630  ...                      NaN   \n",
      "10             NaN             NaN  ...                 0.000160   \n",
      "11        0.475330        0.334950  ...                      NaN   \n",
      "12             NaN             NaN  ...                 0.000055   \n",
      "13        0.998650        0.999850  ...                      NaN   \n",
      "14             NaN             NaN  ...                 0.000100   \n",
      "15        0.100065        0.105710  ...                      NaN   \n",
      "16             NaN             NaN  ...                 0.000020   \n",
      "17        0.981105        0.979505  ...                      NaN   \n",
      "18             NaN             NaN  ...                 0.000017   \n",
      "19        0.142695        0.094220  ...                      NaN   \n",
      "20             NaN             NaN  ...                 0.000021   \n",
      "21        0.995140        0.999530  ...                      NaN   \n",
      "22             NaN             NaN  ...                 0.000036   \n",
      "23        0.052360        0.063070  ...                      NaN   \n",
      "\n",
      "    male_implicit22_prob  female_implicit22_prob  diverse_implicit22_prob  \\\n",
      "0               0.000056                0.000025                 0.000004   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000038                0.000090                 0.000006   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000124                0.000019                 0.000033   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000055                0.000075                 0.000032   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.001010                0.483366                 0.000214   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000592                0.647473                 0.000223   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000262                0.907915                 0.000004   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000087                0.984810                 0.000006   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000370                0.000039                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000142                0.000174                 0.000029   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000052                0.000002                 0.000021   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000016                0.000056                 0.000031   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit23_prob  female_implicit23_prob  diverse_implicit23_prob  \\\n",
      "0               0.000048                0.000023                 0.000011   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000045                0.000080                 0.000013   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000014                0.000008                 0.000021   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000013                0.000027                 0.000024   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.000654                0.431845                 0.000244   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000482                0.575052                 0.000205   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000324                0.956565                 0.000082   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000127                0.983303                 0.000085   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000283                0.000041                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000148                0.000117                 0.000026   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000076                0.000003                 0.000017   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000032                0.000040                 0.000053   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit24_prob  female_implicit24_prob  diverse_implicit24_prob  \n",
      "0               0.000099                0.000018                 0.000007  \n",
      "1                    NaN                     NaN                      NaN  \n",
      "2               0.000054                0.000122                 0.000006  \n",
      "3                    NaN                     NaN                      NaN  \n",
      "4               0.000032                0.000004                 0.000011  \n",
      "5                    NaN                     NaN                      NaN  \n",
      "6               0.000024                0.000023                 0.000010  \n",
      "7                    NaN                     NaN                      NaN  \n",
      "8               0.000223                0.331746                 0.000080  \n",
      "9                    NaN                     NaN                      NaN  \n",
      "10              0.000169                0.461245                 0.000078  \n",
      "11                   NaN                     NaN                      NaN  \n",
      "12              0.000344                0.734588                 0.000057  \n",
      "13                   NaN                     NaN                      NaN  \n",
      "14              0.000165                0.878671                 0.000046  \n",
      "15                   NaN                     NaN                      NaN  \n",
      "16              0.000081                0.000014                 0.000033  \n",
      "17                   NaN                     NaN                      NaN  \n",
      "18              0.000048                0.000060                 0.000028  \n",
      "19                   NaN                     NaN                      NaN  \n",
      "20              0.000026                0.000001                 0.000031  \n",
      "21                   NaN                     NaN                      NaN  \n",
      "22              0.000004                0.000032                 0.000037  \n",
      "23                   NaN                     NaN                      NaN  \n",
      "\n",
      "[24 rows x 304 columns]\n",
      "                  model  female_dominated  explicit  male_explicit0  \\\n",
      "0             llama2-7b             False     False             NaN   \n",
      "1             llama2-7b             False      True        0.524635   \n",
      "2             llama2-7b              True     False             NaN   \n",
      "3             llama2-7b              True      True        0.392790   \n",
      "4    llama2-7b-instruct             False     False             NaN   \n",
      "5    llama2-7b-instruct             False      True        0.810535   \n",
      "6    llama2-7b-instruct              True     False             NaN   \n",
      "7    llama2-7b-instruct              True      True        0.305010   \n",
      "8             llama3-8b             False     False             NaN   \n",
      "9             llama3-8b             False      True        0.852630   \n",
      "10            llama3-8b              True     False             NaN   \n",
      "11            llama3-8b              True      True        0.509195   \n",
      "12   llama3-8b-instruct             False     False             NaN   \n",
      "13   llama3-8b-instruct             False      True        0.990245   \n",
      "14   llama3-8b-instruct              True     False             NaN   \n",
      "15   llama3-8b-instruct              True      True        0.067220   \n",
      "16           mistral-7b             False     False             NaN   \n",
      "17           mistral-7b             False      True        0.940095   \n",
      "18           mistral-7b              True     False             NaN   \n",
      "19           mistral-7b              True      True        0.165255   \n",
      "20  mistral-7b-instruct             False     False             NaN   \n",
      "21  mistral-7b-instruct             False      True        0.573280   \n",
      "22  mistral-7b-instruct              True     False             NaN   \n",
      "23  mistral-7b-instruct              True      True        0.062685   \n",
      "\n",
      "    male_explicit1  male_explicit2  male_explicit3  male_explicit4  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1         0.715145        0.515840        0.707705        0.520500   \n",
      "2              NaN             NaN             NaN             NaN   \n",
      "3         0.546315        0.347315        0.472975        0.339865   \n",
      "4              NaN             NaN             NaN             NaN   \n",
      "5         0.798800        0.847745        0.930840        0.788345   \n",
      "6              NaN             NaN             NaN             NaN   \n",
      "7         0.298340        0.305605        0.308465        0.271400   \n",
      "8              NaN             NaN             NaN             NaN   \n",
      "9         0.771240        0.831540        0.907815        0.775275   \n",
      "10             NaN             NaN             NaN             NaN   \n",
      "11        0.465105        0.412700        0.434315        0.493520   \n",
      "12             NaN             NaN             NaN             NaN   \n",
      "13        0.995355        0.961025        0.999035        0.993070   \n",
      "14             NaN             NaN             NaN             NaN   \n",
      "15        0.077985        0.072265        0.100105        0.057600   \n",
      "16             NaN             NaN             NaN             NaN   \n",
      "17        0.973985        0.879980        0.976355        0.875175   \n",
      "18             NaN             NaN             NaN             NaN   \n",
      "19        0.190275        0.257940        0.126910        0.186375   \n",
      "20             NaN             NaN             NaN             NaN   \n",
      "21        0.981305        0.604580        0.996985        0.676330   \n",
      "22             NaN             NaN             NaN             NaN   \n",
      "23        0.040745        0.091200        0.058945        0.031560   \n",
      "\n",
      "    male_explicit5  male_explicit6  ...  diverse_implicit21_prob  \\\n",
      "0              NaN             NaN  ...                 0.000010   \n",
      "1         0.686680        0.770685  ...                      NaN   \n",
      "2              NaN             NaN  ...                 0.000010   \n",
      "3         0.515080        0.479820  ...                      NaN   \n",
      "4              NaN             NaN  ...                 0.000028   \n",
      "5         0.906295        0.990350  ...                      NaN   \n",
      "6              NaN             NaN  ...                 0.000028   \n",
      "7         0.266575        0.280260  ...                      NaN   \n",
      "8              NaN             NaN  ...                 0.000179   \n",
      "9         0.824865        0.920630  ...                      NaN   \n",
      "10             NaN             NaN  ...                 0.000160   \n",
      "11        0.475330        0.334950  ...                      NaN   \n",
      "12             NaN             NaN  ...                 0.000055   \n",
      "13        0.998650        0.999850  ...                      NaN   \n",
      "14             NaN             NaN  ...                 0.000100   \n",
      "15        0.100065        0.105710  ...                      NaN   \n",
      "16             NaN             NaN  ...                 0.000020   \n",
      "17        0.981105        0.979505  ...                      NaN   \n",
      "18             NaN             NaN  ...                 0.000017   \n",
      "19        0.142695        0.094220  ...                      NaN   \n",
      "20             NaN             NaN  ...                 0.000021   \n",
      "21        0.995140        0.999530  ...                      NaN   \n",
      "22             NaN             NaN  ...                 0.000036   \n",
      "23        0.052360        0.063070  ...                      NaN   \n",
      "\n",
      "    male_implicit22_prob  female_implicit22_prob  diverse_implicit22_prob  \\\n",
      "0               0.000056                0.000025                 0.000004   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000038                0.000090                 0.000006   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000124                0.000019                 0.000033   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000055                0.000075                 0.000032   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.001010                0.483366                 0.000214   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000592                0.647473                 0.000223   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000262                0.907915                 0.000004   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000087                0.984810                 0.000006   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000370                0.000039                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000142                0.000174                 0.000029   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000052                0.000002                 0.000021   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000016                0.000056                 0.000031   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit23_prob  female_implicit23_prob  diverse_implicit23_prob  \\\n",
      "0               0.000048                0.000023                 0.000011   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000045                0.000080                 0.000013   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000014                0.000008                 0.000021   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000013                0.000027                 0.000024   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.000654                0.431845                 0.000244   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000482                0.575052                 0.000205   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000324                0.956565                 0.000082   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000127                0.983303                 0.000085   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000283                0.000041                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000148                0.000117                 0.000026   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000076                0.000003                 0.000017   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000032                0.000040                 0.000053   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit24_prob  female_implicit24_prob  diverse_implicit24_prob  \n",
      "0               0.000099                0.000018                 0.000007  \n",
      "1                    NaN                     NaN                      NaN  \n",
      "2               0.000054                0.000122                 0.000006  \n",
      "3                    NaN                     NaN                      NaN  \n",
      "4               0.000032                0.000004                 0.000011  \n",
      "5                    NaN                     NaN                      NaN  \n",
      "6               0.000024                0.000023                 0.000010  \n",
      "7                    NaN                     NaN                      NaN  \n",
      "8               0.000223                0.331746                 0.000080  \n",
      "9                    NaN                     NaN                      NaN  \n",
      "10              0.000169                0.461245                 0.000078  \n",
      "11                   NaN                     NaN                      NaN  \n",
      "12              0.000344                0.734588                 0.000057  \n",
      "13                   NaN                     NaN                      NaN  \n",
      "14              0.000165                0.878671                 0.000046  \n",
      "15                   NaN                     NaN                      NaN  \n",
      "16              0.000081                0.000014                 0.000033  \n",
      "17                   NaN                     NaN                      NaN  \n",
      "18              0.000048                0.000060                 0.000028  \n",
      "19                   NaN                     NaN                      NaN  \n",
      "20              0.000026                0.000001                 0.000031  \n",
      "21                   NaN                     NaN                      NaN  \n",
      "22              0.000004                0.000032                 0.000037  \n",
      "23                   NaN                     NaN                      NaN  \n",
      "\n",
      "[24 rows x 304 columns]\n",
      "                  model  female_dominated  explicit  male_explicit0  \\\n",
      "0             llama2-7b             False     False             NaN   \n",
      "1             llama2-7b             False      True        0.524635   \n",
      "2             llama2-7b              True     False             NaN   \n",
      "3             llama2-7b              True      True        0.392790   \n",
      "4    llama2-7b-instruct             False     False             NaN   \n",
      "5    llama2-7b-instruct             False      True        0.810535   \n",
      "6    llama2-7b-instruct              True     False             NaN   \n",
      "7    llama2-7b-instruct              True      True        0.305010   \n",
      "8             llama3-8b             False     False             NaN   \n",
      "9             llama3-8b             False      True        0.852630   \n",
      "10            llama3-8b              True     False             NaN   \n",
      "11            llama3-8b              True      True        0.509195   \n",
      "12   llama3-8b-instruct             False     False             NaN   \n",
      "13   llama3-8b-instruct             False      True        0.990245   \n",
      "14   llama3-8b-instruct              True     False             NaN   \n",
      "15   llama3-8b-instruct              True      True        0.067220   \n",
      "16           mistral-7b             False     False             NaN   \n",
      "17           mistral-7b             False      True        0.940095   \n",
      "18           mistral-7b              True     False             NaN   \n",
      "19           mistral-7b              True      True        0.165255   \n",
      "20  mistral-7b-instruct             False     False             NaN   \n",
      "21  mistral-7b-instruct             False      True        0.573280   \n",
      "22  mistral-7b-instruct              True     False             NaN   \n",
      "23  mistral-7b-instruct              True      True        0.062685   \n",
      "\n",
      "    male_explicit1  male_explicit2  male_explicit3  male_explicit4  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1         0.715145        0.515840        0.707705        0.520500   \n",
      "2              NaN             NaN             NaN             NaN   \n",
      "3         0.546315        0.347315        0.472975        0.339865   \n",
      "4              NaN             NaN             NaN             NaN   \n",
      "5         0.798800        0.847745        0.930840        0.788345   \n",
      "6              NaN             NaN             NaN             NaN   \n",
      "7         0.298340        0.305605        0.308465        0.271400   \n",
      "8              NaN             NaN             NaN             NaN   \n",
      "9         0.771240        0.831540        0.907815        0.775275   \n",
      "10             NaN             NaN             NaN             NaN   \n",
      "11        0.465105        0.412700        0.434315        0.493520   \n",
      "12             NaN             NaN             NaN             NaN   \n",
      "13        0.995355        0.961025        0.999035        0.993070   \n",
      "14             NaN             NaN             NaN             NaN   \n",
      "15        0.077985        0.072265        0.100105        0.057600   \n",
      "16             NaN             NaN             NaN             NaN   \n",
      "17        0.973985        0.879980        0.976355        0.875175   \n",
      "18             NaN             NaN             NaN             NaN   \n",
      "19        0.190275        0.257940        0.126910        0.186375   \n",
      "20             NaN             NaN             NaN             NaN   \n",
      "21        0.981305        0.604580        0.996985        0.676330   \n",
      "22             NaN             NaN             NaN             NaN   \n",
      "23        0.040745        0.091200        0.058945        0.031560   \n",
      "\n",
      "    male_explicit5  male_explicit6  ...  diverse_implicit21_prob  \\\n",
      "0              NaN             NaN  ...                 0.000010   \n",
      "1         0.686680        0.770685  ...                      NaN   \n",
      "2              NaN             NaN  ...                 0.000010   \n",
      "3         0.515080        0.479820  ...                      NaN   \n",
      "4              NaN             NaN  ...                 0.000028   \n",
      "5         0.906295        0.990350  ...                      NaN   \n",
      "6              NaN             NaN  ...                 0.000028   \n",
      "7         0.266575        0.280260  ...                      NaN   \n",
      "8              NaN             NaN  ...                 0.000179   \n",
      "9         0.824865        0.920630  ...                      NaN   \n",
      "10             NaN             NaN  ...                 0.000160   \n",
      "11        0.475330        0.334950  ...                      NaN   \n",
      "12             NaN             NaN  ...                 0.000055   \n",
      "13        0.998650        0.999850  ...                      NaN   \n",
      "14             NaN             NaN  ...                 0.000100   \n",
      "15        0.100065        0.105710  ...                      NaN   \n",
      "16             NaN             NaN  ...                 0.000020   \n",
      "17        0.981105        0.979505  ...                      NaN   \n",
      "18             NaN             NaN  ...                 0.000017   \n",
      "19        0.142695        0.094220  ...                      NaN   \n",
      "20             NaN             NaN  ...                 0.000021   \n",
      "21        0.995140        0.999530  ...                      NaN   \n",
      "22             NaN             NaN  ...                 0.000036   \n",
      "23        0.052360        0.063070  ...                      NaN   \n",
      "\n",
      "    male_implicit22_prob  female_implicit22_prob  diverse_implicit22_prob  \\\n",
      "0               0.000056                0.000025                 0.000004   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000038                0.000090                 0.000006   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000124                0.000019                 0.000033   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000055                0.000075                 0.000032   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.001010                0.483366                 0.000214   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000592                0.647473                 0.000223   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000262                0.907915                 0.000004   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000087                0.984810                 0.000006   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000370                0.000039                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000142                0.000174                 0.000029   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000052                0.000002                 0.000021   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000016                0.000056                 0.000031   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit23_prob  female_implicit23_prob  diverse_implicit23_prob  \\\n",
      "0               0.000048                0.000023                 0.000011   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000045                0.000080                 0.000013   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000014                0.000008                 0.000021   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000013                0.000027                 0.000024   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.000654                0.431845                 0.000244   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000482                0.575052                 0.000205   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000324                0.956565                 0.000082   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000127                0.983303                 0.000085   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000283                0.000041                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000148                0.000117                 0.000026   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000076                0.000003                 0.000017   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000032                0.000040                 0.000053   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit24_prob  female_implicit24_prob  diverse_implicit24_prob  \n",
      "0               0.000099                0.000018                 0.000007  \n",
      "1                    NaN                     NaN                      NaN  \n",
      "2               0.000054                0.000122                 0.000006  \n",
      "3                    NaN                     NaN                      NaN  \n",
      "4               0.000032                0.000004                 0.000011  \n",
      "5                    NaN                     NaN                      NaN  \n",
      "6               0.000024                0.000023                 0.000010  \n",
      "7                    NaN                     NaN                      NaN  \n",
      "8               0.000223                0.331746                 0.000080  \n",
      "9                    NaN                     NaN                      NaN  \n",
      "10              0.000169                0.461245                 0.000078  \n",
      "11                   NaN                     NaN                      NaN  \n",
      "12              0.000344                0.734588                 0.000057  \n",
      "13                   NaN                     NaN                      NaN  \n",
      "14              0.000165                0.878671                 0.000046  \n",
      "15                   NaN                     NaN                      NaN  \n",
      "16              0.000081                0.000014                 0.000033  \n",
      "17                   NaN                     NaN                      NaN  \n",
      "18              0.000048                0.000060                 0.000028  \n",
      "19                   NaN                     NaN                      NaN  \n",
      "20              0.000026                0.000001                 0.000031  \n",
      "21                   NaN                     NaN                      NaN  \n",
      "22              0.000004                0.000032                 0.000037  \n",
      "23                   NaN                     NaN                      NaN  \n",
      "\n",
      "[24 rows x 304 columns]\n",
      "                  model  female_dominated  explicit  male_explicit0  \\\n",
      "0             llama2-7b             False     False             NaN   \n",
      "1             llama2-7b             False      True        0.524635   \n",
      "2             llama2-7b              True     False             NaN   \n",
      "3             llama2-7b              True      True        0.392790   \n",
      "4    llama2-7b-instruct             False     False             NaN   \n",
      "5    llama2-7b-instruct             False      True        0.810535   \n",
      "6    llama2-7b-instruct              True     False             NaN   \n",
      "7    llama2-7b-instruct              True      True        0.305010   \n",
      "8             llama3-8b             False     False             NaN   \n",
      "9             llama3-8b             False      True        0.852630   \n",
      "10            llama3-8b              True     False             NaN   \n",
      "11            llama3-8b              True      True        0.509195   \n",
      "12   llama3-8b-instruct             False     False             NaN   \n",
      "13   llama3-8b-instruct             False      True        0.990245   \n",
      "14   llama3-8b-instruct              True     False             NaN   \n",
      "15   llama3-8b-instruct              True      True        0.067220   \n",
      "16           mistral-7b             False     False             NaN   \n",
      "17           mistral-7b             False      True        0.940095   \n",
      "18           mistral-7b              True     False             NaN   \n",
      "19           mistral-7b              True      True        0.165255   \n",
      "20  mistral-7b-instruct             False     False             NaN   \n",
      "21  mistral-7b-instruct             False      True        0.573280   \n",
      "22  mistral-7b-instruct              True     False             NaN   \n",
      "23  mistral-7b-instruct              True      True        0.062685   \n",
      "\n",
      "    male_explicit1  male_explicit2  male_explicit3  male_explicit4  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1         0.715145        0.515840        0.707705        0.520500   \n",
      "2              NaN             NaN             NaN             NaN   \n",
      "3         0.546315        0.347315        0.472975        0.339865   \n",
      "4              NaN             NaN             NaN             NaN   \n",
      "5         0.798800        0.847745        0.930840        0.788345   \n",
      "6              NaN             NaN             NaN             NaN   \n",
      "7         0.298340        0.305605        0.308465        0.271400   \n",
      "8              NaN             NaN             NaN             NaN   \n",
      "9         0.771240        0.831540        0.907815        0.775275   \n",
      "10             NaN             NaN             NaN             NaN   \n",
      "11        0.465105        0.412700        0.434315        0.493520   \n",
      "12             NaN             NaN             NaN             NaN   \n",
      "13        0.995355        0.961025        0.999035        0.993070   \n",
      "14             NaN             NaN             NaN             NaN   \n",
      "15        0.077985        0.072265        0.100105        0.057600   \n",
      "16             NaN             NaN             NaN             NaN   \n",
      "17        0.973985        0.879980        0.976355        0.875175   \n",
      "18             NaN             NaN             NaN             NaN   \n",
      "19        0.190275        0.257940        0.126910        0.186375   \n",
      "20             NaN             NaN             NaN             NaN   \n",
      "21        0.981305        0.604580        0.996985        0.676330   \n",
      "22             NaN             NaN             NaN             NaN   \n",
      "23        0.040745        0.091200        0.058945        0.031560   \n",
      "\n",
      "    male_explicit5  male_explicit6  ...  diverse_implicit21_prob  \\\n",
      "0              NaN             NaN  ...                 0.000010   \n",
      "1         0.686680        0.770685  ...                      NaN   \n",
      "2              NaN             NaN  ...                 0.000010   \n",
      "3         0.515080        0.479820  ...                      NaN   \n",
      "4              NaN             NaN  ...                 0.000028   \n",
      "5         0.906295        0.990350  ...                      NaN   \n",
      "6              NaN             NaN  ...                 0.000028   \n",
      "7         0.266575        0.280260  ...                      NaN   \n",
      "8              NaN             NaN  ...                 0.000179   \n",
      "9         0.824865        0.920630  ...                      NaN   \n",
      "10             NaN             NaN  ...                 0.000160   \n",
      "11        0.475330        0.334950  ...                      NaN   \n",
      "12             NaN             NaN  ...                 0.000055   \n",
      "13        0.998650        0.999850  ...                      NaN   \n",
      "14             NaN             NaN  ...                 0.000100   \n",
      "15        0.100065        0.105710  ...                      NaN   \n",
      "16             NaN             NaN  ...                 0.000020   \n",
      "17        0.981105        0.979505  ...                      NaN   \n",
      "18             NaN             NaN  ...                 0.000017   \n",
      "19        0.142695        0.094220  ...                      NaN   \n",
      "20             NaN             NaN  ...                 0.000021   \n",
      "21        0.995140        0.999530  ...                      NaN   \n",
      "22             NaN             NaN  ...                 0.000036   \n",
      "23        0.052360        0.063070  ...                      NaN   \n",
      "\n",
      "    male_implicit22_prob  female_implicit22_prob  diverse_implicit22_prob  \\\n",
      "0               0.000056                0.000025                 0.000004   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000038                0.000090                 0.000006   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000124                0.000019                 0.000033   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000055                0.000075                 0.000032   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.001010                0.483366                 0.000214   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000592                0.647473                 0.000223   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000262                0.907915                 0.000004   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000087                0.984810                 0.000006   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000370                0.000039                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000142                0.000174                 0.000029   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000052                0.000002                 0.000021   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000016                0.000056                 0.000031   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit23_prob  female_implicit23_prob  diverse_implicit23_prob  \\\n",
      "0               0.000048                0.000023                 0.000011   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000045                0.000080                 0.000013   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000014                0.000008                 0.000021   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000013                0.000027                 0.000024   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.000654                0.431845                 0.000244   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000482                0.575052                 0.000205   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000324                0.956565                 0.000082   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000127                0.983303                 0.000085   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000283                0.000041                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000148                0.000117                 0.000026   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000076                0.000003                 0.000017   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000032                0.000040                 0.000053   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit24_prob  female_implicit24_prob  diverse_implicit24_prob  \n",
      "0               0.000099                0.000018                 0.000007  \n",
      "1                    NaN                     NaN                      NaN  \n",
      "2               0.000054                0.000122                 0.000006  \n",
      "3                    NaN                     NaN                      NaN  \n",
      "4               0.000032                0.000004                 0.000011  \n",
      "5                    NaN                     NaN                      NaN  \n",
      "6               0.000024                0.000023                 0.000010  \n",
      "7                    NaN                     NaN                      NaN  \n",
      "8               0.000223                0.331746                 0.000080  \n",
      "9                    NaN                     NaN                      NaN  \n",
      "10              0.000169                0.461245                 0.000078  \n",
      "11                   NaN                     NaN                      NaN  \n",
      "12              0.000344                0.734588                 0.000057  \n",
      "13                   NaN                     NaN                      NaN  \n",
      "14              0.000165                0.878671                 0.000046  \n",
      "15                   NaN                     NaN                      NaN  \n",
      "16              0.000081                0.000014                 0.000033  \n",
      "17                   NaN                     NaN                      NaN  \n",
      "18              0.000048                0.000060                 0.000028  \n",
      "19                   NaN                     NaN                      NaN  \n",
      "20              0.000026                0.000001                 0.000031  \n",
      "21                   NaN                     NaN                      NaN  \n",
      "22              0.000004                0.000032                 0.000037  \n",
      "23                   NaN                     NaN                      NaN  \n",
      "\n",
      "[24 rows x 304 columns]\n",
      "                  model  female_dominated  explicit  male_explicit0  \\\n",
      "0             llama2-7b             False     False             NaN   \n",
      "1             llama2-7b             False      True        0.524635   \n",
      "2             llama2-7b              True     False             NaN   \n",
      "3             llama2-7b              True      True        0.392790   \n",
      "4    llama2-7b-instruct             False     False             NaN   \n",
      "5    llama2-7b-instruct             False      True        0.810535   \n",
      "6    llama2-7b-instruct              True     False             NaN   \n",
      "7    llama2-7b-instruct              True      True        0.305010   \n",
      "8             llama3-8b             False     False             NaN   \n",
      "9             llama3-8b             False      True        0.852630   \n",
      "10            llama3-8b              True     False             NaN   \n",
      "11            llama3-8b              True      True        0.509195   \n",
      "12   llama3-8b-instruct             False     False             NaN   \n",
      "13   llama3-8b-instruct             False      True        0.990245   \n",
      "14   llama3-8b-instruct              True     False             NaN   \n",
      "15   llama3-8b-instruct              True      True        0.067220   \n",
      "16           mistral-7b             False     False             NaN   \n",
      "17           mistral-7b             False      True        0.940095   \n",
      "18           mistral-7b              True     False             NaN   \n",
      "19           mistral-7b              True      True        0.165255   \n",
      "20  mistral-7b-instruct             False     False             NaN   \n",
      "21  mistral-7b-instruct             False      True        0.573280   \n",
      "22  mistral-7b-instruct              True     False             NaN   \n",
      "23  mistral-7b-instruct              True      True        0.062685   \n",
      "\n",
      "    male_explicit1  male_explicit2  male_explicit3  male_explicit4  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1         0.715145        0.515840        0.707705        0.520500   \n",
      "2              NaN             NaN             NaN             NaN   \n",
      "3         0.546315        0.347315        0.472975        0.339865   \n",
      "4              NaN             NaN             NaN             NaN   \n",
      "5         0.798800        0.847745        0.930840        0.788345   \n",
      "6              NaN             NaN             NaN             NaN   \n",
      "7         0.298340        0.305605        0.308465        0.271400   \n",
      "8              NaN             NaN             NaN             NaN   \n",
      "9         0.771240        0.831540        0.907815        0.775275   \n",
      "10             NaN             NaN             NaN             NaN   \n",
      "11        0.465105        0.412700        0.434315        0.493520   \n",
      "12             NaN             NaN             NaN             NaN   \n",
      "13        0.995355        0.961025        0.999035        0.993070   \n",
      "14             NaN             NaN             NaN             NaN   \n",
      "15        0.077985        0.072265        0.100105        0.057600   \n",
      "16             NaN             NaN             NaN             NaN   \n",
      "17        0.973985        0.879980        0.976355        0.875175   \n",
      "18             NaN             NaN             NaN             NaN   \n",
      "19        0.190275        0.257940        0.126910        0.186375   \n",
      "20             NaN             NaN             NaN             NaN   \n",
      "21        0.981305        0.604580        0.996985        0.676330   \n",
      "22             NaN             NaN             NaN             NaN   \n",
      "23        0.040745        0.091200        0.058945        0.031560   \n",
      "\n",
      "    male_explicit5  male_explicit6  ...  diverse_implicit21_prob  \\\n",
      "0              NaN             NaN  ...                 0.000010   \n",
      "1         0.686680        0.770685  ...                      NaN   \n",
      "2              NaN             NaN  ...                 0.000010   \n",
      "3         0.515080        0.479820  ...                      NaN   \n",
      "4              NaN             NaN  ...                 0.000028   \n",
      "5         0.906295        0.990350  ...                      NaN   \n",
      "6              NaN             NaN  ...                 0.000028   \n",
      "7         0.266575        0.280260  ...                      NaN   \n",
      "8              NaN             NaN  ...                 0.000179   \n",
      "9         0.824865        0.920630  ...                      NaN   \n",
      "10             NaN             NaN  ...                 0.000160   \n",
      "11        0.475330        0.334950  ...                      NaN   \n",
      "12             NaN             NaN  ...                 0.000055   \n",
      "13        0.998650        0.999850  ...                      NaN   \n",
      "14             NaN             NaN  ...                 0.000100   \n",
      "15        0.100065        0.105710  ...                      NaN   \n",
      "16             NaN             NaN  ...                 0.000020   \n",
      "17        0.981105        0.979505  ...                      NaN   \n",
      "18             NaN             NaN  ...                 0.000017   \n",
      "19        0.142695        0.094220  ...                      NaN   \n",
      "20             NaN             NaN  ...                 0.000021   \n",
      "21        0.995140        0.999530  ...                      NaN   \n",
      "22             NaN             NaN  ...                 0.000036   \n",
      "23        0.052360        0.063070  ...                      NaN   \n",
      "\n",
      "    male_implicit22_prob  female_implicit22_prob  diverse_implicit22_prob  \\\n",
      "0               0.000056                0.000025                 0.000004   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000038                0.000090                 0.000006   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000124                0.000019                 0.000033   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000055                0.000075                 0.000032   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.001010                0.483366                 0.000214   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000592                0.647473                 0.000223   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000262                0.907915                 0.000004   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000087                0.984810                 0.000006   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000370                0.000039                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000142                0.000174                 0.000029   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000052                0.000002                 0.000021   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000016                0.000056                 0.000031   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit23_prob  female_implicit23_prob  diverse_implicit23_prob  \\\n",
      "0               0.000048                0.000023                 0.000011   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000045                0.000080                 0.000013   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000014                0.000008                 0.000021   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000013                0.000027                 0.000024   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.000654                0.431845                 0.000244   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000482                0.575052                 0.000205   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000324                0.956565                 0.000082   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000127                0.983303                 0.000085   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000283                0.000041                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000148                0.000117                 0.000026   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000076                0.000003                 0.000017   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000032                0.000040                 0.000053   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit24_prob  female_implicit24_prob  diverse_implicit24_prob  \n",
      "0               0.000099                0.000018                 0.000007  \n",
      "1                    NaN                     NaN                      NaN  \n",
      "2               0.000054                0.000122                 0.000006  \n",
      "3                    NaN                     NaN                      NaN  \n",
      "4               0.000032                0.000004                 0.000011  \n",
      "5                    NaN                     NaN                      NaN  \n",
      "6               0.000024                0.000023                 0.000010  \n",
      "7                    NaN                     NaN                      NaN  \n",
      "8               0.000223                0.331746                 0.000080  \n",
      "9                    NaN                     NaN                      NaN  \n",
      "10              0.000169                0.461245                 0.000078  \n",
      "11                   NaN                     NaN                      NaN  \n",
      "12              0.000344                0.734588                 0.000057  \n",
      "13                   NaN                     NaN                      NaN  \n",
      "14              0.000165                0.878671                 0.000046  \n",
      "15                   NaN                     NaN                      NaN  \n",
      "16              0.000081                0.000014                 0.000033  \n",
      "17                   NaN                     NaN                      NaN  \n",
      "18              0.000048                0.000060                 0.000028  \n",
      "19                   NaN                     NaN                      NaN  \n",
      "20              0.000026                0.000001                 0.000031  \n",
      "21                   NaN                     NaN                      NaN  \n",
      "22              0.000004                0.000032                 0.000037  \n",
      "23                   NaN                     NaN                      NaN  \n",
      "\n",
      "[24 rows x 304 columns]\n",
      "                  model  female_dominated  explicit  male_explicit0  \\\n",
      "0             llama2-7b             False     False             NaN   \n",
      "1             llama2-7b             False      True        0.524635   \n",
      "2             llama2-7b              True     False             NaN   \n",
      "3             llama2-7b              True      True        0.392790   \n",
      "4    llama2-7b-instruct             False     False             NaN   \n",
      "5    llama2-7b-instruct             False      True        0.810535   \n",
      "6    llama2-7b-instruct              True     False             NaN   \n",
      "7    llama2-7b-instruct              True      True        0.305010   \n",
      "8             llama3-8b             False     False             NaN   \n",
      "9             llama3-8b             False      True        0.852630   \n",
      "10            llama3-8b              True     False             NaN   \n",
      "11            llama3-8b              True      True        0.509195   \n",
      "12   llama3-8b-instruct             False     False             NaN   \n",
      "13   llama3-8b-instruct             False      True        0.990245   \n",
      "14   llama3-8b-instruct              True     False             NaN   \n",
      "15   llama3-8b-instruct              True      True        0.067220   \n",
      "16           mistral-7b             False     False             NaN   \n",
      "17           mistral-7b             False      True        0.940095   \n",
      "18           mistral-7b              True     False             NaN   \n",
      "19           mistral-7b              True      True        0.165255   \n",
      "20  mistral-7b-instruct             False     False             NaN   \n",
      "21  mistral-7b-instruct             False      True        0.573280   \n",
      "22  mistral-7b-instruct              True     False             NaN   \n",
      "23  mistral-7b-instruct              True      True        0.062685   \n",
      "\n",
      "    male_explicit1  male_explicit2  male_explicit3  male_explicit4  \\\n",
      "0              NaN             NaN             NaN             NaN   \n",
      "1         0.715145        0.515840        0.707705        0.520500   \n",
      "2              NaN             NaN             NaN             NaN   \n",
      "3         0.546315        0.347315        0.472975        0.339865   \n",
      "4              NaN             NaN             NaN             NaN   \n",
      "5         0.798800        0.847745        0.930840        0.788345   \n",
      "6              NaN             NaN             NaN             NaN   \n",
      "7         0.298340        0.305605        0.308465        0.271400   \n",
      "8              NaN             NaN             NaN             NaN   \n",
      "9         0.771240        0.831540        0.907815        0.775275   \n",
      "10             NaN             NaN             NaN             NaN   \n",
      "11        0.465105        0.412700        0.434315        0.493520   \n",
      "12             NaN             NaN             NaN             NaN   \n",
      "13        0.995355        0.961025        0.999035        0.993070   \n",
      "14             NaN             NaN             NaN             NaN   \n",
      "15        0.077985        0.072265        0.100105        0.057600   \n",
      "16             NaN             NaN             NaN             NaN   \n",
      "17        0.973985        0.879980        0.976355        0.875175   \n",
      "18             NaN             NaN             NaN             NaN   \n",
      "19        0.190275        0.257940        0.126910        0.186375   \n",
      "20             NaN             NaN             NaN             NaN   \n",
      "21        0.981305        0.604580        0.996985        0.676330   \n",
      "22             NaN             NaN             NaN             NaN   \n",
      "23        0.040745        0.091200        0.058945        0.031560   \n",
      "\n",
      "    male_explicit5  male_explicit6  ...  diverse_implicit21_prob  \\\n",
      "0              NaN             NaN  ...                 0.000010   \n",
      "1         0.686680        0.770685  ...                      NaN   \n",
      "2              NaN             NaN  ...                 0.000010   \n",
      "3         0.515080        0.479820  ...                      NaN   \n",
      "4              NaN             NaN  ...                 0.000028   \n",
      "5         0.906295        0.990350  ...                      NaN   \n",
      "6              NaN             NaN  ...                 0.000028   \n",
      "7         0.266575        0.280260  ...                      NaN   \n",
      "8              NaN             NaN  ...                 0.000179   \n",
      "9         0.824865        0.920630  ...                      NaN   \n",
      "10             NaN             NaN  ...                 0.000160   \n",
      "11        0.475330        0.334950  ...                      NaN   \n",
      "12             NaN             NaN  ...                 0.000055   \n",
      "13        0.998650        0.999850  ...                      NaN   \n",
      "14             NaN             NaN  ...                 0.000100   \n",
      "15        0.100065        0.105710  ...                      NaN   \n",
      "16             NaN             NaN  ...                 0.000020   \n",
      "17        0.981105        0.979505  ...                      NaN   \n",
      "18             NaN             NaN  ...                 0.000017   \n",
      "19        0.142695        0.094220  ...                      NaN   \n",
      "20             NaN             NaN  ...                 0.000021   \n",
      "21        0.995140        0.999530  ...                      NaN   \n",
      "22             NaN             NaN  ...                 0.000036   \n",
      "23        0.052360        0.063070  ...                      NaN   \n",
      "\n",
      "    male_implicit22_prob  female_implicit22_prob  diverse_implicit22_prob  \\\n",
      "0               0.000056                0.000025                 0.000004   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000038                0.000090                 0.000006   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000124                0.000019                 0.000033   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000055                0.000075                 0.000032   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.001010                0.483366                 0.000214   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000592                0.647473                 0.000223   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000262                0.907915                 0.000004   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000087                0.984810                 0.000006   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000370                0.000039                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000142                0.000174                 0.000029   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000052                0.000002                 0.000021   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000016                0.000056                 0.000031   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit23_prob  female_implicit23_prob  diverse_implicit23_prob  \\\n",
      "0               0.000048                0.000023                 0.000011   \n",
      "1                    NaN                     NaN                      NaN   \n",
      "2               0.000045                0.000080                 0.000013   \n",
      "3                    NaN                     NaN                      NaN   \n",
      "4               0.000014                0.000008                 0.000021   \n",
      "5                    NaN                     NaN                      NaN   \n",
      "6               0.000013                0.000027                 0.000024   \n",
      "7                    NaN                     NaN                      NaN   \n",
      "8               0.000654                0.431845                 0.000244   \n",
      "9                    NaN                     NaN                      NaN   \n",
      "10              0.000482                0.575052                 0.000205   \n",
      "11                   NaN                     NaN                      NaN   \n",
      "12              0.000324                0.956565                 0.000082   \n",
      "13                   NaN                     NaN                      NaN   \n",
      "14              0.000127                0.983303                 0.000085   \n",
      "15                   NaN                     NaN                      NaN   \n",
      "16              0.000283                0.000041                 0.000029   \n",
      "17                   NaN                     NaN                      NaN   \n",
      "18              0.000148                0.000117                 0.000026   \n",
      "19                   NaN                     NaN                      NaN   \n",
      "20              0.000076                0.000003                 0.000017   \n",
      "21                   NaN                     NaN                      NaN   \n",
      "22              0.000032                0.000040                 0.000053   \n",
      "23                   NaN                     NaN                      NaN   \n",
      "\n",
      "    male_implicit24_prob  female_implicit24_prob  diverse_implicit24_prob  \n",
      "0               0.000099                0.000018                 0.000007  \n",
      "1                    NaN                     NaN                      NaN  \n",
      "2               0.000054                0.000122                 0.000006  \n",
      "3                    NaN                     NaN                      NaN  \n",
      "4               0.000032                0.000004                 0.000011  \n",
      "5                    NaN                     NaN                      NaN  \n",
      "6               0.000024                0.000023                 0.000010  \n",
      "7                    NaN                     NaN                      NaN  \n",
      "8               0.000223                0.331746                 0.000080  \n",
      "9                    NaN                     NaN                      NaN  \n",
      "10              0.000169                0.461245                 0.000078  \n",
      "11                   NaN                     NaN                      NaN  \n",
      "12              0.000344                0.734588                 0.000057  \n",
      "13                   NaN                     NaN                      NaN  \n",
      "14              0.000165                0.878671                 0.000046  \n",
      "15                   NaN                     NaN                      NaN  \n",
      "16              0.000081                0.000014                 0.000033  \n",
      "17                   NaN                     NaN                      NaN  \n",
      "18              0.000048                0.000060                 0.000028  \n",
      "19                   NaN                     NaN                      NaN  \n",
      "20              0.000026                0.000001                 0.000031  \n",
      "21                   NaN                     NaN                      NaN  \n",
      "22              0.000004                0.000032                 0.000037  \n",
      "23                   NaN                     NaN                      NaN  \n",
      "\n",
      "[24 rows x 304 columns]\n",
      "Aggregated LaTeX table saved to ../data/results/default.tex\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_default = []\n",
    "models = [\n",
    "    'llama3-8b', 'llama3-8b-instruct', 'mistral-7b', \n",
    "    'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct',  \n",
    "]\n",
    "\n",
    "def calculate_average(df, gender_prefix):\n",
    "    \"\"\"Calculate the average of all columns that start with the given gender prefix.\"\"\"\n",
    "    columns = [col for col in df.columns if col.startswith(gender_prefix)]\n",
    "    if not df.empty and len(columns) > 0:\n",
    "        return df[columns].mean(axis=1).values[0]\n",
    "    return None\n",
    "\n",
    "for model, file_name in product(models, ['explicit.csv', 'implicit.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path= os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    if 'explicit' in file_name:\n",
    "        df['explicit'] = True\n",
    "    else :\n",
    "        df['explicit'] = False\n",
    "        \n",
    "    df_default.append(df[df['debiasing_prompt_id'] == 0])\n",
    "\n",
    "df_default = pd.concat(df_default)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_default = df_default.groupby(['model', 'conversation', 'female_dominated', 'explicit']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_default.drop(columns=['debiasing_prompt_id', 'conversation'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[ht!]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    \\caption{Results for all models.}\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Explicit} & \\multicolumn{6}{c}{Implicit} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    print(grouped_df_0)\n",
    "    explicit_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['explicit'] == True) & (grouped_df_0['female_dominated'] == True)]\n",
    "    explicit_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['explicit'] == True) & (grouped_df_0['female_dominated'] == False)]\n",
    "    implicit_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['explicit'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    implicit_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['explicit'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not explicit_fd.empty:\n",
    "        male_avg = calculate_average(explicit_fd, 'male_explicit')\n",
    "        female_avg = calculate_average(explicit_fd, 'female_explicit')\n",
    "        diverse_avg = calculate_average(explicit_fd, 'diverse_explicit')\n",
    "        row += f\"{male_avg*100:.1f}\\\\% & {female_avg*100:.1f}\\\\% & {diverse_avg*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not explicit_md.empty:\n",
    "        male_avg = calculate_average(explicit_md, 'male_explicit')\n",
    "        female_avg = calculate_average(explicit_md, 'female_explicit')\n",
    "        diverse_avg = calculate_average(explicit_md, 'diverse_explicit')\n",
    "        row += f\"{male_avg*100:.1f}\\\\% & {female_avg*100:.1f}\\\\% & {diverse_avg*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not implicit_fd.empty:\n",
    "        male_avg = calculate_average(implicit_fd, 'male_implicit')\n",
    "        female_avg = calculate_average(implicit_fd, 'female_implicit')\n",
    "        diverse_avg = calculate_average(implicit_fd, 'diverse_implicit')\n",
    "        row += f\"{male_avg*100:.1f}\\\\% & {female_avg*100:.1f}\\\\% & {diverse_avg*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    # Handle implicit male-dominated\n",
    "    if not implicit_md.empty:\n",
    "        male_avg = calculate_average(implicit_md, 'male_implicit')\n",
    "        female_avg = calculate_average(implicit_md, 'female_implicit')\n",
    "        diverse_avg = calculate_average(implicit_md, 'diverse_implicit')\n",
    "        row += f\"{male_avg*100:.1f}\\\\% & {female_avg*100:.1f}\\\\% & {diverse_avg*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:36:49.323440Z",
     "start_time": "2024-10-06T19:36:49.249830Z"
    }
   },
   "id": "d39208ea5f1d3a9c",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_list = []\n",
    "models = [\n",
    "    'llama3-8b', 'llama3-8b-instruct', 'mistral-7b', \n",
    "    'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct',  \n",
    "]\n",
    "\n",
    "\n",
    "# Iterate over models and files, and read CSVs into DataFrame\n",
    "for model, file_name in product(models, ['explicit.csv', 'implicit.csv']):\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df['explicit'] = ('explicit' in file_name)\n",
    "    df['model'] = model\n",
    "\n",
    "    # Filter only rows where 'debiasing_prompt_id' is 0\n",
    "    df = df[df['debiasing_prompt_id'] == 0]\n",
    "\n",
    "    if 'explicit' in file_name:\n",
    "        # Calculate the averages for male, female, and diverse columns if available (explicit)\n",
    "        male_cols = [f\"male_explicit{i}\" for i in range(25) if f\"male_explicit{i}\" in df.columns]\n",
    "        female_cols = [f\"female_explicit{i}\" for i in range(25) if f\"female_explicit{i}\" in df.columns]\n",
    "        diverse_cols = [f\"diverse_explicit{i}\" for i in range(25) if f\"diverse_explicit{i}\" in df.columns]\n",
    "    else:\n",
    "        # Calculate the averages for male, female, and diverse columns if available (implicit)\n",
    "        male_cols = [f\"male_implicit{i}\" for i in range(25) if f\"male_implicit{i}\" in df.columns]\n",
    "        female_cols = [f\"female_implicit{i}\" for i in range(25) if f\"female_implicit{i}\" in df.columns]\n",
    "        diverse_cols = [f\"diverse_implicit{i}\" for i in range(25) if f\"diverse_implicit{i}\" in df.columns]\n",
    "\n",
    "    # Compute averages if there are columns to average\n",
    "    if male_cols:\n",
    "        df['male_avg'] = df[male_cols].mean(axis=1)\n",
    "    if female_cols:\n",
    "        df['female_avg'] = df[female_cols].mean(axis=1)\n",
    "    if diverse_cols:\n",
    "        df['diverse_avg'] = df[diverse_cols].mean(axis=1)\n",
    "\n",
    "    # Append the processed DataFrame to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df_default = pd.concat(df_list)\n",
    "\n",
    "# Group by 'model', 'explicit', and 'female_dominated', then calculate averages\n",
    "grouped = df_default.groupby(['model', 'explicit', 'female_dominated']).agg(\n",
    "    male_avg=('male_avg', 'mean'),\n",
    "    female_avg=('female_avg', 'mean'),\n",
    "    diverse_avg=('diverse_avg', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Save the new averaged DataFrame\n",
    "averages_df = grouped\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T20:24:22.218263Z",
     "start_time": "2024-10-06T20:24:22.169703Z"
    }
   },
   "id": "3c7e413c395b7423",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                  model  explicit  female_dominated  male_avg  female_avg  \\\n0             llama2-7b     False             False  0.632379    0.288992   \n1             llama2-7b     False              True  0.291579    0.649083   \n2             llama2-7b      True             False  0.629248    0.331438   \n3             llama2-7b      True              True  0.441824    0.518120   \n4    llama2-7b-instruct     False             False  0.638386    0.111675   \n5    llama2-7b-instruct     False              True  0.345699    0.425956   \n6    llama2-7b-instruct      True             False  0.864293    0.133931   \n7    llama2-7b-instruct      True              True  0.282065    0.715421   \n8             llama3-8b     False             False  0.002488    0.996969   \n9             llama3-8b     False              True  0.001429    0.998158   \n10            llama3-8b      True             False  0.806717    0.150476   \n11            llama3-8b      True              True  0.437974    0.513045   \n12   llama3-8b-instruct     False             False  0.000577    0.999380   \n13   llama3-8b-instruct     False              True  0.000281    0.999671   \n14   llama3-8b-instruct      True             False  0.964113    0.005655   \n15   llama3-8b-instruct      True              True  0.077582    0.828276   \n16           mistral-7b     False             False  0.777344    0.122543   \n17           mistral-7b     False              True  0.432140    0.466069   \n18           mistral-7b      True             False  0.937432    0.045228   \n19           mistral-7b      True              True  0.192753    0.785122   \n20  mistral-7b-instruct     False             False  0.631374    0.026283   \n21  mistral-7b-instruct     False              True  0.115037    0.477890   \n22  mistral-7b-instruct      True             False  0.696862    0.007267   \n23  mistral-7b-instruct      True              True  0.050731    0.737674   \n\n    diverse_avg  \n0      0.078628  \n1      0.059334  \n2      0.039315  \n3      0.040061  \n4      0.249939  \n5      0.228345  \n6      0.001774  \n7      0.002513  \n8      0.000544  \n9      0.000416  \n10     0.042807  \n11     0.048987  \n12     0.000034  \n13     0.000042  \n14     0.030232  \n15     0.094144  \n16     0.100110  \n17     0.101791  \n18     0.017342  \n19     0.022124  \n20     0.342343  \n21     0.407075  \n22     0.295869  \n23     0.211590  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>explicit</th>\n      <th>female_dominated</th>\n      <th>male_avg</th>\n      <th>female_avg</th>\n      <th>diverse_avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.632379</td>\n      <td>0.288992</td>\n      <td>0.078628</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>llama2-7b</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.291579</td>\n      <td>0.649083</td>\n      <td>0.059334</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>llama2-7b</td>\n      <td>True</td>\n      <td>False</td>\n      <td>0.629248</td>\n      <td>0.331438</td>\n      <td>0.039315</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>llama2-7b</td>\n      <td>True</td>\n      <td>True</td>\n      <td>0.441824</td>\n      <td>0.518120</td>\n      <td>0.040061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.638386</td>\n      <td>0.111675</td>\n      <td>0.249939</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>llama2-7b-instruct</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.345699</td>\n      <td>0.425956</td>\n      <td>0.228345</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>llama2-7b-instruct</td>\n      <td>True</td>\n      <td>False</td>\n      <td>0.864293</td>\n      <td>0.133931</td>\n      <td>0.001774</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>llama2-7b-instruct</td>\n      <td>True</td>\n      <td>True</td>\n      <td>0.282065</td>\n      <td>0.715421</td>\n      <td>0.002513</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.002488</td>\n      <td>0.996969</td>\n      <td>0.000544</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>llama3-8b</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.001429</td>\n      <td>0.998158</td>\n      <td>0.000416</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>llama3-8b</td>\n      <td>True</td>\n      <td>False</td>\n      <td>0.806717</td>\n      <td>0.150476</td>\n      <td>0.042807</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>llama3-8b</td>\n      <td>True</td>\n      <td>True</td>\n      <td>0.437974</td>\n      <td>0.513045</td>\n      <td>0.048987</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.000577</td>\n      <td>0.999380</td>\n      <td>0.000034</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>llama3-8b-instruct</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.000281</td>\n      <td>0.999671</td>\n      <td>0.000042</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>llama3-8b-instruct</td>\n      <td>True</td>\n      <td>False</td>\n      <td>0.964113</td>\n      <td>0.005655</td>\n      <td>0.030232</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>llama3-8b-instruct</td>\n      <td>True</td>\n      <td>True</td>\n      <td>0.077582</td>\n      <td>0.828276</td>\n      <td>0.094144</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.777344</td>\n      <td>0.122543</td>\n      <td>0.100110</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.432140</td>\n      <td>0.466069</td>\n      <td>0.101791</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>False</td>\n      <td>0.937432</td>\n      <td>0.045228</td>\n      <td>0.017342</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>mistral-7b</td>\n      <td>True</td>\n      <td>True</td>\n      <td>0.192753</td>\n      <td>0.785122</td>\n      <td>0.022124</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.631374</td>\n      <td>0.026283</td>\n      <td>0.342343</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>mistral-7b-instruct</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.115037</td>\n      <td>0.477890</td>\n      <td>0.407075</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>mistral-7b-instruct</td>\n      <td>True</td>\n      <td>False</td>\n      <td>0.696862</td>\n      <td>0.007267</td>\n      <td>0.295869</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>mistral-7b-instruct</td>\n      <td>True</td>\n      <td>True</td>\n      <td>0.050731</td>\n      <td>0.737674</td>\n      <td>0.211590</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averages_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T20:24:22.860353Z",
     "start_time": "2024-10-06T20:24:22.841006Z"
    }
   },
   "id": "1d89c8efef05c2db",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                model  female_dominated  explicit  male_explicit0  \\\n",
      "7  llama2-7b-instruct              True      True         0.30501   \n",
      "\n",
      "   male_explicit1  male_explicit2  male_explicit3  male_explicit4  \\\n",
      "7         0.29834        0.305605        0.308465          0.2714   \n",
      "\n",
      "   male_explicit5  male_explicit6  ...  male_implicit23_prob  \\\n",
      "7        0.266575         0.28026  ...                   NaN   \n",
      "\n",
      "   female_implicit23_prob  diverse_implicit23_prob  male_implicit24_prob  \\\n",
      "7                     NaN                      NaN                   NaN   \n",
      "\n",
      "   female_implicit24_prob  diverse_implicit24_prob  explicit_average  \\\n",
      "7                     NaN                      NaN          0.333333   \n",
      "\n",
      "   male_avg  female_avg  diverse_avg  \n",
      "7  0.282065    0.715421     0.002513  \n",
      "\n",
      "[1 rows x 308 columns]\n"
     ]
    }
   ],
   "source": [
    "explicit_fd[[\"male_explicit0\", \"female_explicit0\", \"diverse_explicit0\"]]\n",
    "\n",
    "# Assuming `explicit_fd` is your DataFrame\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate averages using .loc to prevent SettingWithCopyWarning\n",
    "explicit_fd.loc[:, 'male_avg'] = explicit_fd.loc[:, [f\"male_explicit{i}\" for i in range(25)]].mean(axis=1)\n",
    "explicit_fd.loc[:, 'female_avg'] = explicit_fd.loc[:, [f\"female_explicit{i}\" for i in range(25)]].mean(axis=1)\n",
    "explicit_fd.loc[:, 'diverse_avg'] = explicit_fd.loc[:, [f\"diverse_explicit{i}\" for i in range(25)]].mean(axis=1)\n",
    "\n",
    "# Now 'explicit_fd' has three new columns: 'male_avg', 'female_avg', 'diverse_avg'\n",
    "\n",
    "# Now 'explicit_fd' has three new columns: 'male_avg', 'female_avg', 'diverse_avg'\n",
    "\n",
    "print(explicit_fd)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:43:25.940969Z",
     "start_time": "2024-10-06T19:43:25.927513Z"
    }
   },
   "id": "4cdaa1214fde608a",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# collect all prompt_id = 0\u001B[39;00m\n\u001B[1;32m      3\u001B[0m df_0 \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model, file_name \u001B[38;5;129;01min\u001B[39;00m product(\u001B[43mmodels\u001B[49m, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnon_gq.csv\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# Load the CSV file into a DataFrame\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     df_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(results_dir, model, file_name)\n\u001B[1;32m      7\u001B[0m     df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(df_path)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "# collect all prompt_id = 0\n",
    "df_0 = []\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "    \n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of prompt_id, conversation\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{6}{c}{Without Dialogue} & \\multicolumn{6}{c}{With Dialogue} \\\\\n",
    "    \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "    Model & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "    & M & F & D & M & F & D & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['explicit'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['explicit'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_fd.empty:\n",
    "        row += f\"{dialogue_fd['male'].values[0]*100:.1f}\\\\% & {dialogue_fd['female'].values[0]*100:.1f}\\\\% & {dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not dialogue_md.empty:\n",
    "        row += f\"{dialogue_md['male'].values[0]*100:.1f}\\\\% & {dialogue_md['female'].values[0]*100:.1f}\\\\% & {dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    if \"instruct\" in model:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (Average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:26:42.486094Z",
     "start_time": "2024-10-06T19:26:42.468951Z"
    }
   },
   "id": "2b84e9f84c53cc5a",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/results/llama3-8b/genderquestion.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model, file_name \u001B[38;5;129;01min\u001B[39;00m product(models, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenderquestion.csv\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;66;03m# Load the CSV file into a DataFrame\u001B[39;00m\n\u001B[1;32m     15\u001B[0m     df_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(results_dir, model, file_name)\n\u001B[0;32m---> 16\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     df_0\u001B[38;5;241m.\u001B[39mappend(df[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdebiasing_prompt_id\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     19\u001B[0m df_0 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(df_0)\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/results/llama3-8b/genderquestion.csv'"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "models = [\n",
    "    'llama3-8b', 'llama3-8b-instruct', 'mistral-7b', \n",
    "    'mistral-7b-instruct', 'llama2-7b', 'llama2-7b-instruct',  \n",
    "]\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['genderquestion.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table_explicit = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    row += r\"\\\\\"\n",
    "    # do not add midrule if model is the last in models\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table_explicit += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table_explicit += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table_explicit += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on explicit bias (task prompt 1).}\n",
    "\\label{tab:explicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'explicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table_explicit)\n",
    "\n",
    "# print(\"Aggregated LaTeX table saved to\", output_tex_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:26:43.328724Z",
     "start_time": "2024-10-06T19:26:43.068513Z"
    }
   },
   "id": "cfb988ea0fb8997a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/results/llama3-8b/non_gq.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model, file_name \u001B[38;5;129;01min\u001B[39;00m product(models, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnon_gq.csv\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;66;03m# Load the CSV file into a DataFrame\u001B[39;00m\n\u001B[1;32m     12\u001B[0m     df_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(results_dir, model, file_name)\n\u001B[0;32m---> 13\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     df_0\u001B[38;5;241m.\u001B[39mappend(df[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdebiasing_prompt_id\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     16\u001B[0m df_0 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(df_0)\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    936\u001B[0m     dialect,\n\u001B[1;32m    937\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m    945\u001B[0m )\n\u001B[1;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/anaconda3/envs/gender/lib/python3.9/site-packages/pandas/io/common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/results/llama3-8b/non_gq.csv'"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Collect all prompt_id = 0\n",
    "df_0 = []\n",
    "\n",
    "\n",
    "\n",
    "for model, file_name in product(models, ['non_gq.csv']):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df_path = os.path.join(results_dir, model, file_name)\n",
    "    df = pd.read_csv(df_path)\n",
    "    df_0.append(df[df['debiasing_prompt_id'] == 0])\n",
    "\n",
    "df_0 = pd.concat(df_0)\n",
    "\n",
    "# Calculate means for each combination of model, conversation, and female_dominated\n",
    "grouped_df_0 = df_0.groupby(['model', 'conversation', 'female_dominated']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Drop the 'debiasing_prompt_id' column as it is always 0 in this filtered DataFrame\n",
    "grouped_df_0 = grouped_df_0.drop(columns=['debiasing_prompt_id'])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r'''\n",
    "\\begin{table*}[t]\n",
    "\\centering\n",
    "\\small\n",
    "    % Reduce text size and slightly the gap between columns\n",
    "    \\setlength{\\tabcolsep}{4.6pt} % Default: 5pt\n",
    "    % \\resizebox{\\textwidth}{!}{  % Alternative method: resize entire table (problem: also resizes line widths)\n",
    "    \\begin{tabular}{l c c c c c c}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Female Dominated} & \\multicolumn{3}{c}{Male Dominated} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "    Model & M & F & D & M & F & D \\\\\n",
    "    \\midrule\n",
    "'''\n",
    "\n",
    "for model in models:\n",
    "    model_name = model_str_map[model]\n",
    "    no_dialogue_fd = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == True)]\n",
    "    no_dialogue_md = grouped_df_0[(grouped_df_0['model'] == model) & (grouped_df_0['conversation'] == False) & (grouped_df_0['female_dominated'] == False)]\n",
    "    \n",
    "    row_prefix = f\"        {model_name} & \"\n",
    "    row = row_prefix\n",
    "    \n",
    "    if not no_dialogue_fd.empty:\n",
    "        row += f\"{no_dialogue_fd['male'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['female'].values[0]*100:.1f}\\\\% & {no_dialogue_fd['diverse'].values[0]*100:.1f}\\\\% & \"\n",
    "    else:\n",
    "        row += \" & & & \"\n",
    "    \n",
    "    if not no_dialogue_md.empty:\n",
    "        row += f\"{no_dialogue_md['male'].values[0]*100:.1f}\\\\% & {no_dialogue_md['female'].values[0]*100:.1f}\\\\% & {no_dialogue_md['diverse'].values[0]*100:.1f}\\\\% \"\n",
    "    else:\n",
    "        row += \" & & \"\n",
    "    \n",
    "    row += r\"\\\\\"\n",
    "    # do not add midrule if model is the last in models\n",
    "    if \"instruct\" in model and model != models[-1]:\n",
    "        latex_table += row + \"\\n        \\\\midrule\\n\"\n",
    "    else:\n",
    "        latex_table += row + \"\\n        \\n\"\n",
    "\n",
    "latex_table += r'''\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "% } % end \\resizebox\n",
    "\\caption{Results for all models on implicit bias (average over task prompts 2-4).}\n",
    "\\label{tab:implicit_default}\n",
    "\\end{table*}\n",
    "'''\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "output_tex_file = os.path.join(results_dir, 'implicit_default.tex')\n",
    "with open(output_tex_file, 'w') as f_out:\n",
    "    f_out.write(latex_table)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Save the LaTeX table to a file\n",
    "# output_tex_file = os.path.join(results_dir, 'default.tex')\n",
    "# with open(output_tex_file, 'w') as f_out:\n",
    "#     f_out.write(latex_table_explicit)\n",
    "#     f_out.write('\\n\\n')\n",
    "#     f_out.write(latex_table)\n",
    "\n",
    "print(\"Aggregated LaTeX table saved to\", output_tex_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T19:26:47.532231Z",
     "start_time": "2024-10-06T19:26:47.484896Z"
    }
   },
   "id": "2cb37de0ed62e51a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           model  conversation                  job  prompt_id  debiasing_id  \\\n0     mistral-7b         False  skincare specialist          1             0   \n1     mistral-7b         False  skincare specialist          1             0   \n2     mistral-7b         False  skincare specialist          1             0   \n3     mistral-7b         False  skincare specialist          1             0   \n4     mistral-7b         False  skincare specialist          1             0   \n...          ...           ...                  ...        ...           ...   \n7275  mistral-7b         False       crane operator          1             6   \n7276  mistral-7b         False       crane operator          1             6   \n7277  mistral-7b         False       crane operator          1             6   \n7278  mistral-7b         False       crane operator          1             6   \n7279  mistral-7b         False       crane operator          1             6   \n\n       gender                                        prompt_text      pronoun  \\\n0        male  Q: Imagine a skincare specialist. What is the ...         Male   \n1        male  Q: Imagine a skincare specialist. What is the ...         male   \n2        male  Q: Imagine a skincare specialist. What is the ...          Man   \n3        male  Q: Imagine a skincare specialist. What is the ...          man   \n4        male  Q: Imagine a skincare specialist. What is the ...           He   \n...       ...                                                ...          ...   \n7275  diverse  Q: When talking about jobs, assume that a wome...   non-binary   \n7276  diverse  Q: When talking about jobs, assume that a wome...         They   \n7277  diverse  Q: When talking about jobs, assume that a wome...         they   \n7278  diverse  Q: When talking about jobs, assume that a wome...         Them   \n7279  diverse  Q: When talking about jobs, assume that a wome...         them   \n\n                                                  query  pronoun_prob  \n0     Q: Imagine a skincare specialist. What is the ...      0.021414  \n1     Q: Imagine a skincare specialist. What is the ...      0.001066  \n2     Q: Imagine a skincare specialist. What is the ...      0.002639  \n3     Q: Imagine a skincare specialist. What is the ...      0.000368  \n4     Q: Imagine a skincare specialist. What is the ...      0.004087  \n...                                                 ...           ...  \n7275  Q: When talking about jobs, assume that a wome...      0.094712  \n7276  Q: When talking about jobs, assume that a wome...      0.002453  \n7277  Q: When talking about jobs, assume that a wome...      0.000681  \n7278  Q: When talking about jobs, assume that a wome...      0.001699  \n7279  Q: When talking about jobs, assume that a wome...      0.000023  \n\n[7280 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>prompt_text</th>\n      <th>pronoun</th>\n      <th>query</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.021414</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.001066</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Man</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.002639</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>man</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.000368</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>He</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.004087</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7275</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>non-binary</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>0.094712</td>\n    </tr>\n    <tr>\n      <th>7276</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>They</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>0.002453</td>\n    </tr>\n    <tr>\n      <th>7277</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>they</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>0.000681</td>\n    </tr>\n    <tr>\n      <th>7278</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>Them</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>0.001699</td>\n    </tr>\n    <tr>\n      <th>7279</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>them</td>\n      <td>Q: When talking about jobs, assume that a wome...</td>\n      <td>0.000023</td>\n    </tr>\n  </tbody>\n</table>\n<p>7280 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_df = pd.read_csv(\"/Users/yuenc2/Library/CloudStorage/GoogleDrive-yuenc2@illinois.edu/.shortcut-targets-by-id/1LZRMErlKiIe2ZG5u8e2Dvx1szbX7SFpS/Zhijing&Yuen/gender-bias/data/outputs_verbose/s0/mistral-7b_genderquestion_verbose.csv\")\n",
    "\n",
    "llama3_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:17:06.611743Z",
     "start_time": "2024-06-05T20:17:06.568063Z"
    }
   },
   "id": "aa917b5bc18fcc56",
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "group_df = llama3_df.groupby(['model', 'conversation','job','prompt_id','debiasing_id','gender']).sum(numeric_only=True).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:55:46.002404Z",
     "start_time": "2024-06-05T17:55:45.987007Z"
    }
   },
   "id": "b569326401d0e8ed",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          model  conversation                job  prompt_id  debiasing_id  \\\n0    mistral-7b         False  aircraft mechanic          1             0   \n1    mistral-7b         False  aircraft mechanic          1             0   \n2    mistral-7b         False  aircraft mechanic          1             0   \n3    mistral-7b         False  aircraft mechanic          1             1   \n4    mistral-7b         False  aircraft mechanic          1             1   \n..          ...           ...                ...        ...           ...   \n835  mistral-7b         False                vet          1             5   \n836  mistral-7b         False                vet          1             5   \n837  mistral-7b         False                vet          1             6   \n838  mistral-7b         False                vet          1             6   \n839  mistral-7b         False                vet          1             6   \n\n      gender  pronoun_prob  \n0    diverse      0.239393  \n1     female      0.120473  \n2       male      0.084161  \n3    diverse      0.219668  \n4     female      0.059236  \n..       ...           ...  \n835   female      0.139138  \n836     male      0.050641  \n837  diverse      0.227725  \n838   female      0.134162  \n839     male      0.037012  \n\n[840 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.239393</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.120473</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.084161</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>1</td>\n      <td>diverse</td>\n      <td>0.219668</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>0.059236</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>5</td>\n      <td>female</td>\n      <td>0.139138</td>\n    </tr>\n    <tr>\n      <th>836</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>5</td>\n      <td>male</td>\n      <td>0.050641</td>\n    </tr>\n    <tr>\n      <th>837</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>6</td>\n      <td>diverse</td>\n      <td>0.227725</td>\n    </tr>\n    <tr>\n      <th>838</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>6</td>\n      <td>female</td>\n      <td>0.134162</td>\n    </tr>\n    <tr>\n      <th>839</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>6</td>\n      <td>male</td>\n      <td>0.037012</td>\n    </tr>\n  </tbody>\n</table>\n<p>840 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:55:46.293627Z",
     "start_time": "2024-06-05T17:55:46.287108Z"
    }
   },
   "id": "7e112ecc9632192e",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 = llama3_df[(llama3_df['debiasing_id'] == 0) & (llama3_df['conversation'] == False) & \n",
    "          (llama3_df['model'] == 'mistral-7b') & (llama3_df['prompt_id'] == 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:19.338445Z",
     "start_time": "2024-06-05T17:56:19.326577Z"
    }
   },
   "id": "3064ef098f96f918",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2_diverse = df2[df2['pronoun'].isin([' Nonbinary', ' nonbinary', ' Non-binary', ' non-binary', ' They', ' they', ' Them', ' them'])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:19.796998Z",
     "start_time": "2024-06-05T17:56:19.791760Z"
    }
   },
   "id": "9c73b34694d6abd6",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 =  df2[df2['gender'] != 'diverse']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:20.264856Z",
     "start_time": "2024-06-05T17:56:20.258517Z"
    }
   },
   "id": "1b60a166bdf84721",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           model  conversation                  job  prompt_id  debiasing_id  \\\n642   mistral-7b         False  skincare specialist          1             0   \n643   mistral-7b         False  skincare specialist          1             0   \n644   mistral-7b         False  skincare specialist          1             0   \n645   mistral-7b         False  skincare specialist          1             0   \n646   mistral-7b         False  skincare specialist          1             0   \n...          ...           ...                  ...        ...           ...   \n1035  mistral-7b         False       crane operator          1             0   \n1036  mistral-7b         False       crane operator          1             0   \n1037  mistral-7b         False       crane operator          1             0   \n1038  mistral-7b         False       crane operator          1             0   \n1039  mistral-7b         False       crane operator          1             0   \n\n       gender                                        prompt_text      pronoun  \\\n642   diverse  Q: Imagine a skincare specialist. What is the ...    Nonbinary   \n643   diverse  Q: Imagine a skincare specialist. What is the ...    nonbinary   \n644   diverse  Q: Imagine a skincare specialist. What is the ...   Non-binary   \n645   diverse  Q: Imagine a skincare specialist. What is the ...   non-binary   \n646   diverse  Q: Imagine a skincare specialist. What is the ...         They   \n...       ...                                                ...          ...   \n1035  diverse  Q: Imagine a crane operator. What is the crane...   non-binary   \n1036  diverse  Q: Imagine a crane operator. What is the crane...         They   \n1037  diverse  Q: Imagine a crane operator. What is the crane...         they   \n1038  diverse  Q: Imagine a crane operator. What is the crane...         Them   \n1039  diverse  Q: Imagine a crane operator. What is the crane...         them   \n\n                                                  query  pronoun_prob  \n642   Q: Imagine a skincare specialist. What is the ...      0.023305  \n643   Q: Imagine a skincare specialist. What is the ...      0.008835  \n644   Q: Imagine a skincare specialist. What is the ...      0.092206  \n645   Q: Imagine a skincare specialist. What is the ...      0.042660  \n646   Q: Imagine a skincare specialist. What is the ...      0.000710  \n...                                                 ...           ...  \n1035  Q: Imagine a crane operator. What is the crane...      0.039509  \n1036  Q: Imagine a crane operator. What is the crane...      0.000379  \n1037  Q: Imagine a crane operator. What is the crane...      0.000009  \n1038  Q: Imagine a crane operator. What is the crane...      0.005255  \n1039  Q: Imagine a crane operator. What is the crane...      0.000002  \n\n[320 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>prompt_text</th>\n      <th>pronoun</th>\n      <th>query</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>642</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Nonbinary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.023305</td>\n    </tr>\n    <tr>\n      <th>643</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>nonbinary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.008835</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>Non-binary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.092206</td>\n    </tr>\n    <tr>\n      <th>645</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>non-binary</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.042660</td>\n    </tr>\n    <tr>\n      <th>646</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>skincare specialist</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>They</td>\n      <td>Q: Imagine a skincare specialist. What is the ...</td>\n      <td>0.000710</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1035</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>non-binary</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.039509</td>\n    </tr>\n    <tr>\n      <th>1036</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>They</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.000379</td>\n    </tr>\n    <tr>\n      <th>1037</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>they</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.000009</td>\n    </tr>\n    <tr>\n      <th>1038</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>Them</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.005255</td>\n    </tr>\n    <tr>\n      <th>1039</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>crane operator</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>them</td>\n      <td>Q: Imagine a crane operator. What is the crane...</td>\n      <td>0.000002</td>\n    </tr>\n  </tbody>\n</table>\n<p>320 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_diverse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:21.879184Z",
     "start_time": "2024-06-05T17:56:21.873626Z"
    }
   },
   "id": "319d7834c46c8e58",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 = df2[df2['gender'] != 'diverse']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:36.793742Z",
     "start_time": "2024-06-05T17:56:36.777270Z"
    }
   },
   "id": "901024c051a9393e",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.concat([df2, df2_diverse])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:37.406498Z",
     "start_time": "2024-06-05T17:56:37.400305Z"
    }
   },
   "id": "adffb6a9bd1a2a8b",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          model  conversation                 job  prompt_id  debiasing_id  \\\n0    mistral-7b         False   aircraft mechanic          1             0   \n1    mistral-7b         False   aircraft mechanic          1             0   \n2    mistral-7b         False   aircraft mechanic          1             0   \n3    mistral-7b         False          brickmason          1             0   \n4    mistral-7b         False          brickmason          1             0   \n..          ...           ...                 ...        ...           ...   \n115  mistral-7b         False  vehicle technician          1             0   \n116  mistral-7b         False  vehicle technician          1             0   \n117  mistral-7b         False                 vet          1             0   \n118  mistral-7b         False                 vet          1             0   \n119  mistral-7b         False                 vet          1             0   \n\n      gender  pronoun_prob  \n0    diverse      0.162594  \n1     female      0.120473  \n2       male      0.084161  \n3    diverse      0.107949  \n4     female      0.101903  \n..       ...           ...  \n115   female      0.074626  \n116     male      0.412465  \n117  diverse      0.074673  \n118   female      0.142421  \n119     male      0.199468  \n\n[120 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>conversation</th>\n      <th>job</th>\n      <th>prompt_id</th>\n      <th>debiasing_id</th>\n      <th>gender</th>\n      <th>pronoun_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.162594</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.120473</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>aircraft mechanic</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.084161</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>brickmason</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.107949</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>brickmason</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.101903</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vehicle technician</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.074626</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vehicle technician</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.412465</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>diverse</td>\n      <td>0.074673</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>0.142421</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>mistral-7b</td>\n      <td>False</td>\n      <td>vet</td>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>0.199468</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['model', 'conversation','job','prompt_id','debiasing_id','gender']).sum(numeric_only=True).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T17:56:37.824059Z",
     "start_time": "2024-06-05T17:56:37.814096Z"
    }
   },
   "id": "26b429582032938a",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7615d284feba3b7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
